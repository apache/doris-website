# Detect global dead links (no auto fix)
#
# Core logic:
# Traverse all documents, match the links in the documents, and determine whether it is a dead link by the link address.
# If it is a dead link, print:
#   âŒ ç›®æ ‡æ–‡æ¡£ xxxx/xxxx.md
#   Broken link ${target_link}
#
# This version:
#   - skips inline and code block links
#   - ignores anchors (#xxx)
#   - checks .md and .mdx variants
#   - never modifies files
#   - counts and prints total broken links at the end

import argparse
import os
import re
import sys
from urllib.parse import urlparse

search_dirs = ["docs", "i18n", "versioned_docs", "community"]
broken_count = 0  # å…¨å±€æ­»é“¾è®¡æ•°

def process_md_file(file_path):
    global broken_count

    # åŒ¹é… Markdown é“¾æ¥ï¼š[text](link)
    link_pattern = re.compile(r"\[([^\]]+)\]\(([^)]+)\)")
    # åŒ¹é…ä»£ç å—ï¼ˆåŒ…æ‹¬ ``` å¤šè¡Œä»£ç å— å’Œ `è¡Œå†…ä»£ç `ï¼‰
    code_block_pattern = re.compile(r"(```.*?```|`[^`]*`)", re.DOTALL)

    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()

    # æå–æ‰€æœ‰ä»£ç å—èŒƒå›´
    code_blocks = []
    for match in code_block_pattern.finditer(content):
        code_blocks.append((match.start(), match.end()))

    def is_inside_code_block(pos):
        """åˆ¤æ–­è¯¥ä½ç½®æ˜¯å¦ä½äºä»£ç å—æˆ–è¡Œå†…ä»£ç ä¸­"""
        for start, end in code_blocks:
            if start <= pos < end:
                return True
        return False

    links = list(link_pattern.finditer(content))
    for match in links:
        link_target = match.group(2).strip()
        start_pos = match.start()

        # è·³è¿‡åœ¨ä»£ç å—æˆ–åå¼•å·ä¸­çš„é“¾æ¥
        if is_inside_code_block(start_pos):
            continue

        # è·³è¿‡å¤–éƒ¨é“¾æ¥ï¼ˆhttp/https/mailtoç­‰ï¼‰
        if urlparse(link_target).scheme or os.path.isabs(link_target):
            continue

        # å»æ‰é”šç‚¹éƒ¨åˆ†ï¼ˆ#xxxï¼‰
        link_target_path = link_target.split("#", 1)[0]

        # å¦‚æœé“¾æ¥ä¸ºç©ºæˆ–åªæ˜¯é”šç‚¹ï¼ˆå¦‚ #sectionï¼‰ï¼Œè·³è¿‡
        if link_target_path == "" or link_target_path.startswith("#"):
            continue

        # æ„é€ ç›¸å¯¹è·¯å¾„
        full_path = os.path.normpath(os.path.join(os.path.dirname(file_path), link_target_path))

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆå…è®¸çœç•¥ .md / .mdxï¼‰
        if not os.path.exists(full_path):
            md_path = full_path + ".md"
            mdx_path = full_path + ".mdx"
            if not os.path.exists(md_path) and not os.path.exists(mdx_path):
                print(f"ç›®æ ‡æ–‡æ¡£ {file_path}\nBroken link {link_target}\n")
                broken_count += 1

def travel(root_path: str):
    for root, dirs, files in os.walk(root_path):
        for file in files:
            if file.endswith(".md") or file.endswith(".mdx"):
                process_md_file(os.path.join(root, file))

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Detect broken md links (no auto fix)")
    parser.add_argument("--commit-id", type=str, help="Optional Git commit id (ignored for now)", default=None)
    args = parser.parse_args()

    print("ğŸ” Scanning for broken links...\n")

    for dir in search_dirs:
        if os.path.exists(dir):
            travel(dir)

    if broken_count > 0:
        print(f"â— å…±å‘ç° {broken_count} ä¸ªæ­»é“¾")
    else:
        print("âœ… æœªå‘ç°æ­»é“¾")

    print("âœ… Scan complete.")
