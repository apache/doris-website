---
{
    "title": "Paimon Catalog",
    "language": "en"
}
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Doris currently supports accessing Paimon table metadata through various metadata services and querying Paimon data.

At present, only read operations on Paimon tables are supported. Write operations to Paimon tables will be supported in the future.

[Quick start with Apache Doris and Apache Paimon](../best-practices/doris-paimon.md).

## Applicable Scenarios

| Scenario     | Description                                                  |
| ------------ | ------------------------------------------------------------ |
| Query Acceleration | Use Doris's distributed computing engine to directly access Paimon data for query acceleration. |
| Data Integration   | Read Paimon data and write it into Doris internal tables, or perform ZeroETL operations using the Doris computing engine. |
| Data Write-back    | Not supported yet.                                      |

## Configuring Catalog

### Syntax

```sql
CREATE CATALOG [IF NOT EXISTS] catalog_name PROPERTIES (
    'type' = 'paimon',
    'paimon.catalog.type' = '<paimon_catalog_type>',
    'warehouse' = '<paimon_warehouse>'
    {MetaStoreProperties},
    {StorageProperties},
    {PaimonProperties},
    {CommonProperties}
);
```

* `<paimon_catalog_type>`

  The type of Paimon Catalog, supporting the following:

  * `filesystem`: Default. Directly accesses metadata stored on the file system.

  * `hms`: Uses Hive Metastore as the metadata service.

  * `dlf`: Uses Alibaba Cloud DLF as the metadata service.

* `<paimon_warehouse>`

  The warehouse path for Paimon. This parameter must be specified when `<paimon_catalog_type>` is `filesystem`.

  The `warehouse` path must point to the level above the `Database` path. For example, if your table path is: `s3://bucket/path/to/db1/table1`, then `warehouse` should be: `s3://bucket/path/to/`.

* `{MetaStoreProperties}`

  The MetaStoreProperties section is used to fill in connection and authentication information for the Metastore metadata service. Refer to the section on [Supported Metadata Services] for details.

* `{StorageProperties}`

  The StorageProperties section is used to fill in connection and authentication information related to the storage system. Refer to the section on [Supported Storage Systems] for details.

* `{PaimonProperties}`

  The PaimonProperties section is used to fill Paimon-related properties.

  When Doris accesses Paimon metadata, it partially uses the Paimon Java SDK, so some custom parameters may need to be passed through to the Paimon Java SDK. You can use the following prefixes:

  ```
  paimon.s3.xxx
  paimon.s3a.xxx
  paimon.fs.xxx
  ```

  These parameters will be automatically converted and passed through. Here are some examples:

  | Input Parameter | Converted Parameter for Paimon Java SDK |
  | --- | --- |
  | "paimon.s3.list.version" = "1" | "fs.s3a.list.version" = "1" |
  | "paimon.s3.paging.maximum" = "100" | "fs.s3a.paging.maximum" = "100" |
  | "paimon.fs.s3.read.ahead.buffer.size" = "1" | "fs.s3a.read.ahead.buffer.size" = "1" |
  | "paimon.s3a.replication.factor" = "3" | "fs.s3a.replication.factor" = "3" |

* `{CommonProperties}`

  The CommonProperties section is used to fill in common properties. Please refer to the [Catalog Overview](../catalog-overview.md) section on [Common Properties].
  
### Supported Paimon Versions

The currently dependent Paimon version is 1.0.0.

### Supported Paimon Formats

* Supports reading Paimon Deletion Vector

### Supported Metadata Services

* [Hive Metastore](../metastores/hive-metastore.md)

* [Aliyun DLF](../metastores/aliyun-dlf.md)

* [FileSystem](../metastores/filesystem.md)

> Note: The service types and parameters supported by different Doris versions are slightly different. Please refer to the [Examples] section.

### Supported Storage Systems

* [HDFS](../storages/hdfs.md)

* [AWS S3](../storages/s3.md)

* [Google Cloud Storage](../storages/gcs.md)

* [Alibaba Cloud OSS](../storages/aliyun-oss.md)

* [Tencent Cloud COS](../storages/tencent-cos.md)

* [Huawei Cloud OBS](../storages/huawei-obs.md)

* [MINIO](../storages/minio.md)

> Note: The service types and parameters supported by different Doris versions are slightly different. Please refer to the [Examples] section.

### Supported Data Formats

* [Parquet](../file-formats/parquet.md)

* [ORC](../file-formats/orc.md)

## Column Type Mapping

| Paimon Type                        | Doris Type    | Comment                                                                 |
| ---------------------------------- | ------------- | ----------------------------------------------------------------------- |
| boolean                            | boolean       |                                                                         |
| tinyint                            | tinyint       |                                                                         |
| smallint                           | smallint      |                                                                         |
| integer                            | int           |                                                                         |
| bigint                             | bigint        |                                                                         |
| float                              | float         |                                                                         |
| double                             | double        |                                                                         |
| decimal(P, S)                      | decimal(P, S) |                                                                         |
| varchar                            | string        |                                                                         |
| char                               | string        |                                                                         |
| binary, varbinary                             | string/varbinary | Controlled by the `enable.mapping.varbinary` property of Catalog (supported since 4.0.2). The default is `false`, which maps to `string`; when `true`, it maps to `varbinary` type.|
| date                               | date          |                                                                         |
| timestamp\_without\_time\_zone     | datetime(N)   | Mapped according to precision. If precision is greater than 6, it maps to a maximum of 6 (may cause precision loss). |
| timestamp\_with\_local\_time\_zone | datetime(N)   | Mapped according to precision. If precision is greater than 6, it maps to a maximum of 6 (may cause precision loss). |
| array                              | array         |                                                                         |
| map                                | map           |                                                                         |
| row                                | struct        |                                                                         |
| other                              | UNSUPPORTED   |                                                                         |

> Note:
>
> Doris currently does not support `Timestamp` types with timezone. All `timestamp_without_time_zone` and `timestamp_with_local_time_zone` will be uniformly mapped to `datetime(N)` type. However, during reading, Doris will correctly handle timezones based on the actual source type. For example, after specifying a timezone with `SET time_zone=<tz>`, it will affect the return results of `timestamp_with_local_time_zone` columns.
>
> You can check whether the source type contains timezone information in the Extra column of the `DESCRIBE table_name` statement. If it displays `WITH_TIMEZONE`, it indicates that the source type is a timezone-aware type. (This feature is supported since 3.0.8)

## Examples
### Hive Metastore
<details>
    <summary>Version 3.1+</summary>
    <Tabs>
        <TabItem value='HDFS' label='HDFS' default>
            ```sql
            CREATE CATALOG test_paimon_on_hms_hdfs_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'hms',
                'warehouse' = 'hdfs://127.0.0.1:8320/user/hive/warehouse',
                'hive.metastore.uris' = 'thrift://127.0.0.1:9383',
                'fs.defaultFS' = 'hdfs://127.0.0.1:8320',
                'hadoop.username' = 'doris'
            );
            ```
        </TabItem>
        <TabItem value='S3' label='S3'>
            ```sql
            CREATE CATALOG test_paimon_on_hms_aws_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'hms',
                'hive.metastore.uris' = 'thrift://127.0.0.1:9383',
                'warehouse' = 's3://bucket/paimon_warehouse',
                's3.region' = 'ap-east-1',
                's3.endpoint' = 's3.ap-east-1.amazonaws.com',
                's3.access_key' = '<ak>',
                's3.secret_key' = '<sk>'
            );
            ```
            Obtaining S3 access credentials using an IAM Assumed Role (3.1.221+)
            ```sql
            CREATE CATALOG paimon_hms_on_s3_iamrole PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'hms',
                'warehouse' = 's3://bucket/warehouse',
                'hive.metastore.uris' = 'thrift://127.0.0.1:9383',
                's3.region' = 'us-east-1',
                's3.role_arn' = 'arn:aws:iam::543815668950:role/role'
            );
            ```
        </TabItem>
        <TabItem value='OSS' label='OSS'>
            ```sql
            CREATE CATALOG test_paimon_on_hms_ali_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'hms',
                'hive.metastore.uris' = 'thrift://127.0.0.1:9383',
                'warehouse' = 'oss://bucket/regression/paimon_warehouse',
                'oss.region' = 'cn-beijing',
                'oss.endpoint' = 'oss-cn-beijing.aliyuncs.com',
                'oss.access_key' = '<ak>',
                'oss.secret_key' = '<sk>'
            );
            ```

        </TabItem>
        <TabItem value='COS' label='COS'>
            ```sql
            CREATE CATALOG test_paimon_on_hms_tx_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'hms',
                'warehouse' = 'cosn://bucket/paimon_warehouse',
                'hive.metastore.uris' = 'thrift://127.0.0.1:9383',
                'cos.region' = 'ap-beijing',
                'cos.endpoint' = 'cos.ap-beijing.myqcloud.com',
                'cos.access_key' = '<ak>',
                'cos.secret_key' = '<sk>'
            );
            ```
        </TabItem>
        <TabItem value='OBS' label='OBS'>
            ```sql
            CREATE CATALOG test_paimon_on_hms_hw_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'hms',
                'warehouse' = 'obs://bucket/regression/paimon_warehouse',
                'hive.metastore.uris' = 'thrift://127.0.0.1:9383',
                'obs.region' = 'cn-north-4',
                'obs.endpoint' = 'obs.cn-north-4.myhuaweicloud.com',
                'obs.access_key' = '<ak>',
                'obs.secret_key' = '<sk>'
            );
            ```
        </TabItem>
        <TabItem value='GCS' label='GCS'>
            ```sql
            CREATE CATALOG `paimon_on_gcs` PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'hms',
                'warehouse' = 'gs://bucket/paimon_warehouse',
                'hive.metastore.uris' = 'thrift://127.0.0.1:9383',
                'fs.gcs.support' = 'true',
                'gs.secret_key' = '<sk>',
                'gs.access_key' = '<ak>'
            );
            ```
        </TabItem>
        <TabItem value='MinIO' label='MinIO'>
            ```sql
            CREATE CATALOG paimon_hms_on_minio_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'hms',
                'warehouse' = 's3://test-bucket/paimon-warehouse',
                'hive.metastore.uris' = 'thrift://127.0.0.1:9383',
                'fs.minio.support' = 'true',
                'minio.endpoint' = 'http://127.0.0.1:19000',
                'minio.access_key' = 'minioadmin',
                'minio.secret_key' = 'minioadmin',
                'minio.use_path_style' = 'true'
            );
            ```
        </TabItem>
    </Tabs>
</details>

<details >
    <summary>Version 2.1 & 3.0</summary>
    <Tabs>
        <TabItem value='HDFS' label='HDFS' default>
            Access HMS without Kerberos authentication
            ```sql
            CREATE CATALOG paimon_hms_on_hdfs_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'hms',
                'hive.metastore.uris' = 'thrift://127.0.0.1:9383',
                'warehouse' = 'hdfs://127.0.0.1:8320/user/paimon/warehouse/paimon-hms-hdfs-warehouse',
                'hadoop.username' = 'doris',
                'fs.defaultFS' = 'hdfs://127.0.0.1:8320'
            );
            ```
            Access HMS with Kerberos authentication enabled
            ```sql
            CREATE CATALOG paimon_hms_on_hdfs_kerberos_hdfs_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'hms',
                'warehouse' = 'hdfs://127.0.0.1:8520/paimon-hms-hdfs-warehouse',
                'hive.metastore.uris' = 'thrift://127.0.0.1:9583',
                'hive.metastore.kerberos.principal' = 'hive/hadoop-master@LABS.TERADATA.COM',
                'hive.metastore.sasl.enabled ' = 'true',
                'fs.defaultFS' = 'hdfs://127.0.0.1:8520',
                'hadoop.security.auth_to_local' = 'RULE:[2:\$1@\$0](.*@LABS.TERADATA.COM)s/@.*//
                RULE:[2:\$1@\$0](.*@OTHERLABS.TERADATA.COM)s/@.*//
                RULE:[2:\$1@\$0](.*@OTHERREALM.COM)s/@.*//
                DEFAULT',
                'hadoop.security.authentication' = 'kerberos',
                'hadoop.kerberos.principal'='hive/presto-master.docker.cluster@LABS.TERADATA.COM',
                'hadoop.kerberos.keytab' = '/keytabs/hive-presto-master.keytab'
            );
            ```
        </TabItem>
        <TabItem value='S3' label='S3'>
            ```sql
            CREATE CATALOG test_paimon_on_hms_aws_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'hms',
                'warehouse' = 's3://bucket-hk/paimon_warehouse',
                'hive.metastore.uris' = 'thrift://127.0.0.1:9383',
                's3.region' = 'ap-east-1',
                'paimon.s3.region' = 'ap-east-1',
                's3.endpoint' = 's3.ap-east-1.amazonaws.com',
                'paimon.s3.endpoint' = 'ap-east-1',
                's3.access_key' = '<ak>',
                'paimon.s3.access-key' = '<ak>',
                's3.secret_key' = '<sk>',
                'paimon.s3.secret-key' = '<sk>'    
            );
            ```
        </TabItem>
        <TabItem value='OSS' label='OSS'>
            ```sql
            CREATE CATALOG test_paimon_on_hms_ali_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'hms',
                'warehouse' = 'oss://bucket/regression/paimon_warehouse',
                'hive.metastore.uris' = 'thrift://127.0.0.1:9383',
                'oss.region' = 'cn-beijing',
                'oss.endpoint' = 'oss-cn-beijing.aliyuncs.com',
                'oss.access_key' = '<ak>',
                'oss.secret_key' = '<sk>'
            );
            ```
        </TabItem>
        <TabItem value='COS' label='COS'>
            ```sql
            CREATE CATALOG test_paimon_on_hms_tx_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'hms',
                'warehouse' = 'cosn://bucket/paimon_warehouse',
                'hive.metastore.uris' = 'thrift://127.0.0.1:9383',
                'cos.region' = 'ap-beijing',
                'cos.endpoint' = 'cos.ap-beijing.myqcloud.com',
                'cos.access_key' = '<ak>',
                'cos.secret_key' = '<sk>'
            );
            ```
        </TabItem>
        <TabItem value='OBS' label='OBS'>
            ```sql
            CREATE CATALOG test_paimon_on_hms_hw_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'hms',
                'warehouse' = 'obs://bucket/regression/paimon_warehouse',
                'hive.metastore.uris' = 'thrift://127.0.0.1:9383',
                'obs.region' = 'cn-north-4',
                'obs.endpoint' = 'obs.cn-north-4.myhuaweicloud.com',
                'obs.access_key' = '<ak>',
                'obs.secret_key' = '<sk>'
            );
            ```
        </TabItem>
        <TabItem value='MinIO' label='MinIO'>
            ```sql
            CREATE CATALOG test_paimon_on_hms_minio_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'hms',
                'warehouse' = 's3://bucket/paimon-warehouse',
                'hive.metastore.uris' = 'thrift://127.0.0.1:9383',
                's3.endpoint' = 'http://127.0.0.1:19000',
                'paimon.s3.endpoint' = 'http://127.0.0.1:19000',
                's3.access_key' = '<ak>',
                'paimon.s3.access-key' = '<ak>',
                's3.secret_key' = '<sk>',
                'paimon.s3.secret-key' = '<sk>',    
                's3.path.style.access' = 'true'
            );
            ```
        </TabItem>
    </Tabs>
</details>

### Aliyun DLF Metastore
<details>
    <summary>Version 3.1+</summary>
    <Tabs>
        <TabItem value='DLF 1.0' label='DLF 1.0' default>
            ```sql
            CREATE CATALOG paimon_dlf_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'dlf',
                'warehouse' = 'oss://bucket/p2_regression_case',
                'dlf.uid' = '772905',
                'dlf.catalog_id' = 'p2_regression_case',
                'dlf.region' = 'cn-beijing',
                'dlf.endpoint' = 'dlf.cn-beijing.aliyuncs.com',
                'dlf.access_key' = '<ak>',
                'dlf.secret_key' = '<sk>'
            );
            ```
        </TabItem>
        <TabItem value='DLF(2.5+)' label='DLF(2.5+)'>
            ``` sql
            CREATE CATALOG paimon_dlf_test PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'rest',
                'uri' = 'http://cn-beijing-vpc.dlf.aliyuncs.com',
                'warehouse' = 'new_dfl_paimon_catalog',
                'paimon.rest.token.provider' = 'dlf',
                'paimon.rest.dlf.access-key-id' = '<ak>',
                'paimon.rest.dlf.access-key-secret' = '<sk>'
            );
            ```
        </TabItem>
    </Tabs>


</details>

<details >
    <summary>Version 2.1 & 3.0</summary>

    <Tabs>
        <TabItem value='DLF 1.0' label='DLF 1.0' default>
            ```sql
            CREATE CATALOG paimon_dlf_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'dlf',
                'warehouse' = 'oss://bucket/paimon-dlf-oss-warehouse',
                'dlf.uid' = '7716890',
                'dlf.catalog.id' = 'p2_regression_case',
                'dlf.region' = 'cn-beijing',
                'dlf.endpoint' = 'dlf.cn-beijing.aliyuncs.com',
                'dlf.access_key' = '<ak>',
                'dlf.secret_key' = '<sk>'
            );
            ```
        </TabItem>

    </Tabs>
</details>

### FileSystem Metastore

<details>
    <summary>Version 3.1+</summary>
    <Tabs>
        <TabItem value='HDFS' label='HDFS' default>
            Access HMS and HDFS services without Kerberos authentication
            ```sql
            CREATE CATALOG ctl_test_paimon_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'filesystem',
                'warehouse' = 'hdfs://127.0.0.1:8020/user/doris/paimon1',
                'fs.defaultFS' = 'hdfs://127.0.0.1:8020'
            );
            ```
        </TabItem>
        <TabItem value='S3' label='S3'>
            ```sql
            CREATE CATALOG test_paimon_on_fs_aws_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'filesystem',
                'warehouse' = 's3://bucket/paimon_warehouse',
                's3.region' = 'ap-east-1',
                's3.endpoint' = 's3.ap-east-1.amazonaws.com',
                's3.access_key' = '<ak>',
                's3.secret_key' = '<sk>'
            );
            ```
            Obtaining S3 access credentials using an IAM Assumed Role (3.1.2+)
            ```sql
            CREATE CATALOG paimon_fs_on_s3_iamrole PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'filesystem',
                'warehouse' = 's3://bucket/warehouse',
                's3.region' = 'us-east-1',
                's3.role_arn' = 'arn:aws:iam::543815668950:role/role'
            );
            ``` 
        </TabItem>
        <TabItem value='OSS' label='OSS'>
            Use OSS

            ```sql
            CREATE CATALOG paimon_base_filesystem_paimon_oss PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'filesystem',
                'warehouse' = 'oss://bucket/regression/paimon1',
                'oss.region'='cn-beijing',
                'oss.endpoint'='oss-cn-beijing.aliyuncs.com',
                'oss.access_key'='<ak>',
                'oss.secret_key'='<sk>'
            );
            ```

            Use OSS-HDFS

            ```sql
            CREATE CATALOG paimon_base_filesystem_paimon_oss_hdfs PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'filesystem',
                'warehouse' = 'oss://bucket/regression/paimon1',
                'fs.oss-hdfs.support' = 'true',
                'oss.hdfs.access_key' = '<ak>',
                'oss.hdfs.secret_key' = '<sk>',
                'oss.hdfs.endpoint' = 'cn-beijing.oss-dls.aliyuncs.com',
                'oss.hdfs.region' = 'cn-beijing'
            );
            ```
        </TabItem>
        <TabItem value='COS' label='COS'>
            ```sql
            CREATE CATALOG paimon_base_filesystem_paimon_cosn PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'filesystem',
                'warehouse' = 'cosn://bucket/regression/paimon1',
                'cos.region' = 'ap-beijing',
                'cos.endpoint' = 'cos.ap-beijing.myqcloud.com',
                'cos.access_key' = '<ak>',
                'cos.secret_key' = '<sk>'
            );
            ```
        </TabItem>
        <TabItem value='OBS' label='OBS'>
            ```sql
            CREATE CATALOG paimon_base_filesystem_paimon_obs PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'filesystem',
                'warehouse' = 'obs://bucket/regression/paimon1',
                'obs.region' = 'cn-north-4',
                'obs.endpoint' = 'obs.cn-north-4.myhuaweicloud.com',
                'obs.access_key' = '<ak>',
                'obs.secret_key' = '<sk>'
            );
            ```
        </TabItem>
        <TabItem value='GCS' label='GCS'>
            ```sql
            CREATE CATALOG paimon_on_gcs_s3_fs PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'filesystem',
                'warehouse' = 's3://bucket/paimon_warehouse',
                'fs.gcs.support' = 'true',
                'gs.secret_key' = '<sk>',
                'gs.access_key' = '<ak>'
            );
            ```
        </TabItem>
        <TabItem value='MinIO' label='MinIO'>
            ```sql
            CREATE CATALOG test_paimon_minio_minio PROPERTIES (
                'type' = 'paimon',
                'warehouse' = 's3://warehouse/wh',
                'fs.minio.support' = 'true',
                'minio.endpoint' = 'http://127.0.0.1:19001',
                'minio.access_key' = 'admin',
                'minio.secret_key' = 'password',
                'minio.use_path_style' = 'true'
            );
            ```
        </TabItem>
    </Tabs>
</details>

<details>
    <summary>Version 2.1 & 3.0</summary>
    <Tabs>
        <TabItem value='HDFS' label='HDFS' default>
            Access HMS and HDFS services without Kerberos authentication
            ```sql
            CREATE CATALOG ctl_test_paimon_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'filesystem',
                'warehouse' = 'hdfs://127.0.0.1:8020/user/doris/paimon1',
                'fs.defaultFS' = 'hdfs://127.0.0.1:8020'
            );
            ```
        </TabItem>
        <TabItem value='S3' label='S3'>
            ```sql
            CREATE CATALOG test_paimon_on_fs_aws_catalog PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'filesystem',
                'warehouse' = 's3://bucket/paimon_warehouse',
                's3.region' = 'ap-east-1',
                's3.endpoint' = 's3.ap-east-1.amazonaws.com',
                's3.access_key' = '<ak>',
                's3.secret_key' = '<sk>'
            );
            ```
        </TabItem>
        <TabItem value='OSS' label='OSS'>
            Use OSS

            ```sql
            CREATE CATALOG paimon_base_filesystem_paimon_oss PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'filesystem',
                'warehouse' = 'oss://bucket/regression/paimon1',
                'oss.region'='cn-beijing',
                'oss.endpoint'='oss-cn-beijing.aliyuncs.com',
                'oss.access_key'='<ak>',
                'oss.secret_key'='<sk>'
            );
            ```

            Use OSS-HDFS

            ```sql
            CREATE CATALOG paimon_base_filesystem_paimon_oss_hdfs PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'filesystem',
                'warehouse' = 'oss://bucket/regression/paimon1',
                'oss.hdfs.enabled' = 'true',
                'oss.access_key' = 'your-access-key',
                'oss.secret_key' = 'your-secret-key',
                'oss.endpoint' = 'cn-hangzhou.oss-dls.aliyuncs.com',
                'oss.region' = 'cn-hangzhou'
            );
            ```
        </TabItem>
        <TabItem value='COS' label='COS'>
            ```sql
            CREATE CATALOG paimon_base_filesystem_paimon_cosn PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'filesystem',
                'warehouse' = 'cosn://bucket/regression/paimon1',
                'cos.region' = 'ap-beijing',
                'cos.endpoint' = 'cos.ap-beijing.myqcloud.com',
                'cos.access_key' = '<ak>',
                'cos.secret_key' = '<sk>'
            );
            ```
        </TabItem>
        <TabItem value='OBS' label='OBS'>
            ```sql
            CREATE CATALOG paimon_base_filesystem_paimon_obs PROPERTIES (
                'type' = 'paimon',
                'paimon.catalog.type' = 'filesystem',
                'warehouse' = 'obs://bucket/regression/paimon1',
                'obs.region' = 'cn-north-4',
                'obs.endpoint' = 'obs.cn-north-4.myhuaweicloud.com',
                'obs.access_key' = '<ak>',
                'obs.secret_key' = '<sk>'
            );
            ```
        </TabItem>
        <TabItem value='MinIO' label='MinIO'>
            ```sql
            CREATE CATALOG paimon_base_filesystem_paimon_minio PROPERTIES (
                'type' = 'paimon',
                'warehouse' = 's3://warehouse/wh',
                'paimon.catalog.type' = 'filesystem',
                's3.endpoint' = 'http://127.0.0.1:19001',
                's3.access_key' = '<ak>',
                's3.secret_key' = '<sk>',
                's3.path.style.access' = 'true'
            );
            ```
        </TabItem>
    </Tabs>
</details>

## Query Operations

### Basic Query

Once the Catalog is configured, you can query the table data in the Catalog as follows:

```sql
-- 1. Switch to catalog, use database, and query
SWITCH paimon_ctl;
USE paimon_db;
SELECT * FROM paimon_tbl LIMIT 10;

-- 2. Use Paimon database directly
USE paimon_ctl.paimon_db;
SELECT * FROM paimon_tbl LIMIT 10;

-- 3. Use fully qualified name to query
SELECT * FROM paimon_ctl.paimon_db.paimon_tbl LIMIT 10;
```

### Batch Incremental Query

> Since version 3.1.0

Supports [Batch Incremental](https://paimon.apache.org/docs/master/flink/sql-query/#batch-incremental) queries for Paimon, similar to Flink.

Supports querying incremental data within specified snapshot or timestamp intervals. The interval is left-closed and right-open.

```sql
-- between snapshots [0, 5)
SELECT * FROM paimon_table@incr('startSnapshotId'='0', 'endSnapshotId'='5');

-- between snapshots [0, 5) with specified scan mode
SELECT * FROM paimon_table@incr('startSnapshotId'='0', 'endSnapshotId'='5', 'incrementalBetweenScanMode'='diff');

-- read from start timestamp
SELECT * FROM paimon_table@incr('startTimestamp'='1750844949000');

-- read between timestamp
SELECT * FROM paimon_table@incr('startTimestamp'='1750844949000', 'endTimestamp'='1750944949000');
```

Parameter:

| Parameter | Description | Example |
| --- | --- | -- |
| `startSnapshotId` | Starting snapshot ID, must be greater than 0. Must be specified with `endSnapshotId` together. | `'startSnapshotId'='3'` |
| `endSnapshotId` | Ending snapshot ID, must be greater than `startSnapshotId`. Must be specified with `startSnapshotId` together. | `'endSnapshotId'='10'` |
| `incrementalBetweenScanMode` | Specifies the incremental read mode, default is `auto`, supports `delta`, `changelog` and `diff` |  `'incrementalBetweenScanMode'='delta'` |
| `startTimestamp` | Starting snapshot timestamp, must be greater than or equal to 0. Unit is millisecond. | `'startTimestamp'='1750844949000'` |
| `endTimestamp` | Ending snapshot timestamp, must be greater than `startTimestamp`. Optional, if not specified, reads from `startTimestamp` to the latest snapshot. Unit is millisecond. | `'endTimestamp'='1750944949000'` |

> Notice:
>
> `startSnapshotId` and `endSnapshotId` will compose the Paimon parameter `'incremental-between'='3,10'`
>
> `startTimestamp` and `endTimestamp` will compose the Paimon parameter `'incremental-between-timestamp'='1750844949000,1750944949000'`
>
> `incrementalBetweenScanMode` corresponds to the Paimon parameter `incremental-between-scan-mode`.

Refer to the [Paimon documentation](https://paimon.apache.org/docs/master/maintenance/configurations/) for further details about these parameters.

### Time Travel

> Since version 3.1.0

Supports reading specified snapshots of Paimon tables.

By default, read requests only read the latest version of snapshots.

You can query snapshots of a specified Paimon table through the `$snapshots` table function:

```sql
Doris > SELECT snapshot_id,commit_time FROM paimon_tbl$snapshots;
+-------------+-------------------------+
| snapshot_id | commit_time             |
+-------------+-------------------------+
|           1 | 2025-08-17 06:05:52.740 |
|           2 | 2025-08-17 06:05:52.979 |
|           3 | 2025-08-17 06:05:53.240 |
|           4 | 2025-08-17 06:05:53.561 |
+-------------+-------------------------+
```

You can use `FOR TIME AS OF` and `FOR VERSION AS OF` statements to read historical version data based on snapshot ID or the time when the snapshot was created. Examples:

```sql
-- Notice:
-- Before 3.1.1, only support format like YYYY-MM-DD HH:MM:SS.SSS
-- After 3.1.2, support YYYY-MM-DD HH:MM:SS and YYYY-MM-DD
SELECT * FROM paimon_tbl FOR TIME AS OF "2025-08-17 06:05:52.740";
SELECT * FROM paimon_tbl FOR TIME AS OF "2025-08-17 06:05:52";
SELECT * FROM paimon_tbl FOR TIME AS OF "2025-08-17";

-- Notice: The timestamp must be precise down to the millisecond.
SELECT * FROM paimon_tbl FOR TIME AS OF 1755381952740;
-- Use snapshot id
SELECT * FROM paimon_tbl FOR VERSION AS OF 1;
```

### Branch and Tag

> Since version 3.1.0

Supports reading branches and tags of specified Paimon tables.

You can use the `$branches` and `$tags` system tables to view branches and tags of Paimon tables:

```
Doris > SELECT * FROM paimon_tbl$branches;
+-------------+-------------------------+
| branch_name | create_time             |
+-------------+-------------------------+
| b_1         | 2025-08-17 06:34:37.294 |
| b_2         | 2025-08-17 06:34:37.297 |
+-------------+-------------------------+

Doris > SELECT * FROM paimon_tbl$tags;
+----------+-------------+-----------+-------------------------+--------------+-------------+---------------+
| tag_name | snapshot_id | schema_id | commit_time             | record_count | create_time | time_retained |
+----------+-------------+-----------+-------------------------+--------------+-------------+---------------+
| t_1      |           1 |         0 | 2025-08-17 06:05:52.740 |            3 | NULL        | NULL          |
| t_2      |           2 |         0 | 2025-08-17 06:05:52.979 |            6 | NULL        | NULL          |
| t_3      |           3 |         0 | 2025-08-17 06:05:53.240 |            9 | NULL        | NULL          |
| t_4      |           4 |         0 | 2025-08-17 06:05:53.561 |           12 | NULL        | NULL          |
+----------+-------------+-----------+-------------------------+--------------+-------------+---------------+
```

Supports various syntax forms to be compatible with systems like Spark/Trino:

```sql
-- BRANCH
SELECT * FROM paimon_tbl@branch(branch1);
SELECT * FROM paimon_tbl@branch("name" = "branch1");

-- TAG
SELECT * FROM paimon_tbl@tag(tag1);
SELECT * FROM paimon_tbl@tag("name" = "tag1");
SELECT * FROM paimon_tbl FOR VERSION AS OF 'tag1';
```

For the `FOR VERSION AS OF` syntax, Doris will automatically determine whether the parameter is a timestamp

## System Tables

> Since version 3.1.0

Doris supports querying Paimon system tables to retrieve table-related metadata. System tables can be used to view snapshot history, manifest files, data files, partitions, and other information.

To access metadata of a Paimon table, add a `$` symbol after the table name, followed by the system table name:

```sql
SELECT * FROM my_table$system_table_name;
```

> Note: Doris does not support reading Paimon global system tables, which are only supported in Flink.


### schemas

Shows current and historical schema information of the table. When modifying table schema using `ALTER TABLE`, `CREATE TABLE AS`, or `CREATE DATABASE AS` statements, each modification generates a record in the schemas table:

```sql
SELECT * FROM my_table$schemas;
```

Result:
```text
+-----------+--------------------------------------------------------------------------------------------------------------------+----------------+--------------+---------+---------+-------------------------+
| schema_id | fields                                                                                                             | partition_keys | primary_keys | options | comment | update_time             |
+-----------+--------------------------------------------------------------------------------------------------------------------+----------------+--------------+---------+---------+-------------------------+
|         0 | [{"id":0,"name":"k","type":"INT NOT NULL"},{"id":1,"name":"f0","type":"INT"},{"id":2,"name":"f1","type":"STRING"}] | []             | ["k"]        | {}      |         | 2025-03-04 22:48:41.666 |
+-----------+--------------------------------------------------------------------------------------------------------------------+----------------+--------------+---------+---------+-------------------------+
```

### snapshots

Shows all valid snapshot information of the table, including snapshot creation time, commit user, operation type, etc.:

```sql
SELECT * FROM my_table$snapshots;
```

Result:
```text
+-------------+-----------+--------------------------------------+---------------------+-------------+-------------------------+------------------------------------------------------+------------------------------------------------------+-------------------------+--------------------+--------------------+------------------------+----------------------+
| snapshot_id | schema_id | commit_user                          | commit_identifier   | commit_kind | commit_time             | base_manifest_list                                   | delta_manifest_list                                  | changelog_manifest_list | total_record_count | delta_record_count | changelog_record_count | watermark            |
+-------------+-----------+--------------------------------------+---------------------+-------------+-------------------------+------------------------------------------------------+------------------------------------------------------+-------------------------+--------------------+--------------------+------------------------+----------------------+
|           1 |         0 | d7ea4996-92c7-469f-b9ff-c76525954f1c | 9223372036854775807 | APPEND      | 2025-03-04 22:48:45.575 | manifest-list-dc5490ba-420c-445a-b6f7-6962d394935c-0 | manifest-list-dc5490ba-420c-445a-b6f7-6962d394935c-1 | NULL                    |                  1 |                  1 |                      0 | -9223372036854775808 |
|           2 |         0 | 34de47f6-31d1-4f06-b378-c85ef4fbca41 | 9223372036854775807 | APPEND      | 2025-07-01 23:11:35.406 | manifest-list-dca6aa5b-6fc6-4b4f-ac22-acfa15bbf171-0 | manifest-list-dca6aa5b-6fc6-4b4f-ac22-acfa15bbf171-1 | NULL                    |                  2 |                  1 |                      0 | -9223372036854775808 |
|           3 |         0 | 89f67183-a1f8-4ee9-b73c-3f7e992b79a7 | 9223372036854775807 | APPEND      | 2025-07-01 23:11:45.114 | manifest-list-6d624d1b-c774-4d95-905e-8258a7b89ecb-0 | manifest-list-6d624d1b-c774-4d95-905e-8258a7b89ecb-1 | NULL                    |                  3 |                  1 |                      0 | -9223372036854775808 |
|           4 |         0 | 31924a7c-1389-490c-adf1-3bb805b33cd7 | 9223372036854775807 | APPEND      | 2025-07-01 23:12:42.042 | manifest-list-09097a51-afde-485e-929b-d2cc39eb6eb2-0 | manifest-list-09097a51-afde-485e-929b-d2cc39eb6eb2-1 | NULL                    |                  5 |                  2 |                      0 | -9223372036854775808 |
|           5 |         0 | 1e90a80b-41cb-4242-b97c-889728f76810 | 9223372036854775807 | APPEND      | 2025-07-01 23:14:26.445 | manifest-list-b8471969-9c4d-41cd-b790-64f6efb2d142-0 | manifest-list-b8471969-9c4d-41cd-b790-64f6efb2d142-1 | NULL                    |                  6 |                  1 |                      0 | -9223372036854775808 |
|           6 |         0 | 1e90a80b-41cb-4242-b97c-889728f76810 | 9223372036854775807 | COMPACT     | 2025-07-01 23:14:29.317 | manifest-list-b8471969-9c4d-41cd-b790-64f6efb2d142-2 | manifest-list-b8471969-9c4d-41cd-b790-64f6efb2d142-3 | NULL                    |                  5 |                 -1 |                      0 | -9223372036854775808 |
+-------------+-----------+--------------------------------------+---------------------+-------------+-------------------------+------------------------------------------------------+------------------------------------------------------+-------------------------+--------------------+--------------------+------------------------+----------------------+
```

### options

Shows current configuration options of the table. If a table option is not included in the table, that option is set to its default value:

```sql
SELECT * FROM my_table$options;
```

Result:
```text
+------------------------+--------------------+
|         key            |        value       |
+------------------------+--------------------+
| snapshot.time-retained |         5 h        |
+------------------------+--------------------+
```

### files

Shows information about all data files pointed to by the current snapshot, including file format, record count, file size, etc.:

```sql
SELECT * FROM my_table$files;
```

Result:
```text
mysql> SELECT * FROM my_table$files;
+-----------+--------+------------------------------------------------------------------------------------------------------------------------+-------------+-----------+-------+--------------+--------------------+---------+---------+-------------------+---------------------+---------------------+---------------------+---------------------+-------------------------+-------------+
| partition | bucket | file_path                                                                                                              | file_format | schema_id | level | record_count | file_size_in_bytes | min_key | max_key | null_value_counts | min_value_stats     | max_value_stats     | min_sequence_number | max_sequence_number | creation_time           | file_source |
+-----------+--------+------------------------------------------------------------------------------------------------------------------------+-------------+-----------+-------+--------------+--------------------+---------+---------+-------------------+---------------------+---------------------+---------------------+---------------------+-------------------------+-------------+
| {}        |      0 | s3://paimon-warehouse-dev/test-flink/cookbook.db/my_table/bucket-0/data-b4a49c57-6ef6-4c04-8813-07a4960d987c-0.parquet | parquet     |         0 |     5 |            5 |               1321 | [1]     | [6]     | {f0=0, f1=0, k=0} | {f0=4, f1=111, k=1} | {f0=11, f1=k7, k=6} |                   0 |                   5 | 2025-07-01 23:14:23.967 | COMPACT     |
+-----------+--------+------------------------------------------------------------------------------------------------------------------------+-------------+-----------+-------+--------------+--------------------+---------+---------+-------------------+---------------------+---------------------+---------------------+---------------------+-------------------------+-------------+
```

### tags

Shows all tag information of the table, including tag names and associated snapshots:

```sql
SELECT * FROM my_table$tags;
```

Result:
```text
+----------+-------------+-----------+-------------------------+--------------+--------------+
| tag_name | snapshot_id | schema_id |             commit_time | record_count |   branches   |
+----------+-------------+-----------+-------------------------+--------------+--------------+
|     tag1 |           1 |         0 | 2025-03-04 14:55:29.344 |            3 |      []      |
|     tag3 |           3 |         0 | 2025-03-04 14:58:24.691 |            7 |  [branch-1]  |
+----------+-------------+-----------+-------------------------+--------------+--------------+
```

### branches

Shows all known branch information of the table:

```sql
SELECT * FROM my_table$branches;
```

Result:
```text
+----------------------+-------------------------+
|          branch_name |             create_time |
+----------------------+-------------------------+
|              branch1 | 2025-03-04 20:31:39.084 |
|              branch2 | 2025-03-04 21:11:14.373 |
+----------------------+-------------------------+
```

### consumers

Shows consumer information of the table, used to track data consumption:

```sql
SELECT * FROM my_table$consumers;
```

Result:
```text
+-------------+------------------+
| consumer_id | next_snapshot_id |
+-------------+------------------+
|         id1 |                1 |
|         id2 |                3 |
+-------------+------------------+
```

### manifests

Shows manifest file information of the table's current snapshot:

```sql
SELECT * FROM my_table$manifests;
```

Result:
```text
+-------------------------------------------------+-----------+-----------------+-------------------+-----------+---------------------+---------------------+
| file_name                                       | file_size | num_added_files | num_deleted_files | schema_id | min_partition_stats | max_partition_stats |
+-------------------------------------------------+-----------+-----------------+-------------------+-----------+---------------------+---------------------+
| manifest-3df9bb64-5c11-4aef-994e-d8717fedfc70-0 |      1949 |               1 |                 0 |         0 | {}                  | {}                  |
| manifest-d7eb4ec4-7238-478a-9ae6-91a4ccebd561-0 |      1946 |               1 |                 0 |         0 | {}                  | {}                  |
| manifest-3b6f4079-c893-4413-aedc-1e8fbcea6db1-0 |      1948 |               1 |                 0 |         0 | {}                  | {}                  |
| manifest-abe5177f-82da-4e86-9864-40efffb391bd-0 |      1964 |               1 |                 0 |         0 | {}                  | {}                  |
| manifest-ee89dff3-a523-4655-a4b8-d7c9e471a1d6-0 |      1949 |               1 |                 0 |         0 | {}                  | {}                  |
| manifest-ee89dff3-a523-4655-a4b8-d7c9e471a1d6-1 |      2232 |               1 |                 5 |         0 | {}                  | {}                  |
+-------------------------------------------------+-----------+-----------------+-------------------+-----------+---------------------+---------------------+
```

### aggregation_fields

Shows aggregation field information of the table, used for field configuration in aggregate tables:

```sql
SELECT * FROM my_table$aggregation_fields;
```

Result:
```text
+------------+--------------+----------+------------------+---------+
| field_name | field_type   | function | function_options | comment |
+------------+--------------+----------+------------------+---------+
| k          | INT NOT NULL | []       | []               | NULL    |
| f0         | INT          | []       | []               | NULL    |
| f1         | STRING       | []       | []               | NULL    |
+------------+--------------+----------+------------------+---------+
```

### partitions

Shows partition information of the table, including total record count and total file size for each partition:

```sql
SELECT * FROM my_table$partitions;
```

Result:
```text
+-----------+--------------+--------------------+------------+-------------------------+
| partition | record_count | file_size_in_bytes | file_count | last_update_time        |
+-----------+--------------+--------------------+------------+-------------------------+
| {}        |            5 |               1321 |          1 | 2025-07-01 23:14:23.967 |
+-----------+--------------+--------------------+------------+-------------------------+
```

### buckets

Shows bucket information of the table, including statistics for each bucket:

```sql
SELECT * FROM my_table$buckets;
```

Result:
```text
+-----------+--------+--------------+--------------------+------------+-------------------------+
| partition | bucket | record_count | file_size_in_bytes | file_count | last_update_time        |
+-----------+--------+--------------+--------------------+------------+-------------------------+
| {}        |      0 |            5 |               1321 |          1 | 2025-07-01 23:14:23.967 |
+-----------+--------+--------------+--------------------+------------+-------------------------+
```

### statistics

Shows statistical information of the table, including row count, data size, and other statistics:

```sql
SELECT * FROM my_table$statistics;
```

Result:
```text
+--------------+------------+-----------------------+------------------+----------+
|  snapshot_id |  schema_id |     mergedRecordCount | mergedRecordSize |  colstat |
+--------------+------------+-----------------------+------------------+----------+
|            2 |          0 |              2        |         2        |    {}    |
+--------------+------------+-----------------------+------------------+----------+
```

### table_indexes

Shows index information of the table:

```sql
SELECT * FROM my_table$table_indexes;
```

Result:
```text
+--------------------------------+-------------+--------------------------------+--------------------------------+----------------------+----------------------+--------------------------------+
|                      partition |      bucket |                     index_type |                      file_name |            file_size |            row_count |                      dv_ranges |
+--------------------------------+-------------+--------------------------------+--------------------------------+----------------------+----------------------+--------------------------------+
|                   {2025-03-01} |           0 |                           HASH | index-70abfebf-149e-4796-9f... |                   12 |                    3 |                         <NULL> |
|                   {2025-04-01} |           0 |               DELETION_VECTORS | index-633857e7-cdce-47d2-87... |                   33 |                    1 | [(data-346cb9c8-4032-4d66-a... |
+--------------------------------+-------------+--------------------------------+--------------------------------+----------------------+----------------------+--------------------------------+
```

### System Table Use Cases

Through system tables, you can easily accomplish the following operations and monitoring tasks.

#### View the latest snapshot information of a table to understand its current state

```sql
SELECT snapshot_id, commit_time, commit_kind, total_record_count FROM catalog_sales$snapshots ORDER BY snapshot_id DESC;
```
Result:

```text
+-------------+-------------------------+-------------+--------------------+
| snapshot_id | commit_time             | commit_kind | total_record_count |
+-------------+-------------------------+-------------+--------------------+
|           1 | 2025-07-01 21:21:54.179 | APPEND      |           14329288 |
+-------------+-------------------------+-------------+--------------------+
```

#### View table information for snapshots

```sql
SELECT s.snapshot_id, t.schema_id, t.fields FROM store_sales$snapshots s JOIN store_sales$schemas t ON s.schema_id=t.schema_id;
```

Result:

```text
+-------------+-----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| snapshot_id | schema_id | fields                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
+-------------+-----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|           1 |         0 | [{"id":0,"name":"ss_sold_date_sk","type":"INT"},{"id":1,"name":"ss_item_sk","type":"INT NOT NULL"},{"id":2,"name":"ss_ticket_number","type":"INT NOT NULL"},{"id":3,"name":"ss_sold_time_sk","type":"INT"},{"id":4,"name":"ss_customer_sk","type":"INT"},{"id":5,"name":"ss_cdemo_sk","type":"INT"},{"id":6,"name":"ss_hdemo_sk","type":"INT"},{"id":7,"name":"ss_addr_sk","type":"INT"},{"id":8,"name":"ss_store_sk","type":"INT"},{"id":9,"name":"ss_promo_sk","type":"INT"},{"id":10,"name":"ss_quantity","type":"INT"},{"id":11,"name":"ss_wholesale_cost","type":"DECIMAL(7, 2)"},{"id":12,"name":"ss_list_price","type":"DECIMAL(7, 2)"},{"id":13,"name":"ss_sales_price","type":"DECIMAL(7, 2)"},{"id":14,"name":"ss_ext_discount_amt","type":"DECIMAL(7, 2)"},{"id":15,"name":"ss_ext_sales_price","type":"DECIMAL(7, 2)"},{"id":16,"name":"ss_ext_wholesale_cost","type":"DECIMAL(7, 2)"},{"id":17,"name":"ss_ext_list_price","type":"DECIMAL(7, 2)"},{"id":18,"name":"ss_ext_tax","type":"DECIMAL(7, 2)"},{"id":19,"name":"ss_coupon_amt","type":"DECIMAL(7, 2)"},{"id":20,"name":"ss_net_paid","type":"DECIMAL(7, 2)"},{"id":21,"name":"ss_net_paid_inc_tax","type":"DECIMAL(7, 2)"},{"id":22,"name":"ss_net_profit","type":"DECIMAL(7, 2)"}] |
|           2 |         0 | [{"id":0,"name":"ss_sold_date_sk","type":"INT"},{"id":1,"name":"ss_item_sk","type":"INT NOT NULL"},{"id":2,"name":"ss_ticket_number","type":"INT NOT NULL"},{"id":3,"name":"ss_sold_time_sk","type":"INT"},{"id":4,"name":"ss_customer_sk","type":"INT"},{"id":5,"name":"ss_cdemo_sk","type":"INT"},{"id":6,"name":"ss_hdemo_sk","type":"INT"},{"id":7,"name":"ss_addr_sk","type":"INT"},{"id":8,"name":"ss_store_sk","type":"INT"},{"id":9,"name":"ss_promo_sk","type":"INT"},{"id":10,"name":"ss_quantity","type":"INT"},{"id":11,"name":"ss_wholesale_cost","type":"DECIMAL(7, 2)"},{"id":12,"name":"ss_list_price","type":"DECIMAL(7, 2)"},{"id":13,"name":"ss_sales_price","type":"DECIMAL(7, 2)"},{"id":14,"name":"ss_ext_discount_amt","type":"DECIMAL(7, 2)"},{"id":15,"name":"ss_ext_sales_price","type":"DECIMAL(7, 2)"},{"id":16,"name":"ss_ext_wholesale_cost","type":"DECIMAL(7, 2)"},{"id":17,"name":"ss_ext_list_price","type":"DECIMAL(7, 2)"},{"id":18,"name":"ss_ext_tax","type":"DECIMAL(7, 2)"},{"id":19,"name":"ss_coupon_amt","type":"DECIMAL(7, 2)"},{"id":20,"name":"ss_net_paid","type":"DECIMAL(7, 2)"},{"id":21,"name":"ss_net_paid_inc_tax","type":"DECIMAL(7, 2)"},{"id":22,"name":"ss_net_profit","type":"DECIMAL(7, 2)"}] |
+-------------+-----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
```

#### View data distribution of buckets

```sql
SELECT `bucket` , COUNT(*) as file_count, SUM(file_size_in_bytes)/1024/1024 as total_size_mb from paimon_s3.tpcds.catalog_sales$files GROUP BY `bucket`  ORDER BY total_size_mb;
```
> Note: Many fields in Paimon system tables are keywords in Doris, so they need to be enclosed in backticks.

Result:

```text
+--------+------------+--------------------+
| bucket | file_count | total_size_mb      |
+--------+------------+--------------------+
|     35 |          1 | 12.144722938537598 |
|     81 |          1 | 12.143454551696777 |
|     37 |          1 |  12.14071273803711 |
|     36 |          1 | 12.139023780822754 |
|     63 |          1 | 12.137332916259766 |
|      7 |          1 | 12.122495651245117 |
|     15 |          1 | 12.117934226989746 |
|     11 |          1 | 12.116133689880371 |
|     12 |          1 |  12.11155891418457 |
|     46 |          1 | 12.111005783081055 |
+--------+------------+--------------------+
```

## Appendix

### FAQ

1. `Could not find a file io implementation for scheme 's3a' in the classpath`

    In versions prior to 3.1, when using HMS as metadata storage with 's3a' or 's3' protocol on the storage side, the following error occurs:
    
    ```
    java.io.UncheckedIOException: org.apache.paimon.fs.UnsupportedSchemeException: Could not find a file io implementation for scheme 's3a' in the classpath. Hadoop FileSystem also cannot access this path 's3a://`.
    ```
    **Versions prior to 3.1**
    Versions prior to 3.1 do not support the `s3a` protocol. If you must use it, you can temporarily add the `s3a`-related parameters as a workaround.

    **Version 3.1 and above**
    Starting from version 3.1, explicitly adding `s3a` parameters is no longer necessary. If you need to override Paimon storage parameters, you can add parameters with the `paimon.fs.` prefix. Since Paimon internally uses the HDFS API, all `fs.s3a.*` parameters are supported.

    For example:

    ```sql
    CREATE CATALOG `paimon_hms_on_s3a` PROPERTIES (
        "type" = "paimon",
        "paimon.catalog.type" = "hms",
        "hive.metastore.uris" = "thrift://172.20.48.119:9383"
        "warehouse" = "s3a://bucket/paimon_warehouse",
        "s3.access_key" = "<ak>",
        "s3.secret_key" = "<sk>",
        "s3.region" = "ap-east-1",
        "s3.endpoint" = "s3.ap-east-1.amazonaws.com",
        -- explicitly add s3a parameters
        "fs.s3a.access.key"="<ak>",
        "fs.s3a.secret.key"="<sk>",
        "fs.s3a.endpoint.region"="ap-east-1",
        "fs.s3a.endpoint"="s3.ap-east-1.amazonaws.com",
        "fs.s3a.impl"= "org.apache.hadoop.fs.s3a.S3AFileSystem",
    ); 
    ``` 

    When using the `s3` protocol, you need to explicitly add Paimon S3-related parameters, i.e., add the `paimon.` prefix. For example:

    ```sql
    CREATE CATALOG test_paimon_on_hms_aws_catalog PROPERTIES (
        'type' = 'paimon',
        'paimon.catalog.type' = 'hms',
        'warehouse' = 's3://bucket-hk/paimon_warehouse',
        'hive.metastore.uris' = 'thrift://127.0.0.1:9383',
        's3.region' = 'ap-east-1',
        's3.endpoint' = 's3.ap-east-1.amazonaws.com',
        's3.access_key' = '<ak>',
        's3.secret_key' = '<sk>',
        -- explicitly add s3a parameters
        'paimon.s3.region' = 'ap-east-1',
        'paimon.s3.endpoint' = 'ap-east-1',
        'paimon.s3.access-key' = '<ak>',
        'paimon.s3.secret-key' = '<sk>'
    );
    ```
