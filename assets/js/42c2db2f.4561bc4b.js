"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["485781"],{652:function(e,n,t){t.r(n),t.d(n,{default:()=>h,frontMatter:()=>o,metadata:()=>r,assets:()=>l,toc:()=>a,contentTitle:()=>d});var r=JSON.parse('{"id":"install/preparation/cluster-planning","title":"Cluster Planning","description":"Architecture Planning","source":"@site/docs/install/preparation/cluster-planning.md","sourceDirName":"install/preparation","slug":"/install/preparation/cluster-planning","permalink":"/docs/dev/install/preparation/cluster-planning","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Cluster Planning","language":"en"},"sidebar":"docs","previous":{"title":"Environment Checking","permalink":"/docs/dev/install/preparation/env-checking"},"next":{"title":"OS Checking","permalink":"/docs/dev/install/preparation/os-checking"}}'),i=t("785893"),s=t("250065");let o={title:"Cluster Planning",language:"en"},d=void 0,l={},a=[{value:"Architecture Planning",id:"architecture-planning",level:2},{value:"Port Planning",id:"port-planning",level:2},{value:"Node Count Planning",id:"node-count-planning",level:2},{value:"FE Node Count",id:"fe-node-count",level:3},{value:"BE Node Count",id:"be-node-count",level:3}];function c(e){let n={a:"a",h2:"h2",h3:"h3",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"architecture-planning",children:"Architecture Planning"}),"\n",(0,i.jsx)(n.p,{children:"When deploying Doris, you can choose between the integrated storage-compute architecture or the decoupled storage-compute architecture based on your business needs:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/docs/dev/gettingStarted/what-is-apache-doris#Integrated-Storage-Compute",children:"Integrated Storage-Compute"}),": The integrated storage-compute architecture is easy to deploy, performs excellently, and does not rely on external shared storage devices. It is suitable for business scenarios that do not require extreme elasticity in scaling."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/docs/dev/gettingStarted/what-is-apache-doris#Decoupled-Storage-Compute",children:"Decoupled Storage-Compute"}),": The decoupled storage-compute architecture relies on shared storage and enables elastic scaling of computing resources. It is suitable for business scenarios that require dynamic adjustment of computing resources."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"port-planning",children:"Port Planning"}),"\n",(0,i.jsx)(n.p,{children:"Doris instances communicate over the network, and their proper functioning requires the following ports to be available. Administrators can adjust Doris' port configuration based on the actual environment:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Instance Name"}),(0,i.jsx)(n.th,{children:"Port Name"}),(0,i.jsx)(n.th,{children:"Default Port"}),(0,i.jsx)(n.th,{children:"Communication Direction"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"BE"}),(0,i.jsx)(n.td,{children:"be_port"}),(0,i.jsx)(n.td,{children:"9060"}),(0,i.jsx)(n.td,{children:"FE -> BE"}),(0,i.jsx)(n.td,{children:"Thrift Server port on BE, used to receive requests from FE"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"BE"}),(0,i.jsx)(n.td,{children:"webserver_port"}),(0,i.jsx)(n.td,{children:"8040"}),(0,i.jsx)(n.td,{children:"BE <-> BE"}),(0,i.jsx)(n.td,{children:"HTTP Server port on BE"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"BE"}),(0,i.jsx)(n.td,{children:"heartbeat_service_port"}),(0,i.jsx)(n.td,{children:"9050"}),(0,i.jsx)(n.td,{children:"FE -> BE"}),(0,i.jsx)(n.td,{children:"Heartbeat service port (Thrift) on BE, used to receive heartbeats from FE"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"BE"}),(0,i.jsx)(n.td,{children:"brpc_port"}),(0,i.jsx)(n.td,{children:"8060"}),(0,i.jsx)(n.td,{children:"FE <-> BE, BE <-> BE"}),(0,i.jsx)(n.td,{children:"BRPC port on BE, used for communication between BEs"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"FE"}),(0,i.jsx)(n.td,{children:"http_port"}),(0,i.jsx)(n.td,{children:"8030"}),(0,i.jsx)(n.td,{children:"FE <-> FE, Client <-> FE"}),(0,i.jsx)(n.td,{children:"HTTP Server port on FE"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"FE"}),(0,i.jsx)(n.td,{children:"rpc_port"}),(0,i.jsx)(n.td,{children:"9020"}),(0,i.jsx)(n.td,{children:"BE -> FE, FE <-> FE"}),(0,i.jsx)(n.td,{children:"Thrift Server port on FE, each FE should have the same configuration"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"FE"}),(0,i.jsx)(n.td,{children:"query_port"}),(0,i.jsx)(n.td,{children:"9030"}),(0,i.jsx)(n.td,{children:"Client <-> FE"}),(0,i.jsx)(n.td,{children:"MySQL Server port on FE"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"FE"}),(0,i.jsx)(n.td,{children:"edit_log_port"}),(0,i.jsx)(n.td,{children:"9010"}),(0,i.jsx)(n.td,{children:"FE <-> FE"}),(0,i.jsx)(n.td,{children:"bdbje communication port on FE"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"node-count-planning",children:"Node Count Planning"}),"\n",(0,i.jsx)(n.h3,{id:"fe-node-count",children:"FE Node Count"}),"\n",(0,i.jsx)(n.p,{children:"FE nodes are primarily responsible for user request handling, query parsing and planning, metadata management, and node management."}),"\n",(0,i.jsx)(n.p,{children:"For production clusters, it is generally recommended to deploy at least 3 FE nodes to achieve a high-availability environment. FE nodes are divided into the following two roles:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Follower nodes"}),": Participate in election operations. When the Master node fails, a Follower node will be selected as the new Master."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Observer nodes"}),": Only sync metadata from the Leader node and do not participate in the election. These nodes can be used for horizontal scaling to improve the read service capacity of metadata."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"In general, it is recommended to deploy at least 3 Follower nodes. In high-concurrency scenarios, increasing the number of Observer nodes can help improve the cluster's connection capacity."}),"\n",(0,i.jsx)(n.h3,{id:"be-node-count",children:"BE Node Count"}),"\n",(0,i.jsx)(n.p,{children:"BE nodes are responsible for data storage and computation. In production environments, to ensure data reliability and fault tolerance, 3 copies of data are usually stored. Therefore, it is recommended to deploy at least 3 BE nodes."}),"\n",(0,i.jsx)(n.p,{children:"BE nodes support horizontal scaling, and by increasing the number of BE nodes, the query performance and concurrent processing capabilities of the cluster can be effectively improved."})]})}function h(e={}){let{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},250065:function(e,n,t){t.d(n,{Z:function(){return d},a:function(){return o}});var r=t(667294);let i={},s=r.createContext(i);function o(e){let n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);