"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["526488"],{47373:function(e,i,n){n.r(i),n.d(i,{default:()=>c,frontMatter:()=>a,metadata:()=>r,assets:()=>o,toc:()=>d,contentTitle:()=>l});var r=JSON.parse('{"id":"lakehouse/file-formats/parquet","title":"Parquet | File Formats","description":"This document introduces the support for reading and writing Parquet file formats in Doris. It applies to the following features:","source":"@site/docs/lakehouse/file-formats/parquet.md","sourceDirName":"lakehouse/file-formats","slug":"/lakehouse/file-formats/parquet","permalink":"/docs/dev/lakehouse/file-formats/parquet","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1770477659000,"frontMatter":{"title":"Parquet | File Formats","language":"zh-CN","description":"This document introduces the support for reading and writing Parquet file formats in Doris. It applies to the following features:","sidebar_label":"Parquet"},"sidebar":"docs","previous":{"title":"MinIO","permalink":"/docs/dev/lakehouse/storages/minio"},"next":{"title":"ORC","permalink":"/docs/dev/lakehouse/file-formats/orc"}}'),t=n("785893"),s=n("250065");let a={title:"Parquet | File Formats",language:"zh-CN",description:"This document introduces the support for reading and writing Parquet file formats in Doris. It applies to the following features:",sidebar_label:"Parquet"},l="Parquet",o={},d=[{value:"Supported Compression Formats",id:"supported-compression-formats",level:2},{value:"Parameters",id:"parameters",level:2},{value:"Session Variables",id:"session-variables",level:3},{value:"BE Configuration",id:"be-configuration",level:3}];function u(e){let i={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",ul:"ul",...(0,s.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.header,{children:(0,t.jsx)(i.h1,{id:"parquet",children:"Parquet"})}),"\n",(0,t.jsx)(i.p,{children:"This document introduces the support for reading and writing Parquet file formats in Doris. It applies to the following features:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Reading and writing data in the Catalog."}),"\n",(0,t.jsx)(i.li,{children:"Reading data using Table Valued Functions."}),"\n",(0,t.jsx)(i.li,{children:"Reading data with Broker Load."}),"\n",(0,t.jsx)(i.li,{children:"Writing data during Export."}),"\n",(0,t.jsx)(i.li,{children:"Writing data with Outfile."}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"supported-compression-formats",children:"Supported Compression Formats"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"uncompressed"}),"\n",(0,t.jsx)(i.li,{children:"snappy"}),"\n",(0,t.jsx)(i.li,{children:"lz4"}),"\n",(0,t.jsx)(i.li,{children:"zstd"}),"\n",(0,t.jsx)(i.li,{children:"gzip"}),"\n",(0,t.jsx)(i.li,{children:"lzo"}),"\n",(0,t.jsx)(i.li,{children:"brotli"}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"parameters",children:"Parameters"}),"\n",(0,t.jsx)(i.h3,{id:"session-variables",children:"Session Variables"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.code,{children:"enable_parquet_lazy_mat"})," (2.1+, 3.0+)"]}),"\n",(0,t.jsx)(i.p,{children:"Controls whether the Parquet Reader enables lazy materialization. Default is true."}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.code,{children:"hive_parquet_use_column_names"})," (2.1.6+, 3.0.3+)"]}),"\n",(0,t.jsxs)(i.p,{children:["When reading Parquet data types from Hive tables, Doris will, by default, read data from columns in the Parquet file that have the same name as the columns in the Hive table. When this variable is set to ",(0,t.jsx)(i.code,{children:"false"}),", Doris will read data from the Parquet file based on the column order in the Hive table, regardless of column names. This is similar to the ",(0,t.jsx)(i.code,{children:"parquet.column.index.access"})," variable in Hive. This parameter only applies to top-level column names and is ineffective for columns inside Structs."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"be-configuration",children:"BE Configuration"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.code,{children:"enable_parquet_page_index"})," (2.1.5+, 3.0+)"]}),"\n",(0,t.jsx)(i.p,{children:"Determines whether the Parquet Reader uses the Page Index to filter data. This is only for debugging purposes, in case the page index sometimes filters incorrect data. Default value is false."}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.code,{children:"parquet_header_max_size_mb"})," (2.1+, 3.0+)"]}),"\n",(0,t.jsx)(i.p,{children:"The maximum buffer size allocated when reading the Parquet Page header. Default is 1M."}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.code,{children:"parquet_rowgroup_max_buffer_mb"})," (2.1+, 3.0+)"]}),"\n",(0,t.jsx)(i.p,{children:"The maximum buffer size allocated when reading a Parquet Row Group. Default is 128M."}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.code,{children:"parquet_column_max_buffer_mb"})," (2.1+, 3.0+)"]}),"\n",(0,t.jsx)(i.p,{children:"The maximum buffer size allocated when reading a Column within a Parquet Row Group. Default is 8M."}),"\n"]}),"\n"]})]})}function c(e={}){let{wrapper:i}={...(0,s.a)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(u,{...e})}):u(e)}},250065:function(e,i,n){n.d(i,{Z:function(){return l},a:function(){return a}});var r=n(667294);let t={},s=r.createContext(t);function a(e){let i=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function l(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),r.createElement(s.Provider,{value:i},e.children)}}}]);