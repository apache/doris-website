"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["404472"],{935302:function(e,i,n){n.r(i),n.d(i,{default:()=>h,frontMatter:()=>s,metadata:()=>l,assets:()=>c,toc:()=>a,contentTitle:()=>o});var l=JSON.parse('{"id":"admin-manual/config/be-config","title":"BE Configuration","description":"This document mainly introduces the relevant configuration items of BE.","source":"@site/versioned_docs/version-3.x/admin-manual/config/be-config.md","sourceDirName":"admin-manual/config","slug":"/admin-manual/config/be-config","permalink":"/docs/3.x/admin-manual/config/be-config","draft":false,"unlisted":false,"tags":[],"version":"3.x","lastUpdatedAt":1770477659000,"frontMatter":{"title":"BE Configuration","language":"en","toc_min_heading_level":2,"toc_max_heading_level":4,"description":"This document mainly introduces the relevant configuration items of BE."},"sidebar":"docs","previous":{"title":"FE Configuration","permalink":"/docs/3.x/admin-manual/config/fe-config"},"next":{"title":"User Property","permalink":"/docs/3.x/admin-manual/config/user-property"}}'),r=n("785893"),t=n("250065");let s={title:"BE Configuration",language:"en",toc_min_heading_level:2,toc_max_heading_level:4,description:"This document mainly introduces the relevant configuration items of BE."},o="BE Configuration",c={},a=[{value:"View configuration items",id:"view-configuration-items",level:2},{value:"Set configuration items",id:"set-configuration-items",level:2},{value:"Examples",id:"examples",level:2},{value:"Configurations",id:"configurations",level:2},{value:"Services",id:"services",level:3},{value:"<code>deploy_mode</code>",id:"deploy_mode",level:4},{value:"<code>be_port</code>",id:"be_port",level:4},{value:"<code>heartbeat_service_port</code>",id:"heartbeat_service_port",level:4},{value:"<code>webserver_port</code>",id:"webserver_port",level:4},{value:"<code>brpc_port</code>",id:"brpc_port",level:4},{value:"<code>arrow_flight_sql_port</code>",id:"arrow_flight_sql_port",level:4},{value:"<code>enable_https</code>",id:"enable_https",level:4},{value:"<code>priority_networks</code>",id:"priority_networks",level:4},{value:"<code>storage_root_path</code>",id:"storage_root_path",level:4},{value:"<code>heartbeat_service_thread_count</code>",id:"heartbeat_service_thread_count",level:4},{value:"<code>ignore_broken_disk</code>",id:"ignore_broken_disk",level:4},{value:"<code>mem_limit</code>",id:"mem_limit",level:4},{value:"<code>cluster_id</code>",id:"cluster_id",level:4},{value:"<code>custom_config_dir</code>",id:"custom_config_dir",level:4},{value:"<code>trash_file_expire_time_sec</code>",id:"trash_file_expire_time_sec",level:4},{value:"<code>es_http_timeout_ms</code>",id:"es_http_timeout_ms",level:4},{value:"<code>es_scroll_keepalive</code>",id:"es_scroll_keepalive",level:4},{value:"<code>external_table_connect_timeout_sec</code>",id:"external_table_connect_timeout_sec",level:4},{value:"<code>pipeline_status_report_interval</code>",id:"pipeline_status_report_interval",level:4},{value:"<code>brpc_max_body_size</code>",id:"brpc_max_body_size",level:4},{value:"<code>brpc_socket_max_unwritten_bytes</code>",id:"brpc_socket_max_unwritten_bytes",level:4},{value:"<code>transfer_large_data_by_brpc</code>",id:"transfer_large_data_by_brpc",level:4},{value:"<code>brpc_num_threads</code>",id:"brpc_num_threads",level:4},{value:"<code>thrift_rpc_timeout_ms</code>",id:"thrift_rpc_timeout_ms",level:4},{value:"<code>thrift_client_retry_interval_ms</code>",id:"thrift_client_retry_interval_ms",level:4},{value:"<code>thrift_connect_timeout_seconds</code>",id:"thrift_connect_timeout_seconds",level:4},{value:"<code>thrift_server_type_of_fe</code>",id:"thrift_server_type_of_fe",level:4},{value:"<code>thrift_max_message_size</code>",id:"thrift_max_message_size",level:4},{value:"<code>txn_commit_rpc_timeout_ms</code>",id:"txn_commit_rpc_timeout_ms",level:4},{value:"<code>txn_map_shard_size</code>",id:"txn_map_shard_size",level:4},{value:"<code>txn_shard_size</code>",id:"txn_shard_size",level:4},{value:"<code>unused_rowset_monitor_interval</code>",id:"unused_rowset_monitor_interval",level:4},{value:"<code>max_client_cache_size_per_host</code>",id:"max_client_cache_size_per_host",level:4},{value:"<code>string_type_length_soft_limit_bytes</code>",id:"string_type_length_soft_limit_bytes",level:4},{value:"<code>big_column_size_buffer</code>",id:"big_column_size_buffer",level:4},{value:"<code>small_column_size_buffer</code>",id:"small_column_size_buffer",level:4},{value:"Query",id:"query",level:3},{value:"<code>fragment_mgr_asynic_work_pool_queue_size</code>",id:"fragment_mgr_asynic_work_pool_queue_size",level:4},{value:"<code>fragment_mgr_asynic_work_pool_thread_num_min</code>",id:"fragment_mgr_asynic_work_pool_thread_num_min",level:4},{value:"<code>fragment_mgr_asynic_work_pool_thread_num_max</code>",id:"fragment_mgr_asynic_work_pool_thread_num_max",level:4},{value:"<code>doris_scanner_row_num</code>",id:"doris_scanner_row_num",level:4},{value:"<code>doris_scanner_row_bytes</code>",id:"doris_scanner_row_bytes",level:4},{value:"<code>doris_scanner_thread_pool_queue_size</code>",id:"doris_scanner_thread_pool_queue_size",level:4},{value:"<code>doris_scanner_thread_pool_thread_num</code>",id:"doris_scanner_thread_pool_thread_num",level:4},{value:"<code>doris_max_remote_scanner_thread_pool_thread_num</code>",id:"doris_max_remote_scanner_thread_pool_thread_num",level:4},{value:"<code>exchg_node_buffer_size_bytes</code>",id:"exchg_node_buffer_size_bytes",level:4},{value:"<code>doris_scan_range_max_mb</code>",id:"doris_scan_range_max_mb",level:4},{value:"compaction",id:"compaction",level:3},{value:"<code>disable_auto_compaction</code>",id:"disable_auto_compaction",level:4},{value:"<code>enable_vertical_compaction</code>",id:"enable_vertical_compaction",level:4},{value:"<code>vertical_compaction_num_columns_per_group</code>",id:"vertical_compaction_num_columns_per_group",level:4},{value:"<code>vertical_compaction_max_row_source_memory_mb</code>",id:"vertical_compaction_max_row_source_memory_mb",level:4},{value:"<code>vertical_compaction_max_segment_size</code>",id:"vertical_compaction_max_segment_size",level:4},{value:"<code>enable_ordered_data_compaction</code>",id:"enable_ordered_data_compaction",level:4},{value:"<code>ordered_data_compaction_min_segment_size</code>",id:"ordered_data_compaction_min_segment_size",level:4},{value:"<code>max_base_compaction_threads</code>",id:"max_base_compaction_threads",level:4},{value:"<code>generate_compaction_tasks_interval_ms</code>",id:"generate_compaction_tasks_interval_ms",level:4},{value:"<code>base_compaction_min_rowset_num</code>",id:"base_compaction_min_rowset_num",level:4},{value:"<code>base_compaction_min_data_ratio</code>",id:"base_compaction_min_data_ratio",level:4},{value:"<code>total_permits_for_compaction_score</code>",id:"total_permits_for_compaction_score",level:4},{value:"<code>compaction_promotion_size_mbytes</code>",id:"compaction_promotion_size_mbytes",level:4},{value:"<code>compaction_promotion_ratio</code>",id:"compaction_promotion_ratio",level:4},{value:"<code>compaction_promotion_min_size_mbytes</code>",id:"compaction_promotion_min_size_mbytes",level:4},{value:"<code>compaction_min_size_mbytes</code>",id:"compaction_min_size_mbytes",level:4},{value:"<code>default_rowset_type</code>",id:"default_rowset_type",level:4},{value:"<code>cumulative_compaction_min_deltas</code>",id:"cumulative_compaction_min_deltas",level:4},{value:"<code>cumulative_compaction_max_deltas</code>",id:"cumulative_compaction_max_deltas",level:4},{value:"<code>base_compaction_trace_threshold</code>",id:"base_compaction_trace_threshold",level:4},{value:"<code>cumulative_compaction_trace_threshold</code>",id:"cumulative_compaction_trace_threshold",level:4},{value:"<code>compaction_task_num_per_disk</code>",id:"compaction_task_num_per_disk",level:4},{value:"<code>compaction_task_num_per_fast_disk</code>",id:"compaction_task_num_per_fast_disk",level:4},{value:"<code>cumulative_compaction_rounds_for_each_base_compaction_round</code>",id:"cumulative_compaction_rounds_for_each_base_compaction_round",level:4},{value:"<code>max_cumu_compaction_threads</code>",id:"max_cumu_compaction_threads",level:4},{value:"<code>enable_segcompaction</code>",id:"enable_segcompaction",level:4},{value:"<code>segcompaction_batch_size</code>",id:"segcompaction_batch_size",level:4},{value:"<code>segcompaction_candidate_max_rows</code>",id:"segcompaction_candidate_max_rows",level:4},{value:"<code>segcompaction_candidate_max_bytes</code>",id:"segcompaction_candidate_max_bytes",level:4},{value:"<code>segcompaction_task_max_rows</code>",id:"segcompaction_task_max_rows",level:4},{value:"<code>segcompaction_task_max_bytes</code>",id:"segcompaction_task_max_bytes",level:4},{value:"<code>segcompaction_num_threads</code>",id:"segcompaction_num_threads",level:4},{value:"<code>disable_compaction_trace_log</code>",id:"disable_compaction_trace_log",level:4},{value:"<code>pick_rowset_to_compact_interval_sec</code>",id:"pick_rowset_to_compact_interval_sec",level:4},{value:"<code>max_single_replica_compaction_threads</code>",id:"max_single_replica_compaction_threads",level:4},{value:"<code>update_replica_infos_interval_seconds</code>",id:"update_replica_infos_interval_seconds",level:4},{value:"<code>cold_data_compaction_score_threshold</code>",id:"cold_data_compaction_score_threshold",level:4},{value:"<code>cold_data_compaction_thread_num</code>",id:"cold_data_compaction_thread_num",level:4},{value:"<code>cold_data_compaction_interval_sec</code>",id:"cold_data_compaction_interval_sec",level:4},{value:"Load",id:"load",level:3},{value:"<code>enable_stream_load_record</code>",id:"enable_stream_load_record",level:4},{value:"<code>load_data_reserve_hours</code>",id:"load_data_reserve_hours",level:4},{value:"<code>push_worker_count_high_priority</code>",id:"push_worker_count_high_priority",level:4},{value:"<code>push_worker_count_normal_priority</code>",id:"push_worker_count_normal_priority",level:4},{value:"<code>enable_single_replica_load</code>",id:"enable_single_replica_load",level:4},{value:"<code>load_error_log_reserve_hours</code>",id:"load_error_log_reserve_hours",level:4},{value:"<code>load_error_log_limit_bytes</code>",id:"load_error_log_limit_bytes",level:4},{value:"<code>load_process_max_memory_limit_percent</code>",id:"load_process_max_memory_limit_percent",level:4},{value:"<code>load_process_soft_mem_limit_percent</code>",id:"load_process_soft_mem_limit_percent",level:4},{value:"<code>slave_replica_writer_rpc_timeout_sec</code>",id:"slave_replica_writer_rpc_timeout_sec",level:4},{value:"<code>max_segment_num_per_rowset</code>",id:"max_segment_num_per_rowset",level:4},{value:"<code>high_priority_flush_thread_num_per_store</code>",id:"high_priority_flush_thread_num_per_store",level:4},{value:"<code>routine_load_consumer_pool_size</code>",id:"routine_load_consumer_pool_size",level:4},{value:"<code>multi_table_batch_plan_threshold</code>",id:"multi_table_batch_plan_threshold",level:4},{value:"<code>multi_table_max_wait_tables</code>",id:"multi_table_max_wait_tables",level:4},{value:"<code>single_replica_load_download_num_workers</code>",id:"single_replica_load_download_num_workers",level:4},{value:"<code>load_task_high_priority_threshold_second</code>",id:"load_task_high_priority_threshold_second",level:4},{value:"<code>min_load_rpc_timeout_ms</code>",id:"min_load_rpc_timeout_ms",level:4},{value:"<code>kafka_api_version_request</code>",id:"kafka_api_version_request",level:4},{value:"<code>kafka_broker_version_fallback</code>",id:"kafka_broker_version_fallback",level:4},{value:"<code>max_consumer_num_per_group</code>",id:"max_consumer_num_per_group",level:4},{value:"<code>streaming_load_max_mb</code>",id:"streaming_load_max_mb",level:4},{value:"<code>streaming_load_json_max_mb</code>",id:"streaming_load_json_max_mb",level:4},{value:"<code>olap_table_sink_send_interval_microseconds</code>",id:"olap_table_sink_send_interval_microseconds",level:4},{value:"<code>olap_table_sink_send_interval_auto_partition_factor</code>",id:"olap_table_sink_send_interval_auto_partition_factor",level:4},{value:"Thread",id:"thread",level:3},{value:"<code>delete_worker_count</code>",id:"delete_worker_count",level:4},{value:"<code>clear_transaction_task_worker_count</code>",id:"clear_transaction_task_worker_count",level:4},{value:"<code>clone_worker_count</code>",id:"clone_worker_count",level:4},{value:"<code>be_service_threads</code>",id:"be_service_threads",level:4},{value:"<code>download_worker_count</code>",id:"download_worker_count",level:4},{value:"<code>drop_tablet_worker_count</code>",id:"drop_tablet_worker_count",level:4},{value:"<code>flush_thread_num_per_store</code>",id:"flush_thread_num_per_store",level:4},{value:"<code>publish_version_worker_count</code>",id:"publish_version_worker_count",level:4},{value:"<code>upload_worker_count</code>",id:"upload_worker_count",level:4},{value:"<code>webserver_num_workers</code>",id:"webserver_num_workers",level:4},{value:"<code>send_batch_thread_pool_thread_num</code>",id:"send_batch_thread_pool_thread_num",level:4},{value:"<code>send_batch_thread_pool_queue_size</code>",id:"send_batch_thread_pool_queue_size",level:4},{value:"<code>make_snapshot_worker_count</code>",id:"make_snapshot_worker_count",level:4},{value:"<code>release_snapshot_worker_count</code>",id:"release_snapshot_worker_count",level:4},{value:"Memory",id:"memory",level:3},{value:"<code>madvise_huge_pages</code>",id:"madvise_huge_pages",level:4},{value:"<code>max_memory_sink_batch_count</code>",id:"max_memory_sink_batch_count",level:4},{value:"<code>memory_max_alignment</code>",id:"memory_max_alignment",level:4},{value:"<code>mmap_buffers</code>",id:"mmap_buffers",level:4},{value:"<code>memtable_mem_tracker_refresh_interval_ms</code>",id:"memtable_mem_tracker_refresh_interval_ms",level:4},{value:"<code>zone_map_row_num_threshold</code>",id:"zone_map_row_num_threshold",level:4},{value:"<code>memory_mode</code>",id:"memory_mode",level:4},{value:"<code>max_sys_mem_available_low_water_mark_bytes</code>",id:"max_sys_mem_available_low_water_mark_bytes",level:4},{value:"<code>memory_limitation_per_thread_for_schema_change_bytes</code>",id:"memory_limitation_per_thread_for_schema_change_bytes",level:4},{value:"<code>mem_tracker_consume_min_size_bytes</code>",id:"mem_tracker_consume_min_size_bytes",level:4},{value:"<code>min_buffer_size</code>",id:"min_buffer_size",level:4},{value:"<code>write_buffer_size</code>",id:"write_buffer_size",level:4},{value:"<code>remote_storage_read_buffer_mb</code>",id:"remote_storage_read_buffer_mb",level:4},{value:"<code>file_cache_type</code>",id:"file_cache_type",level:4},{value:"<code>path_gc_check</code>",id:"path_gc_check",level:4},{value:"<code>path_gc_check_interval_second</code>",id:"path_gc_check_interval_second",level:4},{value:"<code>path_gc_check_step</code>",id:"path_gc_check_step",level:4},{value:"<code>path_gc_check_step_interval_ms</code>",id:"path_gc_check_step_interval_ms",level:4},{value:"<code>scan_context_gc_interval_min</code>",id:"scan_context_gc_interval_min",level:4},{value:"Storage",id:"storage",level:3},{value:"<code>default_num_rows_per_column_file_block</code>",id:"default_num_rows_per_column_file_block",level:4},{value:"<code>disable_storage_page_cache</code>",id:"disable_storage_page_cache",level:4},{value:"<code>disk_stat_monitor_interval</code>",id:"disk_stat_monitor_interval",level:4},{value:"<code>max_free_io_buffers</code>",id:"max_free_io_buffers",level:4},{value:"<code>max_garbage_sweep_interval</code>",id:"max_garbage_sweep_interval",level:4},{value:"<code>max_percentage_of_error_disk</code>",id:"max_percentage_of_error_disk",level:4},{value:"<code>min_garbage_sweep_interval</code>",id:"min_garbage_sweep_interval",level:4},{value:"<code>pprof_profile_dir</code>",id:"pprof_profile_dir",level:4},{value:"<code>small_file_dir</code>",id:"small_file_dir",level:4},{value:"<code>user_function_dir</code>",id:"user_function_dir",level:4},{value:"<code>storage_flood_stage_left_capacity_bytes</code>",id:"storage_flood_stage_left_capacity_bytes",level:4},{value:"<code>storage_flood_stage_usage_percent</code>",id:"storage_flood_stage_usage_percent",level:4},{value:"<code>storage_medium_migrate_count</code>",id:"storage_medium_migrate_count",level:4},{value:"<code>storage_page_cache_limit</code>",id:"storage_page_cache_limit",level:4},{value:"<code>storage_page_cache_shard_size</code>",id:"storage_page_cache_shard_size",level:4},{value:"<code>index_page_cache_percentage</code>",id:"index_page_cache_percentage",level:4},{value:"<code>segment_cache_capacity</code>",id:"segment_cache_capacity",level:4},{value:"<code>storage_strict_check_incompatible_old_format</code>",id:"storage_strict_check_incompatible_old_format",level:4},{value:"<code>sync_tablet_meta</code>",id:"sync_tablet_meta",level:4},{value:"<code>pending_data_expire_time_sec</code>",id:"pending_data_expire_time_sec",level:4},{value:"<code>ignore_rowset_stale_unconsistent_delete</code>",id:"ignore_rowset_stale_unconsistent_delete",level:4},{value:"<code>create_tablet_worker_count</code>",id:"create_tablet_worker_count",level:4},{value:"<code>check_consistency_worker_count</code>",id:"check_consistency_worker_count",level:4},{value:"<code>max_tablet_version_num</code>",id:"max_tablet_version_num",level:4},{value:"<code>tablet_map_shard_size</code>",id:"tablet_map_shard_size",level:4},{value:"<code>tablet_meta_checkpoint_min_interval_secs</code>",id:"tablet_meta_checkpoint_min_interval_secs",level:4},{value:"<code>tablet_meta_checkpoint_min_new_rowsets_num</code>",id:"tablet_meta_checkpoint_min_new_rowsets_num",level:4},{value:"<code>tablet_rowset_stale_sweep_time_sec</code>",id:"tablet_rowset_stale_sweep_time_sec",level:4},{value:"<code>tablet_writer_open_rpc_timeout_sec</code>",id:"tablet_writer_open_rpc_timeout_sec",level:4},{value:"<code>tablet_writer_ignore_eovercrowded</code>",id:"tablet_writer_ignore_eovercrowded",level:4},{value:"<code>streaming_load_rpc_max_alive_time_sec</code>",id:"streaming_load_rpc_max_alive_time_sec",level:4},{value:"<code>alter_tablet_worker_count</code>",id:"alter_tablet_worker_count",level:4},{value:"<code>alter_index_worker_count</code>",id:"alter_index_worker_count",level:4},{value:"<code>ignore_load_tablet_failure</code>",id:"ignore_load_tablet_failure",level:4},{value:"<code>report_disk_state_interval_seconds</code>",id:"report_disk_state_interval_seconds",level:4},{value:"<code>result_buffer_cancelled_interval_time</code>",id:"result_buffer_cancelled_interval_time",level:4},{value:"<code>snapshot_expire_time_sec</code>",id:"snapshot_expire_time_sec",level:4},{value:"Log",id:"log",level:3},{value:"<code>sys_log_dir</code>",id:"sys_log_dir",level:4},{value:"<code>sys_log_level</code>",id:"sys_log_level",level:4},{value:"<code>sys_log_roll_mode</code>",id:"sys_log_roll_mode",level:4},{value:"<code>sys_log_roll_num</code>",id:"sys_log_roll_num",level:4},{value:"<code>sys_log_verbose_level</code>",id:"sys_log_verbose_level",level:4},{value:"<code>sys_log_verbose_modules</code>",id:"sys_log_verbose_modules",level:4},{value:"<code>aws_log_level</code>",id:"aws_log_level",level:4},{value:"<code>log_buffer_level</code>",id:"log_buffer_level",level:4},{value:"Others",id:"others",level:3},{value:"<code>report_tablet_interval_seconds</code>",id:"report_tablet_interval_seconds",level:4},{value:"<code>report_task_interval_seconds</code>",id:"report_task_interval_seconds",level:4},{value:"<code>periodic_counter_update_period_ms</code>",id:"periodic_counter_update_period_ms",level:4},{value:"<code>enable_metric_calculator</code>",id:"enable_metric_calculator",level:4},{value:"<code>enable_system_metrics</code>",id:"enable_system_metrics",level:4},{value:"<code>enable_token_check</code>",id:"enable_token_check",level:4},{value:"<code>max_runnings_transactions_per_txn_map</code>",id:"max_runnings_transactions_per_txn_map",level:4},{value:"<code>max_download_speed_kbps</code>",id:"max_download_speed_kbps",level:4},{value:"<code>download_low_speed_time</code>",id:"download_low_speed_time",level:4},{value:"<code>download_low_speed_limit_kbps</code>",id:"download_low_speed_limit_kbps",level:4},{value:"<code>enable_batch_download</code>",id:"enable_batch_download",level:4},{value:"<code>priority_queue_remaining_tasks_increased_frequency</code>",id:"priority_queue_remaining_tasks_increased_frequency",level:4},{value:"<code>jdbc_drivers_dir</code>",id:"jdbc_drivers_dir",level:4},{value:"<code>enable_simdjson_reader</code>",id:"enable_simdjson_reader",level:4},{value:"<code>enable_query_memory_overcommit</code>",id:"enable_query_memory_overcommit",level:4},{value:"<code>user_files_secure_path</code>",id:"user_files_secure_path",level:4},{value:"<code>brpc_streaming_client_batch_bytes</code>",id:"brpc_streaming_client_batch_bytes",level:4},{value:"<code>grace_shutdown_wait_seconds</code>",id:"grace_shutdown_wait_seconds",level:4},{value:"<code>enable_java_support</code>",id:"enable_java_support",level:4},{value:"<code>group_commit_wal_path</code>",id:"group_commit_wal_path",level:4},{value:"Compute and Storage Disaggregated Mode",id:"compute-and-storage-disaggregated-mode",level:3},{value:"<code>deploy_mode</code>",id:"deploy_mode-1",level:4},{value:"<code>meta_service_endpoint</code>",id:"meta_service_endpoint",level:4},{value:"<code>enable_file_cache</code>",id:"enable_file_cache",level:4},{value:"<code>file_cache_path</code>",id:"file_cache_path",level:4},{value:"<code>time_series_max_tablet_version_num</code>",id:"time_series_max_tablet_version_num",level:4}];function d(e){let i={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.header,{children:(0,r.jsx)(i.h1,{id:"be-configuration",children:"BE Configuration"})}),"\n",(0,r.jsx)(i.p,{children:"This document mainly introduces the relevant configuration items of BE."}),"\n",(0,r.jsxs)(i.p,{children:["The BE configuration file ",(0,r.jsx)(i.code,{children:"be.conf"})," is usually stored in the ",(0,r.jsx)(i.code,{children:"conf/"})," directory of the BE deployment path. In version 0.14, another configuration file ",(0,r.jsx)(i.code,{children:"be_custom.conf"})," will be introduced. The configuration file is used to record the configuration items that are dynamically configured and persisted by the user during operation."]}),"\n",(0,r.jsxs)(i.p,{children:["After the BE process is started, it will read the configuration items in ",(0,r.jsx)(i.code,{children:"be.conf"})," first, and then read the configuration items in ",(0,r.jsx)(i.code,{children:"be_custom.conf"}),". The configuration items in ",(0,r.jsx)(i.code,{children:"be_custom.conf"})," will overwrite the same configuration items in ",(0,r.jsx)(i.code,{children:"be.conf"}),"."]}),"\n",(0,r.jsxs)(i.p,{children:["The location of the ",(0,r.jsx)(i.code,{children:"be_custom.conf"})," file can be configured in ",(0,r.jsx)(i.code,{children:"be.conf"})," through the ",(0,r.jsx)(i.code,{children:"custom_config_dir"})," configuration item."]}),"\n",(0,r.jsx)(i.h2,{id:"view-configuration-items",children:"View configuration items"}),"\n",(0,r.jsx)(i.p,{children:"There are two ways to view the configuration items of BE:"}),"\n",(0,r.jsxs)(i.ol,{children:["\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsx)(i.p,{children:"BE web page"}),"\n",(0,r.jsx)(i.p,{children:"Users can view the current configuration items by visiting BE's web page:"}),"\n",(0,r.jsx)(i.p,{children:(0,r.jsx)(i.code,{children:"http://be_host:be_webserver_port/varz"})}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsx)(i.p,{children:"View by command"}),"\n",(0,r.jsxs)(i.p,{children:["You can view the configuration items of the BE in the MySQL client with the following command,Concrete language law reference ",(0,r.jsx)(i.a,{href:"../../sql-manual/sql-statements/cluster-management/instance-management/SHOW-FRONTEND-CONFIG",children:"SHOW-CONFIG"}),":"]}),"\n",(0,r.jsx)(i.p,{children:(0,r.jsx)(i.code,{children:"SHOW BACKEND CONFIG;"})}),"\n",(0,r.jsx)(i.p,{children:"The meanings of the columns in the results are as follows:"}),"\n",(0,r.jsxs)(i.ol,{children:["\n",(0,r.jsx)(i.li,{children:"BackendId: the id of backend."}),"\n",(0,r.jsx)(i.li,{children:"Host: the IP of backend."}),"\n",(0,r.jsx)(i.li,{children:"Key: the name of the configuration item."}),"\n",(0,r.jsx)(i.li,{children:"Value: The value of the current configuration item."}),"\n",(0,r.jsx)(i.li,{children:"Type: The configuration item value type, such as integer or string."}),"\n",(0,r.jsx)(i.li,{children:"IsMutable: whether it can be dynamically configured. If true, the configuration item can be dynamically configured at runtime. If false, it means that the configuration item can only be configured in be.conf and takes effect after restarting BE."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"set-configuration-items",children:"Set configuration items"}),"\n",(0,r.jsx)(i.p,{children:"There are two ways to configure BE configuration items:"}),"\n",(0,r.jsxs)(i.ol,{children:["\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsx)(i.p,{children:"Static configuration"}),"\n",(0,r.jsxs)(i.p,{children:["Add and set configuration items in the ",(0,r.jsx)(i.code,{children:"conf/be.conf"})," file. The configuration items in ",(0,r.jsx)(i.code,{children:"be.conf"})," will be read when BE starts. Configuration items not in ",(0,r.jsx)(i.code,{children:"be.conf"})," will use default values."]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsx)(i.p,{children:"Dynamic configuration"}),"\n",(0,r.jsx)(i.p,{children:"After BE starts, the configuration items can be dynamically set with the following commands."}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{children:"curl -X POST http://{be_ip}:{be_http_port}/api/update_config?{key}={value}\n"})}),"\n",(0,r.jsxs)(i.p,{children:["In version 0.13 and before, the configuration items modified in this way will become invalid after the BE process restarts. In 0.14 and later versions, the modified configuration can be persisted through the following command. The modified configuration items are stored in the ",(0,r.jsx)(i.code,{children:"be_custom.conf"})," file."]}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{children:"curl -X POST http://{be_ip}:{be_http_port}/api/update_config?{key}={value}\\&persist=true\n"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"examples",children:"Examples"}),"\n",(0,r.jsxs)(i.ol,{children:["\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsxs)(i.p,{children:["Modify ",(0,r.jsx)(i.code,{children:"max_base_compaction_threads"})," statically"]}),"\n",(0,r.jsxs)(i.p,{children:["By adding in the ",(0,r.jsx)(i.code,{children:"be.conf"})," file:"]}),"\n",(0,r.jsx)(i.p,{children:(0,r.jsx)(i.code,{children:"max_base_compaction_threads=5"})}),"\n",(0,r.jsx)(i.p,{children:"Then restart the BE process to take effect the configuration."}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsxs)(i.p,{children:["Modify ",(0,r.jsx)(i.code,{children:"streaming_load_max_mb"})," dynamically"]}),"\n",(0,r.jsxs)(i.p,{children:["After BE starts, the configuration item ",(0,r.jsx)(i.code,{children:"streaming_load_max_mb"})," is dynamically set by the following command:"]}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{children:"curl -X POST http://{be_ip}:{be_http_port}/api/update_config?streaming_load_max_mb=1024\n"})}),"\n",(0,r.jsx)(i.p,{children:"The return value is as follows, indicating that the setting is successful."}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{children:'{\n    "status": "OK",\n    "msg": ""\n}\n'})}),"\n",(0,r.jsx)(i.p,{children:"The configuration will become invalid after the BE restarts. If you want to persist the modified results, use the following command:"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{children:"curl -X POST http://{be_ip}:{be_http_port}/api/update_config?streaming_load_max_mb=1024\\&persist=true\n"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"configurations",children:"Configurations"}),"\n",(0,r.jsx)(i.h3,{id:"services",children:"Services"}),"\n",(0,r.jsx)(i.h4,{id:"deploy_mode",children:(0,r.jsx)(i.code,{children:"deploy_mode"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: string"}),"\n",(0,r.jsxs)(i.li,{children:["Description:  The mode in which BE runs. ",(0,r.jsx)(i.code,{children:"cloud"})," indicates the decoupled storage-compute mode."]}),"\n",(0,r.jsx)(i.li,{children:'Default value: ""'}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"be_port",children:(0,r.jsx)(i.code,{children:"be_port"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description:  The port of the thrift server on BE which used to receive requests from FE"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 9060"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"heartbeat_service_port",children:(0,r.jsx)(i.code,{children:"heartbeat_service_port"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: Heartbeat service port (thrift) on BE, used to receive heartbeat from FE"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 9050"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"webserver_port",children:(0,r.jsx)(i.code,{children:"webserver_port"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: Service port of http server on BE"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 8040"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"brpc_port",children:(0,r.jsx)(i.code,{children:"brpc_port"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The port of BRPC on BE, used for communication between BEs"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 8060"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"arrow_flight_sql_port",children:(0,r.jsx)(i.code,{children:"arrow_flight_sql_port"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The port of Arrow Flight SQL server on BE, used for communication between Arrow Flight Client and BE"}),"\n",(0,r.jsx)(i.li,{children:"Default value: -1"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"enable_https",children:(0,r.jsx)(i.code,{children:"enable_https"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: bool"}),"\n",(0,r.jsxs)(i.li,{children:["Description: Whether https is supported. If so, configure ",(0,r.jsx)(i.code,{children:"ssl_certificate_path"})," and ",(0,r.jsx)(i.code,{children:"ssl_private_key_path"})," in be.conf."]}),"\n",(0,r.jsx)(i.li,{children:"Default value: false"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"priority_networks",children:(0,r.jsx)(i.code,{children:"priority_networks"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Declare a selection strategy for those servers with many IPs. Note that at most one ip should match this list. This is a semicolon-separated list in CIDR notation, such as 10.10.10.0/24. If there is no IP matching this rule, one will be randomly selected"}),"\n",(0,r.jsx)(i.li,{children:"Default value: blank"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"storage_root_path",children:(0,r.jsx)(i.code,{children:"storage_root_path"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsx)(i.p,{children:"Type: string"}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsx)(i.p,{children:"Description: data root path, separate by ';'.you can specify the storage medium of each root path, HDD or SSD. you can add capacity limit at the end of each root path, separate by ','.If the user does not use a mix of SSD and HDD disks, they do not need to configure the configuration methods in Example 1 and Example 2 below, but only need to specify the storage directory; they also do not need to modify the default storage media configuration of FE."}),"\n",(0,r.jsxs)(i.p,{children:["eg.1: ",(0,r.jsx)(i.code,{children:"storage_root_path=/home/disk1/doris.HDD;/home/disk2/doris.SSD;/home/disk2/doris"})]}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"1./home/disk1/doris.HDD, indicates that the storage medium is HDD;"}),"\n",(0,r.jsx)(i.li,{children:"2./home/disk2/doris.SSD, indicates that the storage medium is SSD;"}),"\n",(0,r.jsx)(i.li,{children:"3./home/disk2/doris, indicates that the storage medium is HDD by default"}),"\n"]}),"\n",(0,r.jsxs)(i.p,{children:["eg.2: ",(0,r.jsx)(i.code,{children:"storage_root_path=/home/disk1/doris,medium:hdd;/home/disk2/doris,medium:ssd"})]}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"1./home/disk1/doris,medium:hdd, indicates that the storage medium is HDD;"}),"\n",(0,r.jsx)(i.li,{children:"2./home/disk2/doris,medium:ssd, indicates that the storage medium is SSD;"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsx)(i.p,{children:"Default value: ${DORIS_HOME}/storage"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"heartbeat_service_thread_count",children:(0,r.jsx)(i.code,{children:"heartbeat_service_thread_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The number of threads that execute the heartbeat service on BE. the default is 1, it is not recommended to modify"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"ignore_broken_disk",children:(0,r.jsx)(i.code,{children:"ignore_broken_disk"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsx)(i.p,{children:"Type: bool"}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsxs)(i.p,{children:["Description: When BE starts, check ",(0,r.jsx)(i.code,{children:"storage_root_path"})," All paths under configuration."]}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:(0,r.jsx)(i.code,{children:"ignore_broken_disk=true"})}),"\n"]}),"\n",(0,r.jsx)(i.p,{children:"If the path does not exist or the file (bad disk) cannot be read or written under the path, the path will be ignored. If there are other available paths, the startup will not be interrupted."}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:(0,r.jsx)(i.code,{children:"ignore_broken_disk=false"})}),"\n"]}),"\n",(0,r.jsx)(i.p,{children:"If the path does not exist or the file (bad disk) cannot be read or written under the path, the system will abort the startup failure and exit."}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsx)(i.p,{children:"Default value: false"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"mem_limit",children:(0,r.jsx)(i.code,{children:"mem_limit"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: string"}),"\n",(0,r.jsx)(i.li,{children:"Description: Limit the percentage of the server's maximum memory used by the BE process. It is used to prevent BE memory from occupying too the machine's memory. This parameter must be greater than 0. When the percentage is greater than 100%, the value will default to 100%."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 90%"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"cluster_id",children:(0,r.jsx)(i.code,{children:"cluster_id"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsxs)(i.li,{children:["Description: Configure the cluster id to which the BE belongs.\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"This value is usually delivered by the FE to the BE by the heartbeat, no need to configure. When it is confirmed that a BE belongs to a certain Doris cluster, it can be configured. The cluster_id file under the data directory needs to be modified to make sure same as this parament."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: -1"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"custom_config_dir",children:(0,r.jsx)(i.code,{children:"custom_config_dir"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Description: Configure the location of the ",(0,r.jsx)(i.code,{children:"be_custom.conf"})," file. The default is in the ",(0,r.jsx)(i.code,{children:"conf/"})," directory.\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["In some deployment environments, the ",(0,r.jsx)(i.code,{children:"conf/"})," directory may be overwritten due to system upgrades. This will cause the user modified configuration items to be overwritten. At this time, we can store ",(0,r.jsx)(i.code,{children:"be_custom.conf"})," in another specified directory to prevent the configuration file from being overwritten."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: blank"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"trash_file_expire_time_sec",children:(0,r.jsx)(i.code,{children:"trash_file_expire_time_sec"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The interval for cleaning the recycle bin is 24 hours. When the disk space is insufficient, the file retention period under trash may not comply with this parameter"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 86400"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"es_http_timeout_ms",children:(0,r.jsx)(i.code,{children:"es_http_timeout_ms"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The timeout period for connecting to ES via http."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 5000 (ms)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"es_scroll_keepalive",children:(0,r.jsx)(i.code,{children:"es_scroll_keepalive"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: es scroll keep-alive hold time"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 5 (m)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"external_table_connect_timeout_sec",children:(0,r.jsx)(i.code,{children:"external_table_connect_timeout_sec"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The timeout when establishing connection with external table such as ODBC table."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 5 seconds"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"pipeline_status_report_interval",children:(0,r.jsx)(i.code,{children:"pipeline_status_report_interval"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Interval between profile reports"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 5 seconds"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"brpc_max_body_size",children:(0,r.jsx)(i.code,{children:"brpc_max_body_size"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsxs)(i.p,{children:["Description: This configuration is mainly used to modify the parameter ",(0,r.jsx)(i.code,{children:"max_body_size"})," of brpc."]}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Sometimes the query fails and an error message of ",(0,r.jsx)(i.code,{children:"body_size is too large"}),' will appear in the BE log. This may happen when the SQL mode is "multi distinct + no group by + more than 1T of data".This error indicates that the packet size of brpc exceeds the configured value. At this time, you can avoid this error by increasing the configuration.']}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"brpc_socket_max_unwritten_bytes",children:(0,r.jsx)(i.code,{children:"brpc_socket_max_unwritten_bytes"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Description: This configuration is mainly used to modify the parameter ",(0,r.jsx)(i.code,{children:"socket_max_unwritten_bytes"})," of brpc.\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Sometimes the query fails and an error message of ",(0,r.jsx)(i.code,{children:"The server is overcrowded"})," will appear in the BE log. This means there are too many messages to buffer at the sender side, which may happen when the SQL needs to send large bitmap value. You can avoid this error by increasing the configuration."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"transfer_large_data_by_brpc",children:(0,r.jsx)(i.code,{children:"transfer_large_data_by_brpc"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: bool"}),"\n",(0,r.jsx)(i.li,{children:"Description: This configuration is used to control whether to serialize the protoBuf request and embed the Tuple/Block data into the controller attachment and send it through http brpc when the length of the Tuple/Block data is greater than 1.8G. To avoid errors when the length of the protoBuf request exceeds 2G: Bad request, error_text=[E1003]Fail to compress request. In the past version, after putting Tuple/Block data in the attachment, it was sent through the default baidu_std brpc, but when the attachment exceeds 2G, it will be truncated. There is no 2G limit for sending through http brpc."}),"\n",(0,r.jsx)(i.li,{children:"Default value: true"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"brpc_num_threads",children:(0,r.jsx)(i.code,{children:"brpc_num_threads"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Description: This configuration is mainly used to modify the number of bthreads for brpc. The default value is set to -1, which means the number of bthreads is #cpu-cores.\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["User can set this configuration to a larger value to get better QPS performance. For more information, please refer to ",(0,r.jsx)(i.code,{children:"https://github.com/apache/brpc/blob/master/docs/cn/benchmark.md"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: -1"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"thrift_rpc_timeout_ms",children:(0,r.jsx)(i.code,{children:"thrift_rpc_timeout_ms"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: thrift default timeout time"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 60000"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"thrift_client_retry_interval_ms",children:(0,r.jsx)(i.code,{children:"thrift_client_retry_interval_ms"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int64"}),"\n",(0,r.jsx)(i.li,{children:"Description: Used to set retry interval for thrift client in be to avoid avalanche disaster in fe thrift server, the unit is ms."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1000"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"thrift_connect_timeout_seconds",children:(0,r.jsx)(i.code,{children:"thrift_connect_timeout_seconds"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The default thrift client connection timeout time"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 3 (s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"thrift_server_type_of_fe",children:(0,r.jsx)(i.code,{children:"thrift_server_type_of_fe"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsx)(i.p,{children:"Type: string"}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsxs)(i.p,{children:["Description:This configuration indicates the service model used by FE's Thrift service. The type is string and is case-insensitive. This parameter needs to be consistent with the setting of fe's thrift_server_type parameter. Currently there are two values for this parameter, ",(0,r.jsx)(i.code,{children:"THREADED"})," and ",(0,r.jsx)(i.code,{children:"THREAD_POOL"}),"."]}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsxs)(i.p,{children:["If the parameter is ",(0,r.jsx)(i.code,{children:"THREADED"}),", the model is a non-blocking I/O model."]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsxs)(i.p,{children:["If the parameter is ",(0,r.jsx)(i.code,{children:"THREAD_POOL"}),", the model is a blocking I/O model."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"thrift_max_message_size",children:(0,r.jsx)(i.code,{children:"thrift_max_message_size"})}),"\n",(0,r.jsx)(i.p,{children:"Default: 100MB"}),"\n",(0,r.jsx)(i.p,{children:'The maximum size of a (received) message of the thrift server, in bytes. If the size of the message sent by the client exceeds this limit, the Thrift server will reject the request and close the connection. As a result, the client will encounter the error: "connection has been closed by peer." In this case, you can try increasing this parameter.'}),"\n",(0,r.jsx)(i.h4,{id:"txn_commit_rpc_timeout_ms",children:(0,r.jsx)(i.code,{children:"txn_commit_rpc_timeout_ms"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description:txn submit rpc timeout"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 60,000 (ms)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"txn_map_shard_size",children:(0,r.jsx)(i.code,{children:"txn_map_shard_size"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: txn_map_lock fragment size, the value is 2^n, n=0,1,2,3,4. This is an enhancement to improve the performance of managing txn"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 128"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"txn_shard_size",children:(0,r.jsx)(i.code,{children:"txn_shard_size"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: txn_lock shard size, the value is 2^n, n=0,1,2,3,4, this is an enhancement function that can improve the performance of submitting and publishing txn"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1024"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"unused_rowset_monitor_interval",children:(0,r.jsx)(i.code,{children:"unused_rowset_monitor_interval"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Time interval for clearing expired Rowset"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 30 (s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"max_client_cache_size_per_host",children:(0,r.jsx)(i.code,{children:"max_client_cache_size_per_host"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The maximum number of client caches per host. There are multiple client caches in BE, but currently we use the same cache size configuration. If necessary, use different configurations to set up different client-side caches"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 10"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"string_type_length_soft_limit_bytes",children:(0,r.jsx)(i.code,{children:"string_type_length_soft_limit_bytes"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The soft limit of the maximum length of String type."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1,048,576"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"big_column_size_buffer",children:(0,r.jsx)(i.code,{children:"big_column_size_buffer"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int64"}),"\n",(0,r.jsx)(i.li,{children:"Description: When using the odbc external table, if a column type of the odbc source table is HLL, CHAR or VARCHAR, and the length of the column value exceeds this value, the query will report an error 'column value length longer than buffer length'. You can increase this value"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 65535"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"small_column_size_buffer",children:(0,r.jsx)(i.code,{children:"small_column_size_buffer"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int64"}),"\n",(0,r.jsx)(i.li,{children:"Description:  When using the odbc external table, if a column type of the odbc source table is not HLL, CHAR or VARCHAR, and the length of the column value exceeds this value, the query will report an error 'column value length longer than buffer length'. You can increase this value"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 100"}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"query",children:"Query"}),"\n",(0,r.jsx)(i.h4,{id:"fragment_mgr_asynic_work_pool_queue_size",children:(0,r.jsx)(i.code,{children:"fragment_mgr_asynic_work_pool_queue_size"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The upper limit of asynic work that can be processed on a single node"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 4096"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"fragment_mgr_asynic_work_pool_thread_num_min",children:(0,r.jsx)(i.code,{children:"fragment_mgr_asynic_work_pool_thread_num_min"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Number of threads to execute asynic work. By default, the minimum number of threads is 16."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 16"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"fragment_mgr_asynic_work_pool_thread_num_max",children:(0,r.jsx)(i.code,{children:"fragment_mgr_asynic_work_pool_thread_num_max"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Follow up asynic work create threads dynamically, with a maximum of 512 threads created."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 512"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"doris_scanner_row_num",children:(0,r.jsx)(i.code,{children:"doris_scanner_row_num"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The maximum number of data rows returned by each scanning thread in a single execution"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 16384"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"doris_scanner_row_bytes",children:(0,r.jsx)(i.code,{children:"doris_scanner_row_bytes"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Description: single read execute fragment row bytes\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Note: If there are too many columns in the table, you can adjust this config if you encounter a ",(0,r.jsx)(i.code,{children:"select *"})," stuck"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 10485760"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"doris_scanner_thread_pool_queue_size",children:(0,r.jsx)(i.code,{children:"doris_scanner_thread_pool_queue_size"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The queue length of the Scanner thread pool. In Doris' scanning tasks, each Scanner will be submitted as a thread task to the thread pool waiting to be scheduled, and after the number of submitted tasks exceeds the length of the thread pool queue, subsequent submitted tasks will be blocked until there is a empty slot in the queue."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 102400"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"doris_scanner_thread_pool_thread_num",children:(0,r.jsx)(i.code,{children:"doris_scanner_thread_pool_thread_num"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The number of threads in the Scanner thread pool. In Doris' scanning tasks, each Scanner will be submitted as a thread task to the thread pool to be scheduled. This parameter determines the size of the Scanner thread pool."}),"\n",(0,r.jsxs)(i.li,{children:["Default value: Depending on cpu cores. Equal to ",(0,r.jsx)(i.code,{children:"max(48, 2 * num_of_cpu_cores)"})]}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"doris_max_remote_scanner_thread_pool_thread_num",children:(0,r.jsx)(i.code,{children:"doris_max_remote_scanner_thread_pool_thread_num"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: Max thread number of Remote scanner thread pool. Remote scanner thread pool is used for scan task of all external data sources."}),"\n",(0,r.jsx)(i.li,{children:"Default: 512"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"exchg_node_buffer_size_bytes",children:(0,r.jsx)(i.code,{children:"exchg_node_buffer_size_bytes"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The size of the Buffer queue of the ExchangeNode node, in bytes. After the amount of data sent from the Sender side is larger than the Buffer size of ExchangeNode, subsequent data sent will block until the Buffer frees up space for writing."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 10485760"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"doris_scan_range_max_mb",children:(0,r.jsx)(i.code,{children:"doris_scan_range_max_mb"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The maximum amount of data read by each OlapScanner."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1024"}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"compaction",children:"compaction"}),"\n",(0,r.jsx)(i.h4,{id:"disable_auto_compaction",children:(0,r.jsx)(i.code,{children:"disable_auto_compaction"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: bool"}),"\n",(0,r.jsxs)(i.li,{children:["Description: Whether disable automatic compaction task\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Generally it needs to be turned off. When you want to manually operate the compaction task in the debugging or test environment, you can turn on the configuration."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: false"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"enable_vertical_compaction",children:(0,r.jsx)(i.code,{children:"enable_vertical_compaction"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: bool"}),"\n",(0,r.jsx)(i.li,{children:"Description: Whether to enable vertical compaction"}),"\n",(0,r.jsx)(i.li,{children:"Default value: true"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"vertical_compaction_num_columns_per_group",children:(0,r.jsx)(i.code,{children:"vertical_compaction_num_columns_per_group"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: In vertical compaction, column number for every group"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 5"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"vertical_compaction_max_row_source_memory_mb",children:(0,r.jsx)(i.code,{children:"vertical_compaction_max_row_source_memory_mb"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: In vertical compaction, max memory usage for row_source_buffer,The unit is MB."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 200"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"vertical_compaction_max_segment_size",children:(0,r.jsx)(i.code,{children:"vertical_compaction_max_segment_size"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: In vertical compaction, max dest segment file size, The unit is m bytes."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 268435456"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"enable_ordered_data_compaction",children:(0,r.jsx)(i.code,{children:"enable_ordered_data_compaction"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: bool"}),"\n",(0,r.jsx)(i.li,{children:"Description: Whether to enable ordered data compaction"}),"\n",(0,r.jsx)(i.li,{children:"Default value: true"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"ordered_data_compaction_min_segment_size",children:(0,r.jsx)(i.code,{children:"ordered_data_compaction_min_segment_size"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: In ordered data compaction, min segment size for input rowset, The unit is m bytes."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 10485760"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"max_base_compaction_threads",children:(0,r.jsx)(i.code,{children:"max_base_compaction_threads"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The maximum of thread number in base compaction thread pool, -1 means one thread per disk."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 4"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"generate_compaction_tasks_interval_ms",children:(0,r.jsx)(i.code,{children:"generate_compaction_tasks_interval_ms"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Minimal interval (ms) to generate compaction tasks"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 10 (ms)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"base_compaction_min_rowset_num",children:(0,r.jsx)(i.code,{children:"base_compaction_min_rowset_num"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: One of the triggering conditions of BaseCompaction: The limit of the number of Cumulative files to be reached. After reaching this limit, BaseCompaction will be triggered"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 5"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"base_compaction_min_data_ratio",children:(0,r.jsx)(i.code,{children:"base_compaction_min_data_ratio"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: One of the trigger conditions of BaseCompaction: Cumulative file size reaches the proportion of Base file"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 0.3 (30%)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"total_permits_for_compaction_score",children:(0,r.jsx)(i.code,{children:"total_permits_for_compaction_score"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int64"}),"\n",(0,r.jsx)(i.li,{children:'Description: The upper limit of "permits" held by all compaction tasks. This config can be set to limit memory consumption for compaction.'}),"\n",(0,r.jsx)(i.li,{children:"Default value: 10000"}),"\n",(0,r.jsx)(i.li,{children:"Dynamically modifiable: Yes"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"compaction_promotion_size_mbytes",children:(0,r.jsx)(i.code,{children:"compaction_promotion_size_mbytes"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int64"}),"\n",(0,r.jsxs)(i.li,{children:["Description: The total disk size of the output rowset of cumulative compaction exceeds this configuration size, and the rowset will be used for base compaction. The unit is m bytes.\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Generally, if the configuration is less than 2G, in order to prevent the cumulative compression time from being too long, resulting in the version backlog."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1024"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"compaction_promotion_ratio",children:(0,r.jsx)(i.code,{children:"compaction_promotion_ratio"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: double"}),"\n",(0,r.jsxs)(i.li,{children:["Description: When the total disk size of the cumulative compaction output rowset exceeds the configuration ratio of the base version rowset, the rowset will be used for base compaction.\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Generally, it is recommended that the configuration should not be higher than 0.1 and lower than 0.02."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 0.05"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"compaction_promotion_min_size_mbytes",children:(0,r.jsx)(i.code,{children:"compaction_promotion_min_size_mbytes"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int64"}),"\n",(0,r.jsxs)(i.li,{children:["Description: If the total disk size of the output rowset of the cumulative compaction is lower than this configuration size, the rowset will not undergo base compaction and is still in the cumulative compaction process. The unit is m bytes.\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Generally, the configuration is within 512m. If the configuration is too large, the size of the early base version is too small, and base compaction has not been performed."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 128"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"compaction_min_size_mbytes",children:(0,r.jsx)(i.code,{children:"compaction_min_size_mbytes"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int64"}),"\n",(0,r.jsxs)(i.li,{children:["Description: When the cumulative compaction is merged, the selected rowsets to be merged have a larger disk size than this configuration, then they are divided and merged according to the level policy. When it is smaller than this configuration, merge directly. The unit is m bytes.\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Generally, the configuration is within 128m. Over configuration will cause more cumulative compaction write amplification."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 64"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"default_rowset_type",children:(0,r.jsx)(i.code,{children:"default_rowset_type"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: string"}),"\n",(0,r.jsxs)(i.li,{children:['Description: Identifies the storage format selected by BE by default. The configurable parameters are: "',(0,r.jsx)(i.strong,{children:"ALPHA"}),'", "',(0,r.jsx)(i.strong,{children:"BETA"}),'". Mainly play the following two roles\n',(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"When the storage_format of the table is set to Default, select the storage format of BE through this configuration."}),"\n",(0,r.jsx)(i.li,{children:"Select the storage format of when BE performing Compaction"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: BETA"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"cumulative_compaction_min_deltas",children:(0,r.jsx)(i.code,{children:"cumulative_compaction_min_deltas"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Cumulative compaction strategy: the minimum number of incremental files"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 5"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"cumulative_compaction_max_deltas",children:(0,r.jsx)(i.code,{children:"cumulative_compaction_max_deltas"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Cumulative compaction strategy: the maximum number of incremental files"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1000"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"base_compaction_trace_threshold",children:(0,r.jsx)(i.code,{children:"base_compaction_trace_threshold"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: Threshold to logging base compaction's trace information, in seconds"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 10"}),"\n"]}),"\n",(0,r.jsx)(i.p,{children:"Base compaction is a long time cost background task, this configuration is the threshold to logging trace information. Trace information in log file looks like:"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{children:"W0610 11:26:33.804431 56452 storage_engine.cpp:552] execute base compaction cost 0.00319222\nBaseCompaction:546859:\n  - filtered_rows: 0\n   - input_row_num: 10\n   - input_rowsets_count: 10\n   - input_rowsets_data_size: 2.17 KB\n   - input_segments_num: 10\n   - merge_rowsets_latency: 100000.510ms\n   - merged_rows: 0\n   - output_row_num: 10\n   - output_rowset_data_size: 224.00 B\n   - output_segments_num: 1\n0610 11:23:03.727535 (+     0us) storage_engine.cpp:554] start to perform base compaction\n0610 11:23:03.728961 (+  1426us) storage_engine.cpp:560] found best tablet 546859\n0610 11:23:03.728963 (+     2us) base_compaction.cpp:40] got base compaction lock\n0610 11:23:03.729029 (+    66us) base_compaction.cpp:44] rowsets picked\n0610 11:24:51.784439 (+108055410us) compaction.cpp:46] got concurrency lock and start to do compaction\n0610 11:24:51.784818 (+   379us) compaction.cpp:74] prepare finished\n0610 11:26:33.359265 (+101574447us) compaction.cpp:87] merge rowsets finished\n0610 11:26:33.484481 (+125216us) compaction.cpp:102] output rowset built\n0610 11:26:33.484482 (+     1us) compaction.cpp:106] check correctness finished\n0610 11:26:33.513197 (+ 28715us) compaction.cpp:110] modify rowsets finished\n0610 11:26:33.513300 (+   103us) base_compaction.cpp:49] compaction finished\n0610 11:26:33.513441 (+   141us) base_compaction.cpp:56] unused rowsets have been moved to GC queue\n"})}),"\n",(0,r.jsx)(i.h4,{id:"cumulative_compaction_trace_threshold",children:(0,r.jsx)(i.code,{children:"cumulative_compaction_trace_threshold"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsxs)(i.li,{children:["Description: Threshold to logging cumulative compaction's trace information, in seconds\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Similar to ",(0,r.jsx)(i.code,{children:"base_compaction_trace_threshold"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 2"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"compaction_task_num_per_disk",children:(0,r.jsx)(i.code,{children:"compaction_task_num_per_disk"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The number of compaction tasks which execute in parallel for a disk(HDD)."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 4"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"compaction_task_num_per_fast_disk",children:(0,r.jsx)(i.code,{children:"compaction_task_num_per_fast_disk"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The number of compaction tasks which execute in parallel for a fast disk(SSD)."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 8"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"cumulative_compaction_rounds_for_each_base_compaction_round",children:(0,r.jsx)(i.code,{children:"cumulative_compaction_rounds_for_each_base_compaction_round"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: How many rounds of cumulative compaction for each round of base compaction when compaction tasks generation."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 9"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"max_cumu_compaction_threads",children:(0,r.jsx)(i.code,{children:"max_cumu_compaction_threads"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The maximum of thread number in cumulative compaction thread pool, -1 means one thread per disk."}),"\n",(0,r.jsx)(i.li,{children:"Default value: -1"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"enable_segcompaction",children:(0,r.jsx)(i.code,{children:"enable_segcompaction"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: bool"}),"\n",(0,r.jsx)(i.li,{children:"Description: Enable to use segment compaction during loading to avoid -238 error"}),"\n",(0,r.jsx)(i.li,{children:"Default value: true"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"segcompaction_batch_size",children:(0,r.jsx)(i.code,{children:"segcompaction_batch_size"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: Segment compaction is triggered when the number of segments exceeds this threshold. This configuration also limits the maximum number of raw segments in a single segment compaction task."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 10"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"segcompaction_candidate_max_rows",children:(0,r.jsx)(i.code,{children:"segcompaction_candidate_max_rows"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: Max row count allowed in a single source segment, bigger segments will be skipped."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1048576"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"segcompaction_candidate_max_bytes",children:(0,r.jsx)(i.code,{children:"segcompaction_candidate_max_bytes"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int64"}),"\n",(0,r.jsx)(i.li,{children:"Description: Max file size allowed in a single source segment, bigger segments will be skipped."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 104857600"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"segcompaction_task_max_rows",children:(0,r.jsx)(i.code,{children:"segcompaction_task_max_rows"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: Max total row count allowed in a single segcompaction task."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1572864"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"segcompaction_task_max_bytes",children:(0,r.jsx)(i.code,{children:"segcompaction_task_max_bytes"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int64"}),"\n",(0,r.jsx)(i.li,{children:"Description: Max total file size allowed in a single segcompaction task."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 157286400"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"segcompaction_num_threads",children:(0,r.jsx)(i.code,{children:"segcompaction_num_threads"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: Global segcompaction thread pool size."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 5"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"disable_compaction_trace_log",children:(0,r.jsx)(i.code,{children:"disable_compaction_trace_log"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: bool"}),"\n",(0,r.jsxs)(i.li,{children:["Description: disable the trace log of compaction\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["If set to true, the ",(0,r.jsx)(i.code,{children:"cumulative_compaction_trace_threshold"})," and ",(0,r.jsx)(i.code,{children:"base_compaction_trace_threshold"})," won't work and log is disabled."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: true"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"pick_rowset_to_compact_interval_sec",children:(0,r.jsx)(i.code,{children:"pick_rowset_to_compact_interval_sec"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int64"}),"\n",(0,r.jsx)(i.li,{children:"Description: select the time interval in seconds for rowset to be compacted."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 86400"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"max_single_replica_compaction_threads",children:(0,r.jsx)(i.code,{children:"max_single_replica_compaction_threads"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The maximum of thread number in single replica compaction thread pool. -1 means one thread per disk."}),"\n",(0,r.jsx)(i.li,{children:"Default value: -1"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"update_replica_infos_interval_seconds",children:(0,r.jsx)(i.code,{children:"update_replica_infos_interval_seconds"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: Minimal interval (s) to update peer replica infos"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 60 (s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"cold_data_compaction_score_threshold",children:(0,r.jsx)(i.code,{children:"cold_data_compaction_score_threshold"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: This configuration specifies the minimum compaction score threshold for cold data before triggering compaction. When the compaction score of cold data exceeds this threshold, compaction will be considered. Adjusting this value helps control the frequency and aggressiveness of compaction on cold data in remote storage. Supported since 3.1.3."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 100"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"cold_data_compaction_thread_num",children:(0,r.jsx)(i.code,{children:"cold_data_compaction_thread_num"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The number of threads used for cold data compaction. This configuration controls the degree of parallelism for cold data compaction tasks. Increasing this value allows more compaction tasks on cold data to run simultaneously, which may improve throughput but also increase resource usage."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 2"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"cold_data_compaction_interval_sec",children:(0,r.jsx)(i.code,{children:"cold_data_compaction_interval_sec"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The time interval in seconds between triggers for cold data compaction. A shorter interval means compaction on cold data will be considered more frequently, potentially leading to faster cleanup but higher resource consumption."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1800 (seconds)"}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"load",children:"Load"}),"\n",(0,r.jsx)(i.h4,{id:"enable_stream_load_record",children:(0,r.jsx)(i.code,{children:"enable_stream_load_record"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: bool"}),"\n",(0,r.jsx)(i.li,{children:"Description:Whether to enable stream load record function, the default is false."}),"\n",(0,r.jsx)(i.li,{children:"Default value: false"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"load_data_reserve_hours",children:(0,r.jsx)(i.code,{children:"load_data_reserve_hours"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Used for mini load. The mini load data file will be deleted after this time"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 4 (h)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"push_worker_count_high_priority",children:(0,r.jsx)(i.code,{children:"push_worker_count_high_priority"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Import the number of threads for processing HIGH priority tasks"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 3"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"push_worker_count_normal_priority",children:(0,r.jsx)(i.code,{children:"push_worker_count_normal_priority"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Import the number of threads for processing NORMAL priority tasks"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 3"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"enable_single_replica_load",children:(0,r.jsx)(i.code,{children:"enable_single_replica_load"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Whether to enable the single-copy data import function"}),"\n",(0,r.jsx)(i.li,{children:"Default value: true"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"load_error_log_reserve_hours",children:(0,r.jsx)(i.code,{children:"load_error_log_reserve_hours"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The load error log will be deleted after this time"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 48 (h)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"load_error_log_limit_bytes",children:(0,r.jsx)(i.code,{children:"load_error_log_limit_bytes"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The loading error logs larger than this value will be truncated"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 209715200 (byte)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"load_process_max_memory_limit_percent",children:(0,r.jsx)(i.code,{children:"load_process_max_memory_limit_percent"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Description: The percentage of the upper memory limit occupied by all imported threads on a single node, the default is 50%\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Set these default values very large, because we don't want to affect load performance when users upgrade Doris. If necessary, the user should set these configurations correctly"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 50 (%)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"load_process_soft_mem_limit_percent",children:(0,r.jsx)(i.code,{children:"load_process_soft_mem_limit_percent"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The soft limit refers to the proportion of the load memory limit of a single node. For example, the load memory limit for all load tasks is 20GB, and the soft limit defaults to 50% of this value, that is, 10GB. When the load memory usage exceeds the soft limit, the job with the largest memory consumption will be selected to be flushed to release the memory space, the default is 50%"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 50 (%)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"slave_replica_writer_rpc_timeout_sec",children:(0,r.jsx)(i.code,{children:"slave_replica_writer_rpc_timeout_sec"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: This configuration is mainly used to modify timeout of brpc between master replica and slave replica, used for single replica load."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 60"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"max_segment_num_per_rowset",children:(0,r.jsx)(i.code,{children:"max_segment_num_per_rowset"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: Used to limit the number of segments in the newly generated rowset when importing. If the threshold is exceeded, the import will fail with error -238. Too many segments will cause compaction to take up a lot of memory and cause OOM errors."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 200"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"high_priority_flush_thread_num_per_store",children:(0,r.jsx)(i.code,{children:"high_priority_flush_thread_num_per_store"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The number of flush threads per store path allocated for the high priority import task."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"routine_load_consumer_pool_size",children:(0,r.jsx)(i.code,{children:"routine_load_consumer_pool_size"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The number of caches for the data consumer used by the routine load."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 10"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"multi_table_batch_plan_threshold",children:(0,r.jsx)(i.code,{children:"multi_table_batch_plan_threshold"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: For single-stream-multi-table load. When receive a batch of messages from kafka, if the size of batch is more than this threshold, we will request plans for all related tables."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 200"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"multi_table_max_wait_tables",children:(0,r.jsx)(i.code,{children:"multi_table_max_wait_tables"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: Used in single-stream-multi-table load. When receiving a batch of messages from Kafka, if the size of the table wait for plan is more than this threshold, we will request plans for all related tables.The param is aimed to avoid requesting and executing too many plans at once. Performing small batch processing on multiple tables during the loaded process can reduce the pressure of a single RPC and improve the real-time processing of data."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 5"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"single_replica_load_download_num_workers",children:(0,r.jsx)(i.code,{children:"single_replica_load_download_num_workers"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsxs)(i.li,{children:["Description:This configuration is mainly used to modify the number of http worker threads for segment download, used for single replica load. When the load concurrency increases, you can adjust this parameter to ensure that the Slave replica synchronizes data files from the Master replica timely. If needed, ",(0,r.jsx)(i.code,{children:"webserver_num_workers"})," should also be increased for better IO performance."]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 64"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"load_task_high_priority_threshold_second",children:(0,r.jsx)(i.code,{children:"load_task_high_priority_threshold_second"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: When the timeout of an import task is less than this threshold, Doris will consider it to be a high priority task. High priority tasks use a separate pool of flush threads."}),"\n",(0,r.jsx)(i.li,{children:"Default: 120"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"min_load_rpc_timeout_ms",children:(0,r.jsx)(i.code,{children:"min_load_rpc_timeout_ms"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The minimum timeout for each rpc in the load job."}),"\n",(0,r.jsx)(i.li,{children:"Default: 20"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"kafka_api_version_request",children:(0,r.jsx)(i.code,{children:"kafka_api_version_request"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: bool"}),"\n",(0,r.jsx)(i.li,{children:"Description: If the dependent Kafka version is lower than 0.10.0.0, this value should be set to false."}),"\n",(0,r.jsx)(i.li,{children:"Default: true"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"kafka_broker_version_fallback",children:(0,r.jsx)(i.code,{children:"kafka_broker_version_fallback"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: If the dependent Kafka version is lower than 0.10.0.0, the value set by the fallback version kafka_broker_version_fallback will be used if the value of kafka_api_version_request is set to false, and the valid values are: 0.9.0.x, 0.8.x.y."}),"\n",(0,r.jsx)(i.li,{children:"Default: 0.10.0"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"max_consumer_num_per_group",children:(0,r.jsx)(i.code,{children:"max_consumer_num_per_group"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The maximum number of consumers in a data consumer group, used for routine load"}),"\n",(0,r.jsx)(i.li,{children:"Default: 3"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"streaming_load_max_mb",children:(0,r.jsx)(i.code,{children:"streaming_load_max_mb"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int64"}),"\n",(0,r.jsxs)(i.li,{children:["Description: Used to limit the maximum amount of csv data allowed in one Stream load.\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Stream Load is generally suitable for loading data less than a few GB, not suitable for loading too large data."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 10240 (MB)"}),"\n",(0,r.jsx)(i.li,{children:"Dynamically modifiable: Yes"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"streaming_load_json_max_mb",children:(0,r.jsx)(i.code,{children:"streaming_load_json_max_mb"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int64"}),"\n",(0,r.jsxs)(i.li,{children:["Description: it is used to limit the maximum amount of json data allowed in one Stream load. The unit is MB.\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Some data formats, such as JSON, cannot be split. Doris must read all the data into the memory before parsing can begin. Therefore, this value is used to limit the maximum amount of data that can be loaded in a single Stream load."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 100"}),"\n",(0,r.jsx)(i.li,{children:"Dynamically modifiable: Yes"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"olap_table_sink_send_interval_microseconds",children:(0,r.jsx)(i.code,{children:"olap_table_sink_send_interval_microseconds"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Description: While loading data, there's a polling thread keep sending data to corresponding BE from Coordinator's sink node. This thread will check whether there's data to send every ",(0,r.jsx)(i.code,{children:"olap_table_sink_send_interval_microseconds"})," microseconds."]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1000"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"olap_table_sink_send_interval_auto_partition_factor",children:(0,r.jsx)(i.code,{children:"olap_table_sink_send_interval_auto_partition_factor"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Description: If we load data to a table which enabled auto partition. the interval of ",(0,r.jsx)(i.code,{children:"olap_table_sink_send_interval_microseconds"})," is too slow. In that case the real interval will multiply this factor."]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 0.001"}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"thread",children:"Thread"}),"\n",(0,r.jsx)(i.h4,{id:"delete_worker_count",children:(0,r.jsx)(i.code,{children:"delete_worker_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Number of threads performing data deletion tasks"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 3"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"clear_transaction_task_worker_count",children:(0,r.jsx)(i.code,{children:"clear_transaction_task_worker_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Number of threads used to clean up transactions"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"clone_worker_count",children:(0,r.jsx)(i.code,{children:"clone_worker_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Number of threads used to perform cloning tasks"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 3"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"be_service_threads",children:(0,r.jsx)(i.code,{children:"be_service_threads"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The number of execution threads of the thrift server service on BE which represents the number of threads that can be used to execute FE requests."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 64"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"download_worker_count",children:(0,r.jsx)(i.code,{children:"download_worker_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The number of download threads."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"drop_tablet_worker_count",children:(0,r.jsx)(i.code,{children:"drop_tablet_worker_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Number of threads to delete tablet"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 3"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"flush_thread_num_per_store",children:(0,r.jsx)(i.code,{children:"flush_thread_num_per_store"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The number of threads used to refresh the memory table per store"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 2"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"publish_version_worker_count",children:(0,r.jsx)(i.code,{children:"publish_version_worker_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: the count of thread to publish version"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 8"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"upload_worker_count",children:(0,r.jsx)(i.code,{children:"upload_worker_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Maximum number of threads for uploading files"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"webserver_num_workers",children:(0,r.jsx)(i.code,{children:"webserver_num_workers"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Webserver default number of worker threads"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 48"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"send_batch_thread_pool_thread_num",children:(0,r.jsx)(i.code,{children:"send_batch_thread_pool_thread_num"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The number of threads in the SendBatch thread pool. In NodeChannels' sending data tasks, the SendBatch operation of each NodeChannel will be submitted as a thread task to the thread pool to be scheduled. This parameter determines the size of the SendBatch thread pool."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 64"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"send_batch_thread_pool_queue_size",children:(0,r.jsx)(i.code,{children:"send_batch_thread_pool_queue_size"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The queue length of the SendBatch thread pool. In NodeChannels' sending data tasks,  the SendBatch operation of each NodeChannel will be submitted as a thread task to the thread pool waiting to be scheduled, and after the number of submitted tasks exceeds the length of the thread pool queue, subsequent submitted tasks will be blocked until there is a empty slot in the queue."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 102400"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"make_snapshot_worker_count",children:(0,r.jsx)(i.code,{children:"make_snapshot_worker_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Number of threads making snapshots"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 5"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"release_snapshot_worker_count",children:(0,r.jsx)(i.code,{children:"release_snapshot_worker_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Number of threads releasing snapshots"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 5"}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"memory",children:"Memory"}),"\n",(0,r.jsx)(i.h4,{id:"madvise_huge_pages",children:(0,r.jsx)(i.code,{children:"madvise_huge_pages"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: bool"}),"\n",(0,r.jsx)(i.li,{children:"Description: Whether to use linux memory huge pages."}),"\n",(0,r.jsx)(i.li,{children:"Default value: false"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"max_memory_sink_batch_count",children:(0,r.jsx)(i.code,{children:"max_memory_sink_batch_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The maximum external scan cache batch count, which means that the cache max_memory_cache_batch_count * batch_size row, the default is 20, and the default value of batch_size is 1024, which means that 20 * 1024 rows will be cached"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 20"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"memory_max_alignment",children:(0,r.jsx)(i.code,{children:"memory_max_alignment"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Maximum alignment memory"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 16"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"mmap_buffers",children:(0,r.jsx)(i.code,{children:"mmap_buffers"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Whether to use mmap to allocate memory"}),"\n",(0,r.jsx)(i.li,{children:"Default value: false"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"memtable_mem_tracker_refresh_interval_ms",children:(0,r.jsx)(i.code,{children:"memtable_mem_tracker_refresh_interval_ms"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Interval in milliseconds between memtable flush mgr refresh iterations"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 100"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"zone_map_row_num_threshold",children:(0,r.jsx)(i.code,{children:"zone_map_row_num_threshold"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: If the number of rows in a page is less than this value, no zonemap will be created to reduce data expansion"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 20"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"memory_mode",children:(0,r.jsx)(i.code,{children:"memory_mode"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: string"}),"\n",(0,r.jsx)(i.li,{children:"Description: Control gc of tcmalloc, in performance mode Doris releases memory of tcmalloc cache when usage >= 90% * mem_limit, otherwise, doris releases memory of tcmalloc cache when usage >= 50% * mem_limit;"}),"\n",(0,r.jsx)(i.li,{children:"Default value: performance"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"max_sys_mem_available_low_water_mark_bytes",children:(0,r.jsx)(i.code,{children:"max_sys_mem_available_low_water_mark_bytes"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int64"}),"\n",(0,r.jsxs)(i.li,{children:["Description: The maximum low water mark of the system ",(0,r.jsx)(i.code,{children:"/proc/meminfo/MemAvailable"}),", Unit byte, default 1.6G, actual low water mark=min(1.6G, MemTotal * 10%), avoid wasting too much memory on machines with large memory larger than 16G. Turn up max. On machines with more than 16G memory, more memory buffers will be reserved for Full GC. Turn down max. will use as much memory as possible."]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1717986918"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"memory_limitation_per_thread_for_schema_change_bytes",children:(0,r.jsx)(i.code,{children:"memory_limitation_per_thread_for_schema_change_bytes"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Maximum memory allowed for a single schema change task"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 2147483648 (2GB)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"mem_tracker_consume_min_size_bytes",children:(0,r.jsx)(i.code,{children:"mem_tracker_consume_min_size_bytes"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The minimum length of TCMalloc Hook when consume/release MemTracker. Consume size smaller than this value will continue to accumulate to avoid frequent calls to consume/release of MemTracker. Decreasing this value will increase the frequency of consume/release. Increasing this value will cause MemTracker statistics to be inaccurate. Theoretically, the statistical value of a MemTracker differs from the true value = ( mem_tracker_consume_min_size_bytes * the number of BE threads where the MemTracker is located)."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1,048,576"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"min_buffer_size",children:(0,r.jsx)(i.code,{children:"min_buffer_size"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Minimum read buffer size"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1024 (byte)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"write_buffer_size",children:(0,r.jsx)(i.code,{children:"write_buffer_size"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Description: The size of the buffer before flashing\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Imported data is first written to a memory block on the BE, and only written back to disk when this memory block reaches the threshold. The default size is 100MB. too small a threshold may result in a large number of small files on the BE. This threshold can be increased to reduce the number of files. However, too large a threshold may cause RPC timeouts"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 104,857,600"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"remote_storage_read_buffer_mb",children:(0,r.jsx)(i.code,{children:"remote_storage_read_buffer_mb"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsxs)(i.li,{children:["Description: The cache size used when reading files on hdfs or object storage.\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Increasing this value can reduce the number of calls to read remote data, but it will increase memory overhead."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 16 (MB)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"file_cache_type",children:(0,r.jsx)(i.code,{children:"file_cache_type"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: string"}),"\n",(0,r.jsxs)(i.li,{children:["Description: Type of cache file.",(0,r.jsx)(i.code,{children:"whole_file_cache"}),": download the entire segment file, ",(0,r.jsx)(i.code,{children:"sub_file_cache"}),': the segment file is divided into multiple files by size. if set "", no cache, please set this parameter when caching is required.']}),"\n",(0,r.jsx)(i.li,{children:'Default value: ""'}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"path_gc_check",children:(0,r.jsx)(i.code,{children:"path_gc_check"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type\uFF1Abool"}),"\n",(0,r.jsx)(i.li,{children:"Description: Whether to enable the recycle scan data thread check"}),"\n",(0,r.jsx)(i.li,{children:"Default\uFF1Atrue"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"path_gc_check_interval_second",children:(0,r.jsx)(i.code,{children:"path_gc_check_interval_second"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Recycle scan data thread check interval"}),"\n",(0,r.jsx)(i.li,{children:"Default\uFF1A86400 (s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"path_gc_check_step",children:(0,r.jsx)(i.code,{children:"path_gc_check_step"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Default\uFF1A1000"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"path_gc_check_step_interval_ms",children:(0,r.jsx)(i.code,{children:"path_gc_check_step_interval_ms"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Default\uFF1A10 (ms)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"scan_context_gc_interval_min",children:(0,r.jsx)(i.code,{children:"scan_context_gc_interval_min"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: This configuration is used for the context gc thread scheduling cycle. Note: The unit is minutes, and the default is 5 minutes"}),"\n",(0,r.jsx)(i.li,{children:"Default\uFF1A5"}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"storage",children:"Storage"}),"\n",(0,r.jsx)(i.h4,{id:"default_num_rows_per_column_file_block",children:(0,r.jsx)(i.code,{children:"default_num_rows_per_column_file_block"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: Configure how many rows of data are contained in a single RowBlock."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1024"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"disable_storage_page_cache",children:(0,r.jsx)(i.code,{children:"disable_storage_page_cache"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: bool"}),"\n",(0,r.jsx)(i.li,{children:"Description: Disable to use page cache for index caching, this configuration only takes effect in BETA storage format, usually it is recommended to false"}),"\n",(0,r.jsx)(i.li,{children:"Default value: false"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"disk_stat_monitor_interval",children:(0,r.jsx)(i.code,{children:"disk_stat_monitor_interval"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Disk status check interval"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 5 (s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"max_free_io_buffers",children:(0,r.jsx)(i.code,{children:"max_free_io_buffers"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: For each io buffer size, the maximum number of buffers that IoMgr will reserve ranges from 1024B to 8MB buffers, up to about 2GB buffers."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 128"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"max_garbage_sweep_interval",children:(0,r.jsx)(i.code,{children:"max_garbage_sweep_interval"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The maximum interval for disk garbage cleaning"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 3600 (s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"max_percentage_of_error_disk",children:(0,r.jsx)(i.code,{children:"max_percentage_of_error_disk"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: The storage engine allows the percentage of damaged hard disks to exist. After the damaged hard disk exceeds the changed ratio, BE will automatically exit."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 0"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"min_garbage_sweep_interval",children:(0,r.jsx)(i.code,{children:"min_garbage_sweep_interval"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The minimum interval between disk garbage cleaning"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 180 (s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"pprof_profile_dir",children:(0,r.jsx)(i.code,{children:"pprof_profile_dir"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: pprof profile save directory"}),"\n",(0,r.jsx)(i.li,{children:"Default value: ${DORIS_HOME}/log"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"small_file_dir",children:(0,r.jsx)(i.code,{children:"small_file_dir"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Save files downloaded by SmallFileMgr"}),"\n",(0,r.jsx)(i.li,{children:"Default value: ${DORIS_HOME}/lib/small_file/"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"user_function_dir",children:(0,r.jsx)(i.code,{children:"user_function_dir"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: udf function directory"}),"\n",(0,r.jsxs)(i.li,{children:["Default value: ",(0,r.jsx)(i.code,{children:"${DORIS_HOME}/lib/udf"})]}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"storage_flood_stage_left_capacity_bytes",children:(0,r.jsx)(i.code,{children:"storage_flood_stage_left_capacity_bytes"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The min bytes that should be left of a data dir."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1073741824"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"storage_flood_stage_usage_percent",children:(0,r.jsx)(i.code,{children:"storage_flood_stage_usage_percent"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The storage_flood_stage_usage_percent and storage_flood_stage_left_capacity_bytes configurations limit the maximum usage of the capacity of the data directory."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 90 (90%)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"storage_medium_migrate_count",children:(0,r.jsx)(i.code,{children:"storage_medium_migrate_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: the count of thread to clone"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"storage_page_cache_limit",children:(0,r.jsx)(i.code,{children:"storage_page_cache_limit"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Cache for storage page size"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 20%"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"storage_page_cache_shard_size",children:(0,r.jsx)(i.code,{children:"storage_page_cache_shard_size"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Shard size of StoragePageCache, the value must be power of two. It's recommended to set it to a value close to the number of BE cores in order to reduce lock contentions."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 16"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"index_page_cache_percentage",children:(0,r.jsx)(i.code,{children:"index_page_cache_percentage"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: Index page cache as a percentage of total storage page cache, value range is [0, 100]"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 10"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"segment_cache_capacity",children:(0,r.jsx)(i.code,{children:"segment_cache_capacity"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsx)(i.li,{children:"Description: Max number of segment cache (the key is rowset id) entries. -1 is for backward compatibility as fd_number * 2/5."}),"\n",(0,r.jsx)(i.li,{children:"Default value: -1"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"storage_strict_check_incompatible_old_format",children:(0,r.jsx)(i.code,{children:"storage_strict_check_incompatible_old_format"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: bool"}),"\n",(0,r.jsx)(i.li,{children:"Description: Used to check incompatible old format strictly"}),"\n",(0,r.jsx)(i.li,{children:"Default value: true"}),"\n",(0,r.jsx)(i.li,{children:"Dynamically modify: false"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"sync_tablet_meta",children:(0,r.jsx)(i.code,{children:"sync_tablet_meta"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Whether the storage engine opens sync and keeps it to the disk"}),"\n",(0,r.jsx)(i.li,{children:"Default value: true"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"pending_data_expire_time_sec",children:(0,r.jsx)(i.code,{children:"pending_data_expire_time_sec"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The maximum duration of unvalidated data retained by the storage engine"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1800 (s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"ignore_rowset_stale_unconsistent_delete",children:(0,r.jsx)(i.code,{children:"ignore_rowset_stale_unconsistent_delete"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: boolean"}),"\n",(0,r.jsxs)(i.li,{children:["Description:It is used to decide whether to delete the outdated merged rowset if it cannot form a consistent version path.\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"The merged expired rowset version path will be deleted after half an hour. In abnormal situations, deleting these versions will result in the problem that the consistent path of the query cannot be constructed. When the configuration is false, the program check is strict and the program will directly report an error and exit.When configured as true, the program will run normally and ignore this error. In general, ignoring this error will not affect the query, only when the merged version is dispatched by fe, -230 error will appear."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: false"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"create_tablet_worker_count",children:(0,r.jsx)(i.code,{children:"create_tablet_worker_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Number of worker threads for BE to create a tablet"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 3"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"check_consistency_worker_count",children:(0,r.jsx)(i.code,{children:"check_consistency_worker_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The number of worker threads to calculate the checksum of the tablet"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"max_tablet_version_num",children:(0,r.jsx)(i.code,{children:"max_tablet_version_num"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int"}),"\n",(0,r.jsx)(i.li,{children:"Description: Limit the number of versions of a single tablet. It is used to prevent a large number of version accumulation problems caused by too frequent import or untimely compaction. When the limit is exceeded, the import task will be rejected."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 2000"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"tablet_map_shard_size",children:(0,r.jsx)(i.code,{children:"tablet_map_shard_size"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: tablet_map_lock fragment size, the value is 2^n, n=0,1,2,3,4, this is for better tablet management"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 4"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"tablet_meta_checkpoint_min_interval_secs",children:(0,r.jsx)(i.code,{children:"tablet_meta_checkpoint_min_interval_secs"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: TabletMeta Checkpoint \u7EBF\u7A0B\u8F6E\u8BE2\u7684\u65F6\u95F4\u95F4\u9694"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 600 (s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"tablet_meta_checkpoint_min_new_rowsets_num",children:(0,r.jsx)(i.code,{children:"tablet_meta_checkpoint_min_new_rowsets_num"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The minimum number of Rowsets for storing TabletMeta Checkpoints"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 10"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"tablet_rowset_stale_sweep_time_sec",children:(0,r.jsx)(i.code,{children:"tablet_rowset_stale_sweep_time_sec"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int64"}),"\n",(0,r.jsxs)(i.li,{children:["Description: It is used to control the expiration time of cleaning up the merged rowset version. When the current time now() minus the max created rowset's create time in a version path is greater than tablet_rowset_stale_sweep_time_sec, the current path is cleaned up and these merged rowsets are deleted, the unit is second.\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"When writing is too frequent, Fe may not be able to query the merged version, resulting in a query -230 error. This problem can be avoided by increasing this parameter."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 300"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"tablet_writer_open_rpc_timeout_sec",children:(0,r.jsx)(i.code,{children:"tablet_writer_open_rpc_timeout_sec"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Description: Update interval of tablet state cache\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"The RPC timeout for sending a Batch (1024 lines) during import. The default is 60 seconds. Since this RPC may involve writing multiple batches of memory, the RPC timeout may be caused by writing batches, so this timeout can be adjusted to reduce timeout errors (such as send batch fail errors). Also, if you increase the write_buffer_size configuration, you need to increase this parameter as well."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 60"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"tablet_writer_ignore_eovercrowded",children:(0,r.jsx)(i.code,{children:"tablet_writer_ignore_eovercrowded"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: bool"}),"\n",(0,r.jsx)(i.li,{children:"Description: Used to ignore brpc error '[E1011]The server is overcrowded' when writing data."}),"\n",(0,r.jsx)(i.li,{children:"Default value: false"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"streaming_load_rpc_max_alive_time_sec",children:(0,r.jsx)(i.code,{children:"streaming_load_rpc_max_alive_time_sec"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The lifetime of TabletsChannel. If the channel does not receive any data at this time, the channel will be deleted."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 1200"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"alter_tablet_worker_count",children:(0,r.jsx)(i.code,{children:"alter_tablet_worker_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The number of threads making schema changes"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 3"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"alter_index_worker_count",children:(0,r.jsx)(i.code,{children:"alter_index_worker_count"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The number of threads making index change"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 3"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"ignore_load_tablet_failure",children:(0,r.jsx)(i.code,{children:"ignore_load_tablet_failure"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: bool"}),"\n",(0,r.jsx)(i.li,{children:"Description: It is used to decide whether to ignore errors and continue to start be in case of tablet loading failure"}),"\n",(0,r.jsx)(i.li,{children:"Default value: false"}),"\n"]}),"\n",(0,r.jsxs)(i.p,{children:["When BE starts, a separate thread will be started for each data directory to load the meta information of the tablet header. In the default configuration, if a data directory fails to load a tablet, the startup process will terminate. At the same time, it will be displayed in the ",(0,r.jsx)(i.code,{children:"be The following error message is seen in the INFO"})," log:"]}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{children:"load tablets from header failed, failed tablets size: xxx, path=xxx\n"})}),"\n",(0,r.jsx)(i.p,{children:"Indicates how many tablets failed to load in the data directory. At the same time, the log will also contain specific information about the tablets that failed to load. At this time, manual intervention is required to troubleshoot the cause of the error. After troubleshooting, there are usually two ways to restore:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["The tablet information cannot be repaired. If the other copies are normal, you can delete the wrong tablet with the ",(0,r.jsx)(i.code,{children:"meta_tool"})," tool."]}),"\n",(0,r.jsxs)(i.li,{children:["Set ",(0,r.jsx)(i.code,{children:"ignore_load_tablet_failure"})," to true, BE will ignore these faulty tablets and start normally"]}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"report_disk_state_interval_seconds",children:(0,r.jsx)(i.code,{children:"report_disk_state_interval_seconds"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The interval time for the agent to report the disk status to FE"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 60 (s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"result_buffer_cancelled_interval_time",children:(0,r.jsx)(i.code,{children:"result_buffer_cancelled_interval_time"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Result buffer cancellation time"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 300 (s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"snapshot_expire_time_sec",children:(0,r.jsx)(i.code,{children:"snapshot_expire_time_sec"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Snapshot file cleaning interval."}),"\n",(0,r.jsx)(i.li,{children:"Default value:172800 (48 hours)"}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"log",children:"Log"}),"\n",(0,r.jsx)(i.h4,{id:"sys_log_dir",children:(0,r.jsx)(i.code,{children:"sys_log_dir"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: string"}),"\n",(0,r.jsx)(i.li,{children:"Description: Storage directory of BE log data"}),"\n",(0,r.jsxs)(i.li,{children:["Default value: ",(0,r.jsx)(i.code,{children:"${DORIS_HOME}/log"})]}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"sys_log_level",children:(0,r.jsx)(i.code,{children:"sys_log_level"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Log Level: INFO < WARNING < ERROR < FATAL"}),"\n",(0,r.jsx)(i.li,{children:"Default value: INFO"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"sys_log_roll_mode",children:(0,r.jsx)(i.code,{children:"sys_log_roll_mode"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The size of the log split, one log file is split every 1G"}),"\n",(0,r.jsx)(i.li,{children:"Default value: SIZE-MB-1024"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"sys_log_roll_num",children:(0,r.jsx)(i.code,{children:"sys_log_roll_num"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Number of log files kept"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 10"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"sys_log_verbose_level",children:(0,r.jsx)(i.code,{children:"sys_log_verbose_level"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Log display level, used to control the log output at the beginning of VLOG in the code"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 10"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"sys_log_verbose_modules",children:(0,r.jsx)(i.code,{children:"sys_log_verbose_modules"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Log printing module, writing olap will only print the log under the olap module"}),"\n",(0,r.jsx)(i.li,{children:"Default value: empty"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"aws_log_level",children:(0,r.jsx)(i.code,{children:"aws_log_level"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int32"}),"\n",(0,r.jsxs)(i.li,{children:["Description: log level of AWS SDK,\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{children:"   Off = 0,\n   Fatal = 1,\n   Error = 2,\n   Warn = 3,\n   Info = 4,\n   Debug = 5,\n   Trace = 6\n"})}),"\n"]}),"\n",(0,r.jsx)(i.li,{children:"Default value: 3"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"log_buffer_level",children:(0,r.jsx)(i.code,{children:"log_buffer_level"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The log flushing strategy is kept in memory by default"}),"\n",(0,r.jsx)(i.li,{children:"Default value: empty"}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"others",children:"Others"}),"\n",(0,r.jsx)(i.h4,{id:"report_tablet_interval_seconds",children:(0,r.jsx)(i.code,{children:"report_tablet_interval_seconds"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The interval time for the agent to report the olap table to the FE"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 60 (s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"report_task_interval_seconds",children:(0,r.jsx)(i.code,{children:"report_task_interval_seconds"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The interval time for the agent to report the task signature to FE"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 10 (s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"periodic_counter_update_period_ms",children:(0,r.jsx)(i.code,{children:"periodic_counter_update_period_ms"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Update rate counter and sampling counter cycle"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 500 (ms)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"enable_metric_calculator",children:(0,r.jsx)(i.code,{children:"enable_metric_calculator"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: If set to true, the metric calculator will run to collect BE-related indicator information, if set to false, it will not run"}),"\n",(0,r.jsx)(i.li,{children:"Default value: true"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"enable_system_metrics",children:(0,r.jsx)(i.code,{children:"enable_system_metrics"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: User control to turn on and off system indicators."}),"\n",(0,r.jsx)(i.li,{children:"Default value: true"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"enable_token_check",children:(0,r.jsx)(i.code,{children:"enable_token_check"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Used for forward compatibility, will be removed later."}),"\n",(0,r.jsx)(i.li,{children:"Default value: true"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"max_runnings_transactions_per_txn_map",children:(0,r.jsx)(i.code,{children:"max_runnings_transactions_per_txn_map"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Max number of txns for every txn_partition_map in txn manager, this is a self protection to avoid too many txns saving in manager"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 2000"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"max_download_speed_kbps",children:(0,r.jsx)(i.code,{children:"max_download_speed_kbps"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Maximum download speed limit"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 50000 (kb/s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"download_low_speed_time",children:(0,r.jsx)(i.code,{children:"download_low_speed_time"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Download time limit"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 300 (s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"download_low_speed_limit_kbps",children:(0,r.jsx)(i.code,{children:"download_low_speed_limit_kbps"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Minimum download speed"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 50 (KB/s)"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"enable_batch_download",children:(0,r.jsx)(i.code,{children:"enable_batch_download"})}),"\n",(0,r.jsx)(i.admonition,{title:"Tips",type:"tip",children:(0,r.jsx)(i.p,{children:"This configuration is supported since the Apache Doris 3.0.4 version"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Whether to download files in batch, it is recommended to open it when the binlog is enabled."}),"\n",(0,r.jsx)(i.li,{children:"Default value: false"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"priority_queue_remaining_tasks_increased_frequency",children:(0,r.jsx)(i.code,{children:"priority_queue_remaining_tasks_increased_frequency"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: the increased frequency of priority for remaining tasks in BlockingPriorityQueue"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 512"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"jdbc_drivers_dir",children:(0,r.jsx)(i.code,{children:"jdbc_drivers_dir"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Default dirs to put jdbc drivers."}),"\n",(0,r.jsxs)(i.li,{children:["Default value: ",(0,r.jsx)(i.code,{children:"${DORIS_HOME}/jdbc_drivers"})]}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"enable_simdjson_reader",children:(0,r.jsx)(i.code,{children:"enable_simdjson_reader"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Whether enable simdjson to parse json while stream load"}),"\n",(0,r.jsx)(i.li,{children:"Default value: true"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"enable_query_memory_overcommit",children:(0,r.jsx)(i.code,{children:"enable_query_memory_overcommit"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Description: If true, when the process does not exceed the soft mem limit, the query memory will not be limited; when the process memory exceeds the soft mem limit, the query with the largest ratio between the currently used memory and the exec_mem_limit will be canceled. If false, cancel query when the memory used exceeds ",(0,r.jsx)(i.code,{children:"exec_mem_limit"}),"."]}),"\n",(0,r.jsx)(i.li,{children:"Default value: true"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"user_files_secure_path",children:(0,r.jsx)(i.code,{children:"user_files_secure_path"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Description: The storage directory for files queried by ",(0,r.jsx)(i.code,{children:"local"})," table valued functions."]}),"\n",(0,r.jsxs)(i.li,{children:["Default value: ",(0,r.jsx)(i.code,{children:"${DORIS_HOME}"})]}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"brpc_streaming_client_batch_bytes",children:(0,r.jsx)(i.code,{children:"brpc_streaming_client_batch_bytes"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: The batch size for sending data by brpc streaming client"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 262144"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"grace_shutdown_wait_seconds",children:(0,r.jsx)(i.code,{children:"grace_shutdown_wait_seconds"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: In cloud native deployment scenario, BE will be add to cluster and remove from cluster very frequently. User's query will fail if there is a fragment is running on the shuting down BE. Users could use stop_be.sh --grace, then BE will wait all running queries to stop to avoiding running query failure, but if the waiting time exceed the limit, then be will exit directly. During this period, FE will not send any queries to BE and waiting for all running queries to stop."}),"\n",(0,r.jsx)(i.li,{children:"Default value: 120"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"enable_java_support",children:(0,r.jsx)(i.code,{children:"enable_java_support"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: BE Whether to enable the use of java-jni. When enabled, mutual calls between c++ and java are allowed. Currently supports hudi, java-udf, jdbc, max-compute, paimon, preload, avro"}),"\n",(0,r.jsx)(i.li,{children:"Default value: true"}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"group_commit_wal_path",children:(0,r.jsx)(i.code,{children:"group_commit_wal_path"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["The ",(0,r.jsx)(i.code,{children:"WAL"})," directory of group commit."]}),"\n",(0,r.jsxs)(i.li,{children:["Default: A directory named ",(0,r.jsx)(i.code,{children:"wal"})," is created under each directory of the ",(0,r.jsx)(i.code,{children:"storage_root_path"}),". Configuration examples:\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{children:"group_commit_wal_path=/data1/storage/wal;/data2/storage/wal;/data3/storage/wal\n"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"compute-and-storage-disaggregated-mode",children:"Compute and Storage Disaggregated Mode"}),"\n",(0,r.jsx)(i.h4,{id:"deploy_mode-1",children:(0,r.jsx)(i.code,{children:"deploy_mode"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsx)(i.p,{children:'Default: ""'}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["\n",(0,r.jsxs)(i.p,{children:["Description:  The mode in which BE runs. ",(0,r.jsx)(i.code,{children:"cloud"})," indicates the decoupled storage-compute mode."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"meta_service_endpoint",children:(0,r.jsx)(i.code,{children:"meta_service_endpoint"})}),"\n",(0,r.jsx)(i.p,{children:'Default: ""'}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Endpoints of the meta service should be specified in the format 'host1:port,host2:port'. This value is usually delivered by the FE to the BE by the heartbeat, no need to configure."}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"enable_file_cache",children:(0,r.jsx)(i.code,{children:"enable_file_cache"})}),"\n",(0,r.jsx)(i.p,{children:"Default: true for cloud mode, false for non-cloud mode."}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Description: Whether to use file cache."}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"file_cache_path",children:(0,r.jsx)(i.code,{children:"file_cache_path"})}),"\n",(0,r.jsx)(i.p,{children:'Default: [{"path":"${DORIS_HOME}/file_cache"}]'}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["Description: The disk paths and other parameters used for file cache, represented as an array, with one entry for each disk. The ",(0,r.jsx)(i.code,{children:"path"})," specifies the disk path, and ",(0,r.jsx)(i.code,{children:"total_size"})," limits the size of the cache; -1 or 0 will use the entire disk space."]}),"\n",(0,r.jsx)(i.li,{children:'format: [{"path":"/path/to/file_cache","total_size":21474836480,{"path":"/path/to/file_cache2","total_size":21474836480}]'}),"\n"]}),"\n",(0,r.jsx)(i.h4,{id:"time_series_max_tablet_version_num",children:(0,r.jsx)(i.code,{children:"time_series_max_tablet_version_num"})}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Type: int"}),"\n",(0,r.jsx)(i.li,{children:"Description: Limit the number of versions of a single tablet under the time-series compaction policy. It is used to prevent a large number of version accumulation problems caused by too frequent load or untimely compaction. When the limit is exceeded, the load task will be rejected. Supported since version 3.0.7"}),"\n",(0,r.jsx)(i.li,{children:"Default value: 20000"}),"\n"]})]})}function h(e={}){let{wrapper:i}={...(0,t.a)(),...e.components};return i?(0,r.jsx)(i,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},250065:function(e,i,n){n.d(i,{Z:function(){return o},a:function(){return s}});var l=n(667294);let r={},t=l.createContext(r);function s(e){let i=l.useContext(t);return l.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function o(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),l.createElement(t.Provider,{value:i},e.children)}}}]);