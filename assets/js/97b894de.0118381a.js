"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["523139"],{352231:function(e,n,i){i.r(n),i.d(n,{default:()=>h,frontMatter:()=>a,metadata:()=>t,assets:()=>c,toc:()=>d,contentTitle:()=>o});var t=JSON.parse('{"id":"ai/vector-search/ivf","title":"IVF","description":"IVF index is an efficient data structure used for Approximate Nearest Neighbor (ANN) search. It helps narrow down the scope of vectors during search,","source":"@site/versioned_docs/version-4.x/ai/vector-search/ivf.md","sourceDirName":"ai/vector-search","slug":"/ai/vector-search/ivf","permalink":"/docs/4.x/ai/vector-search/ivf","draft":false,"unlisted":false,"tags":[],"version":"4.x","lastUpdatedAt":1770477659000,"frontMatter":{"title":"IVF","language":"en","description":"IVF index is an efficient data structure used for Approximate Nearest Neighbor (ANN) search. It helps narrow down the scope of vectors during search,"},"sidebar":"docs","previous":{"title":"HNSW","permalink":"/docs/4.x/ai/vector-search/hnsw"},"next":{"title":"ANN Index Management","permalink":"/docs/4.x/ai/vector-search/index-management"}}'),r=i("785893"),s=i("250065");let a={title:"IVF",language:"en",description:"IVF index is an efficient data structure used for Approximate Nearest Neighbor (ANN) search. It helps narrow down the scope of vectors during search,"},o="IVF and How to use it in Apache Doris",c={},d=[{value:"What is IVF index?",id:"what-is-ivf-index",level:2},{value:"Using IVF indexes for efficient vector search",id:"using-ivf-indexes-for-efficient-vector-search",level:2},{value:"IVF in Apache Doris",id:"ivf-in-apache-doris",level:2},{value:"Index Construction",id:"index-construction",level:3},{value:"CREATE/BUILD INDEX",id:"createbuild-index",level:4},{value:"DROP INDEX",id:"drop-index",level:4},{value:"Querying",id:"querying",level:3},{value:"Recall Optimization",id:"recall-optimization",level:3},{value:"Index Hyperparameters",id:"index-hyperparameters",level:4},{value:"Number of Rows Covered per Index",id:"number-of-rows-covered-per-index",level:4},{value:"Impact of Compaction on Recall",id:"impact-of-compaction-on-recall",level:4},{value:"Query Performance",id:"query-performance",level:3},{value:"Cold Loading of Index Files",id:"cold-loading-of-index-files",level:4},{value:"Memory Footprint vs. Performance",id:"memory-footprint-vs-performance",level:4},{value:"Benchmark",id:"benchmark",level:3},{value:"Performance768D1M",id:"performance768d1m",level:4}];function l(e){let n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"ivf-and-how-to-use-it-in-apache-doris",children:"IVF and How to use it in Apache Doris"})}),"\n",(0,r.jsx)(n.p,{children:"IVF index is an efficient data structure used for Approximate Nearest Neighbor (ANN) search. It helps narrow down the scope of vectors during search, significantly improving search speed. Since Apache Doris 4.x, an ANN index based on IVF has been supported. This document walks through the IVF algorithm, key parameters, and engineering practices, and explains how to build and tune IVF\u2011based ANN indexes in production Doris clusters."}),"\n",(0,r.jsx)(n.h2,{id:"what-is-ivf-index",children:"What is IVF index?"}),"\n",(0,r.jsx)(n.p,{children:"For completeness, here\u2019s some historical context. The term IVF (inverted file) originates from information retrieval."}),"\n",(0,r.jsxs)(n.p,{children:["Consider a simple example of a few text documents. To search documents that contain a given word, a\xa0",(0,r.jsx)(n.strong,{children:"forward index"}),"\xa0stores a list of words for each document. You must read each document explicitly to find the relevant ones."]}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Document"}),(0,r.jsx)(n.th,{children:"Words"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Document 1"}),(0,r.jsx)(n.td,{children:"the,cow,says,moo"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Document 2"}),(0,r.jsx)(n.td,{children:"the,cat,and,the,hat"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Document 3"}),(0,r.jsx)(n.td,{children:"the,dish,ran,away,with,the,spoon"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:["In contrast, an\xa0",(0,r.jsx)(n.strong,{children:"inverted index"}),"\xa0would contain a dictionary of all the words that you can search, and for each word, you have a list of document indices where the word occurs. This is the inverted list (inverted file), and it enables you to restrict the search to the selected lists."]}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Word"}),(0,r.jsx)(n.th,{children:"Documents"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"the"}),(0,r.jsx)(n.td,{children:"Document 1, Document 3, Document 4, Document 5, Document 7"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"cow"}),(0,r.jsx)(n.td,{children:"Document 2, Document 3, Document 4"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"says"}),(0,r.jsx)(n.td,{children:"Document 5"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"moo"}),(0,r.jsx)(n.td,{children:"Document 7"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Today, text data is often represented as vector embeddings. The IVF method defines cluster centers and these centers are analogous to the dictionary of words in the preceding example. For each cluster center, you have a list of vector indices that belong to the cluster, and search is accelerated because you only have to inspect the selected clusters."}),"\n",(0,r.jsx)(n.h2,{id:"using-ivf-indexes-for-efficient-vector-search",children:"Using IVF indexes for efficient vector search"}),"\n",(0,r.jsx)(n.p,{children:"As datasets grow to millions or even billions of vectors, performing an exhaustive exact k-nearest neighbor (kNN) search, calculating the distance between a query and every single vector in the database becomes computationally prohibitive. This brute-force approach, equivalent to a large matrix multiplication, doesn't scale."}),"\n",(0,r.jsx)(n.p,{children:"Fortunately, many applications can trade a small amount of accuracy for a massive gain in speed. This is the domain of\xa0Approximate Nearest Neighbor (ANN)\xa0search, and the\xa0Inverted File (IVF)\xa0index is one of the most widely used and effective ANN methods."}),"\n",(0,r.jsx)(n.p,{children:'The fundamental principle behind IVF is "partition and conquer." Instead of searching the entire dataset, IVF intelligently narrows the search scope to a few promising regions, drastically reducing the number of comparisons needed.'}),"\n",(0,r.jsx)(n.p,{children:'IVF works by partitioning a large dataset of vectors into smaller, manageable clusters, each represented by a central point called a\xa0"centroid."\xa0These centroids act as anchors for their respective partitions. During a search, the system quickly identifies the clusters whose centroids are closest to the query vector and only searches within those, ignoring the rest of the dataset.'}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"ivf search",src:i(614918).Z+"",width:"1999",height:"814"})}),"\n",(0,r.jsx)(n.h2,{id:"ivf-in-apache-doris",children:"IVF in Apache Doris"}),"\n",(0,r.jsx)(n.p,{children:"Apache Doris supports building IVF\u2011based ANN indexes starting from version 4.x."}),"\n",(0,r.jsx)(n.h3,{id:"index-construction",children:"Index Construction"}),"\n",(0,r.jsxs)(n.p,{children:["The index type used here is ANN. There are two ways to create an ANN index: you can define it when creating the table, or you can use the ",(0,r.jsx)(n.code,{children:"CREATE/BUILD INDEX"})," syntax. The two approaches differ in how and when the index is built, and therefore fit different scenarios."]}),"\n",(0,r.jsx)(n.p,{children:"Approach 1: define an ANN index on a vector column when creating the table. As data is loaded, an ANN index is built for each segment as it is created. The advantage is that once data loading completes, the index is already built and queries can immediately use it for acceleration. The downside is that synchronous index building slows down data ingestion and may cause extra index rebuilds during compaction, leading to some waste of resources."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE sift_1M (\n  id int NOT NULL,\n  embedding array<float>  NOT NULL  COMMENT "",\n  INDEX ann_index (embedding) USING ANN PROPERTIES(\n      "index_type"="ivf",\n      "metric_type"="l2_distance",\n      "dim"="128",\n      "nlist"="1024"\n  )\n) ENGINE=OLAP\nDUPLICATE KEY(id) COMMENT "OLAP"\nDISTRIBUTED BY HASH(id) BUCKETS 1\nPROPERTIES (\n  "replication_num" = "1"\n);\n\nINSERT INTO sift_1M\nSELECT *\nFROM S3(\n  "uri" = "https://selectdb-customers-tools-bj.oss-cn-beijing.aliyuncs.com/sift_database.tsv",\n  "format" = "csv");\n'})}),"\n",(0,r.jsx)(n.h4,{id:"createbuild-index",children:"CREATE/BUILD INDEX"}),"\n",(0,r.jsxs)(n.p,{children:["Approach 2: ",(0,r.jsx)(n.code,{children:"CREATE/BUILD INDEX"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE sift_1M (\n  id int NOT NULL,\n  embedding array<float>  NOT NULL  COMMENT ""\n) ENGINE=OLAP\nDUPLICATE KEY(id) COMMENT "OLAP"\nDISTRIBUTED BY HASH(id) BUCKETS 1\nPROPERTIES (\n  "replication_num" = "1"\n);\n\nINSERT INTO sift_1M\nSELECT *\nFROM S3(\n  "uri" = "https://selectdb-customers-tools-bj.oss-cn-beijing.aliyuncs.com/sift_database.tsv",\n  "format" = "csv");\n'})}),"\n",(0,r.jsxs)(n.p,{children:["After data is loaded, you can run ",(0,r.jsx)(n.code,{children:"CREATE INDEX"}),". At this point the index is defined on the table, but no index is yet built for the existing data."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:'CREATE INDEX idx_test_ann ON sift_1M (`embedding`) USING ANN PROPERTIES (\n  "index_type"="ivf",\n  "metric_type"="l2_distance",\n  "dim"="128",\n  "nlist"="1024"\n);\n\nSHOW DATA ALL FROM sift_1M;\n\nmysql> SHOW DATA ALL FROM sift_1M;\n+-----------+-----------+--------------+----------+----------------+---------------+----------------+-----------------+----------------+-----------------+\n| TableName | IndexName | ReplicaCount | RowCount | LocalTotalSize | LocalDataSize | LocalIndexSize | RemoteTotalSize | RemoteDataSize | RemoteIndexSize |\n+-----------+-----------+--------------+----------+----------------+---------------+----------------+-----------------+----------------+-----------------+\n| sift_1M   | sift_1M   | 10           | 1000000  | 170.093 MB     | 170.093 MB    | 0.000          | 0.000           | 0.000          | 0.000           |\n|           | Total     | 10           |          | 170.093 MB     | 170.093 MB    | 0.000          | 0.000           | 0.000          | 0.000           |\n+-----------+-----------+--------------+----------+----------------+---------------+----------------+-----------------+----------------+-----------------+\n'})}),"\n",(0,r.jsxs)(n.p,{children:["Then you can build the index using the ",(0,r.jsx)(n.code,{children:"BUILD INDEX"})," statement:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"BUILD INDEX idx_test_ann ON sift_1M;\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"BUILD INDEX"})," is executed asynchronously. You can use ",(0,r.jsx)(n.code,{children:"SHOW BUILD INDEX"})," (in some versions ",(0,r.jsx)(n.code,{children:"SHOW ALTER"}),") to check the job status."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:'SHOW BUILD INDEX WHERE TableName = "sift_1M";\n\nmysql> SHOW BUILD INDEX WHERE TableName = "sift_1M";\n+---------------+-----------+---------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+-------------------------+---------------+----------+------+----------+\n| JobId         | TableName | PartitionName | AlterInvertedIndexes                                                                                                                                | CreateTime              | FinishTime              | TransactionId | State    | Msg  | Progress |\n+---------------+-----------+---------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+-------------------------+---------------+----------+------+----------+\n| 1764392359610 | sift_1M   | sift_1M       | [ADD INDEX idx_test_ann (`embedding`) USING ANN PROPERTIES("dim" = "128", "index_type" = "ivf", "metric_type" = "l2_distance", "nlist" = "1024")],  | 2025-12-01 14:18:22.360 | 2025-12-01 14:18:27.885 | 5036          | FINISHED |      | NULL     |\n+---------------+-----------+---------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------+-------------------------+---------------+----------+------+----------+\n1 row in set (0.00 sec)\n\nmysql> SHOW DATA ALL FROM sift_1M;\n+-----------+-----------+--------------+----------+----------------+---------------+----------------+-----------------+----------------+-----------------+\n| TableName | IndexName | ReplicaCount | RowCount | LocalTotalSize | LocalDataSize | LocalIndexSize | RemoteTotalSize | RemoteDataSize | RemoteIndexSize |\n+-----------+-----------+--------------+----------+----------------+---------------+----------------+-----------------+----------------+-----------------+\n| sift_1M   | sift_1M   | 10           | 1000000  | 671.084 MB     | 170.093 MB    | 500.991 MB     | 0.000           | 0.000          | 0.000           |\n|           | Total     | 10           |          | 671.084 MB     | 170.093 MB    | 500.991 MB     | 0.000           | 0.000          | 0.000           |\n+-----------+-----------+--------------+----------+----------------+---------------+----------------+-----------------+----------------+-----------------+\n2 rows in set (0.00 sec)\n'})}),"\n",(0,r.jsx)(n.h4,{id:"drop-index",children:"DROP INDEX"}),"\n",(0,r.jsxs)(n.p,{children:["You can drop an unsuitable ANN index with ",(0,r.jsx)(n.code,{children:"ALTER TABLE sift_1M DROP INDEX idx_test_ann"}),". Dropping and recreating indexes is common during hyperparameter tuning, when you need to test different parameter combinations to achieve the desired recall."]}),"\n",(0,r.jsx)(n.h3,{id:"querying",children:"Querying"}),"\n",(0,r.jsx)(n.p,{children:"ANN indexes support both Top\u2011N search and range search."}),"\n",(0,r.jsx)(n.p,{children:"When the vector column has high dimensionality, the literal representation of the query vector itself can incur extra parsing overhead. Therefore, directly embedding the full query vector into raw SQL is not recommended in production, especially under high concurrency. A better practice is to use prepared statements, which avoid repetitive SQL parsing."}),"\n",(0,r.jsxs)(n.p,{children:["We recommend using the ",(0,r.jsx)(n.a,{href:"https://github.com/uchenily/doris_vector_search",children:"doris-vector-search"})," python library, which wraps the necessary operations for vector search in Doris based on prepared statements, and includes data conversion utilities that map Doris query results into Pandas ",(0,r.jsx)(n.code,{children:"DataFrame"}),"s for convenient downstream AI application development."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from doris_vector_search import DorisVectorClient, AuthOptions\n\nauth = AuthOptions(\n    host="127.0.0.1",\n    query_port=9030,\n    user="root",\n    password="",\n)\n\nclient = DorisVectorClient(database="test", auth_options=auth)\n\ntbl = client.open_table("sift_1M")\n\nquery = [0.1] * 128  # Example 128-dimensional vector\n\n# SELECT id FROM sift_1M ORDER BY l2_distance_approximate(embedding, query) LIMIT 10;\nresult = tbl.search(query, metric_type="l2_distance").limit(10).select(["id"]).to_pandas()\n\nprint(result)\n'})}),"\n",(0,r.jsx)(n.p,{children:"Sample output:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"       id\n0  123911\n1  926855\n2  123739\n3   73311\n4  124493\n5  153178\n6  126138\n7  123740\n8  125741\n9  124048\n"})}),"\n",(0,r.jsx)(n.h3,{id:"recall-optimization",children:"Recall Optimization"}),"\n",(0,r.jsx)(n.p,{children:"In vector search, recall is the most important metric; performance numbers only make sense under a given recall level. The main factors that affect recall are:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Index\u2011time parameter of IVF (",(0,r.jsx)(n.code,{children:"nlist"}),") and query-time parameter (",(0,r.jsx)(n.code,{children:"nprobe"}),")."]}),"\n",(0,r.jsx)(n.li,{children:"Vector quantization."}),"\n",(0,r.jsx)(n.li,{children:"Segment size and the number of segments."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"This article focuses on the impact of (1) and (3) on recall. Vector quantization will be covered in a separate document."}),"\n",(0,r.jsx)(n.h4,{id:"index-hyperparameters",children:"Index Hyperparameters"}),"\n",(0,r.jsx)(n.p,{children:"An IVF index organizes vectors into multiple clusters. During index construction, vectors are partitioned into groups using clustering. The search process then focuses only on the most relevant clusters. The workflow is roughly as follows:"}),"\n",(0,r.jsx)(n.p,{children:"At index time:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Clustering"}),": All vectors are partitioned into ",(0,r.jsx)(n.code,{children:"nlist"})," clusters using a clustering algorithm (e.g., k\u2011means). The centroid of each cluster is computed and stored."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Vector assignment"}),": Each vector is assigned to the cluster whose centroid is closest to it, and the vector is added to that cluster\u2019s inverted list."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"At query time:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Cluster selection using nprobe"}),": For a query vector, distances to all ",(0,r.jsx)(n.code,{children:"nlist"})," centroids are computed. Only the ",(0,r.jsx)(n.code,{children:"nprobe"})," closest clusters are selected for searching."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Exhaustive search within selected clusters"}),": The query is compared against every vector in the selected nprobe clusters to find the nearest neighbors."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"In summary:"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"nlist"})," defines the number of clusters (inverted lists). It affects recall, memory overhead, and build time. A larger ",(0,r.jsx)(n.code,{children:"nlist"})," creates finer\u2011grained clusters, which can improve search speed if the query\u2019s nearest neighbors are well\u2011localized, but it also increases the cost of clustering and the risk of neighbors being spread across multiple clusters."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"nprobe"})," defines the number of clusters to search during a query. A larger ",(0,r.jsx)(n.code,{children:"nprobe"})," increases recall and query latency (more vectors are examined). A smaller nprobe makes queries faster but may miss neighbors that reside in non\u2011probed clusters."]}),"\n",(0,r.jsxs)(n.p,{children:["By default, Doris uses ",(0,r.jsx)(n.code,{children:"nlist = 1024"})," and ",(0,r.jsx)(n.code,{children:"nprobe = 64"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"The above is a qualitative analysis of these two hyperparameters. The following table shows empirical results on the SIFT_1M dataset:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"nlist"}),(0,r.jsx)(n.th,{children:"nprobe"}),(0,r.jsx)(n.th,{children:"recall_at_100"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1024"}),(0,r.jsx)(n.td,{children:"64"}),(0,r.jsx)(n.td,{children:"0.9542"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1024"}),(0,r.jsx)(n.td,{children:"32"}),(0,r.jsx)(n.td,{children:"0.9034"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1024"}),(0,r.jsx)(n.td,{children:"16"}),(0,r.jsx)(n.td,{children:"0.8299"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1024"}),(0,r.jsx)(n.td,{children:"8"}),(0,r.jsx)(n.td,{children:"0.7337"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"512"}),(0,r.jsx)(n.td,{children:"32"}),(0,r.jsx)(n.td,{children:"0.9384"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"512"}),(0,r.jsx)(n.td,{children:"16"}),(0,r.jsx)(n.td,{children:"0.8763"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"512"}),(0,r.jsx)(n.td,{children:"8"}),(0,r.jsx)(n.td,{children:"0.7869"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"It is hard to provide one single optimal setting in advance, but you can follow a practical workflow for hyperparameter selection:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Create a table ",(0,r.jsx)(n.code,{children:"table_multi_index"})," without indexes. It can contain 2 or 3 vector columns."]}),"\n",(0,r.jsxs)(n.li,{children:["Load data into ",(0,r.jsx)(n.code,{children:"table_multi_index"})," using Stream Load or other ingestion methods."]}),"\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.code,{children:"CREATE INDEX"})," and ",(0,r.jsx)(n.code,{children:"BUILD INDEX"})," to build ANN indexes on all vector columns."]}),"\n",(0,r.jsx)(n.li,{children:"Use different index parameter configurations on different columns. After index building finishes, compute recall on each column and choose the best parameter combination."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"for exmaple:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'ALTER TABLE tbl DROP INDEX idx_embedding;\nCREATE INDEX idx_embedding ON tbl (`embedding`) USING ANN PROPERTIES (\n  "index_type"="ivf",\n  "metric_type"="inner_product",\n  "dim"="768",\n  "nlist"="1024"\n);\nBUILD INDEX idx_embedding ON tbl;\n'})}),"\n",(0,r.jsx)(n.h4,{id:"number-of-rows-covered-per-index",children:"Number of Rows Covered per Index"}),"\n",(0,r.jsx)(n.p,{children:"Internally, Doris organizes data in multiple layers."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["At the top is a ",(0,r.jsx)(n.strong,{children:"table"}),", which is partitioned into N ",(0,r.jsx)(n.strong,{children:"tablets"})," using a distribution key. Tablets serve as units for data sharding, relocation, and rebalance."]}),"\n",(0,r.jsxs)(n.li,{children:["Each data ingestion or compaction produces a new ",(0,r.jsx)(n.strong,{children:"rowset"})," under a tablet. A rowset is a versioned collection of data."]}),"\n",(0,r.jsxs)(n.li,{children:["Data in a rowset is actually stored in ",(0,r.jsx)(n.strong,{children:"segment"})," files."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Similar to inverted indexes, vector indexes are built at the ",(0,r.jsx)(n.strong,{children:"segment"})," level. The segment size is determined by BE configuration options like ",(0,r.jsx)(n.code,{children:"write_buffer_size"})," and ",(0,r.jsx)(n.code,{children:"vertical_compaction_max_segment_size"}),". During ingestion and compaction, when the in\u2011memory memtable reaches a certain size, it is flushed to disk as a segment file, and a vector index (or multiple indexes for multiple vector columns) is built for that segment. The index only covers the rows in that segment."]}),"\n",(0,r.jsx)(n.p,{children:"Given a fixed set of IVF parameters, there is always a limit to the number of vectors for which the index can still maintain high recall. Once the number of vectors in a segment grows beyond that limit, recall starts to degrade."}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["You can use ",(0,r.jsx)(n.code,{children:"SHOW TABLETS FROM table"})," to inspect the compaction status of a table. By following the corresponding URL, you can see how many segments it has."]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"impact-of-compaction-on-recall",children:"Impact of Compaction on Recall"}),"\n",(0,r.jsx)(n.p,{children:"Compaction can affect recall because it may create larger segments, which can exceed the \u201Ccoverage capacity\u201D implied by the original hyperparameters. As a result, the recall level achieved before compaction may no longer hold after compaction."}),"\n",(0,r.jsxs)(n.p,{children:["We recommend triggering a full compaction before running ",(0,r.jsx)(n.code,{children:"BUILD INDEX"}),". Building indexes on fully compacted segments stabilizes recall and also reduces write amplification caused by index rebuilds."]}),"\n",(0,r.jsx)(n.h3,{id:"query-performance",children:"Query Performance"}),"\n",(0,r.jsx)(n.h4,{id:"cold-loading-of-index-files",children:"Cold Loading of Index Files"}),"\n",(0,r.jsxs)(n.p,{children:["The IVF ANN index in Doris is implemented using Meta\u2019s open\u2011source library ",(0,r.jsx)(n.a,{href:"https://github.com/facebookresearch/faiss",children:"Faiss"}),". IVF indexes become effective after being loaded into memory. Therefore, before running high\u2011concurrency workloads, it is recommended to run some warm\u2011up queries to make sure that all relevant segment indexes are loaded into memory; otherwise, disk I/O overhead can significantly hurt query performance."]}),"\n",(0,r.jsx)(n.h4,{id:"memory-footprint-vs-performance",children:"Memory Footprint vs. Performance"}),"\n",(0,r.jsx)(n.p,{children:"Without quantization or compression, the memory footprint of an IVF index is roughly 1.02-1.1\xd7 the memory footprint of all vectors it indexes."}),"\n",(0,r.jsx)(n.p,{children:"For example, with 1 million 128\u2011dimensional vectors, an IVF-FLAT index requires approximately:"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"128 * 4 * 1,000,000 * 1.02 \u2248 500 MB"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"Some reference values:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"dim"}),(0,r.jsx)(n.th,{children:"rows"}),(0,r.jsx)(n.th,{children:"estimated memory"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"128"}),(0,r.jsx)(n.td,{children:"1M"}),(0,r.jsx)(n.td,{children:"496 MB"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"768"}),(0,r.jsx)(n.td,{children:"1M"}),(0,r.jsx)(n.td,{children:"2.9 GB"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"To maintain stable performance, ensure that each BE has enough memory; otherwise, frequent swapping and I/O on index files will severely degrade query latency."}),"\n",(0,r.jsx)(n.h3,{id:"benchmark",children:"Benchmark"}),"\n",(0,r.jsx)(n.p,{children:"When benchmark, the deployment model should follow the production environment setup, with FE and BE deployed separately, and the client should run on another independent machine."}),"\n",(0,r.jsxs)(n.p,{children:["You can use ",(0,r.jsx)(n.a,{href:"https://github.com/zilliztech/VectorDBBench",children:"VectorDBBench"})," as benchmark framekwork."]}),"\n",(0,r.jsx)(n.h4,{id:"performance768d1m",children:"Performance768D1M"}),"\n",(0,r.jsx)(n.p,{children:"Benchmark command:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# load\nNUM_PER_BATCH=1000000 python3 -m vectordbbench doris --host 127.0.0.1 --port 9030 --case-type Performance768D1M --db-name Performance768D1M --stream-load-rows-per-batch 500000 --index-prop index_type=ivf,nlist=1024 --skip-search-serial --skip-search-concurrent\n\n# search\nNUM_PER_BATCH=1000000 python3 -m vectordbbench doris --host 127.0.0.1 --port 9030 --case-type Performance768D1M --db-name Performance768D1M --search-concurrent --search-serial --num-concurrency 10,40,80 --stream-load-rows-per-batch 500000 --index-prop index_type=ivf,nlist=1024 --session-var ivf_nprobe=64 --skip-load --skip-drop-old\n"})})]})}function h(e={}){let{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},614918:function(e,n,i){i.d(n,{Z:function(){return t}});let t=i.p+"assets/images/dataset-points-query-clusters-68f2408be77fa59f7b78c1cad3279d9b.png"},250065:function(e,n,i){i.d(n,{Z:function(){return o},a:function(){return a}});var t=i(667294);let r={},s=t.createContext(r);function a(e){let n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);