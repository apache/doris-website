"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["77443"],{23944:function(e,n,s){s.r(n),s.d(n,{default:()=>p,frontMatter:()=>o,metadata:()=>a,assets:()=>l,toc:()=>c,contentTitle:()=>r});var a=JSON.parse('{"id":"lakehouse/best-practices/doris-dlf-paimon","title":"Integration with Aliyun DLF Rest Catalog","description":"Aliyun Data Lake Formation (DLF) serves as a core component of cloud-native data lake architecture, helping users quickly build cloud-native data lake architectures. Data Lake Formation provides unified metadata management on the lake, enterprise-level permission control, and seamlessly integrates with multiple computing engines to break data silos and uncover business value.","source":"@site/versioned_docs/version-2.1/lakehouse/best-practices/doris-dlf-paimon.md","sourceDirName":"lakehouse/best-practices","slug":"/lakehouse/best-practices/doris-dlf-paimon","permalink":"/docs/2.1/lakehouse/best-practices/doris-dlf-paimon","draft":false,"unlisted":false,"tags":[],"version":"2.1","frontMatter":{"title":"Integration with Aliyun DLF Rest Catalog","language":"en"},"sidebar":"docs","previous":{"title":"Integration with AWS S3 Tables","permalink":"/docs/2.1/lakehouse/best-practices/doris-aws-s3tables"},"next":{"title":"From MaxCompute to Doris","permalink":"/docs/2.1/lakehouse/best-practices/doris-maxcompute"}}'),i=s("785893"),t=s("250065");let o={title:"Integration with Aliyun DLF Rest Catalog",language:"en"},r=void 0,l={},c=[{value:"Usage Guide",id:"usage-guide",level:2},{value:"01 Enable DLF Service",id:"01-enable-dlf-service",level:3},{value:"02 Access DLF Using EMR Spark SQL",id:"02-access-dlf-using-emr-spark-sql",level:3},{value:"03 Connect Doris to DLF",id:"03-connect-doris-to-dlf",level:3}];function d(e){let n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.p,{children:["Aliyun ",(0,i.jsx)(n.a,{href:"https://www.alibabacloud.com/en/product/datalake-formation",children:"Data Lake Formation (DLF)"})," serves as a core component of cloud-native data lake architecture, helping users quickly build cloud-native data lake architectures. Data Lake Formation provides unified metadata management on the lake, enterprise-level permission control, and seamlessly integrates with multiple computing engines to break data silos and uncover business value."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Unified Metadata and Storage"}),"\n",(0,i.jsx)(n.p,{children:"Computing engines share a unified set of lake metadata and storage, enabling data flow between lake ecosystem products."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Unified Permission Management"}),"\n",(0,i.jsx)(n.p,{children:"Computing engines share a unified set of lake table permission configurations, achieving one-time configuration with multi-location effectiveness."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Storage Optimization"}),"\n",(0,i.jsx)(n.p,{children:"Provides optimization strategies including small file merging, expired snapshot cleanup, partition organization, and obsolete file cleanup to improve storage efficiency."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Comprehensive Cloud Ecosystem Support"}),"\n",(0,i.jsx)(n.p,{children:"Deep integration with Alibaba Cloud products, including streaming and batch computing engines, enabling out-of-the-box functionality and enhancing user experience and operational convenience."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Starting from DLF version 2.5, Paimon Rest Catalog is supported. Doris, beginning from version 3.1.0, supports integration with DLF 2.5+ Paimon Rest Catalog, enabling seamless connection to DLF for accessing and analyzing Paimon table data. This document demonstrates how to use Apache Doris to connect to DLF 2.5+ and access Paimon table data."}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsx)(n.p,{children:"This feature is supported since Doris 3.1"})}),"\n",(0,i.jsx)(n.h2,{id:"usage-guide",children:"Usage Guide"}),"\n",(0,i.jsx)(n.h3,{id:"01-enable-dlf-service",children:"01 Enable DLF Service"}),"\n",(0,i.jsx)(n.p,{children:"Please refer to the DLF official documentation to enable the DLF service and create corresponding Catalog, Database, and Table."}),"\n",(0,i.jsx)(n.h3,{id:"02-access-dlf-using-emr-spark-sql",children:"02 Access DLF Using EMR Spark SQL"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Connection"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"spark-sql --master yarn \\\n    --conf spark.driver.memory=5g \\\n    --conf spark.sql.defaultCatalog=paimon \\\n    --conf spark.sql.catalog.paimon=org.apache.paimon.spark.SparkCatalog \\\n    --conf spark.sql.catalog.paimon.metastore=rest \\\n    --conf spark.sql.extensions=org.apache.paimon.spark.extensions.PaimonSparkSessionExtensions \\\n    --conf spark.sql.catalog.paimon.uri=http://<region>-vpc.dlf.aliyuncs.com \\\n    --conf spark.sql.catalog.paimon.warehouse=<your-catalog-name> \\\n    --conf spark.sql.catalog.paimon.token.provider=dlf \\\n    --conf spark.sql.catalog.paimon.dlf.token-loader=ecs\n"})}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:["Replace the corresponding ",(0,i.jsx)(n.code,{children:"warehouse"})," and ",(0,i.jsx)(n.code,{children:"uri"})," address."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Write Data"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"USE <your-catalog-name>;\n\nCREATE TABLE users_samples\n(\n    user_id INT,             \n    age_level STRING,           \n    final_gender_code STRING,    \n    clk BOOLEAN\n);\n\nINSERT INTO users_samples VALUES\n(1, '25-34', 'M', true),\n(2, '18-24', 'F', false);\n\nINSERT INTO users_samples VALUES\n(3, '25-34', 'M', true),\n(4, '18-24', 'F', false);\n\nINSERT INTO users_samples VALUES\n(5, '25-34', 'M', true),\n(6, '18-24', 'F', false);\n"})}),"\n",(0,i.jsxs)(n.p,{children:["If you encounter the following error, please try removing ",(0,i.jsx)(n.code,{children:"paimon-jindo-x.y.z.jar"})," from ",(0,i.jsx)(n.code,{children:"/opt/apps/PAIMON/paimon-dlf-2.5/lib/spark3"})," and restart the Spark service before retrying."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Ambiguous FileIO classes are:\norg.apache.paimon.jindo.JindoLoader\norg.apache.paimon.oss.OSSLoader\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"03-connect-doris-to-dlf",children:"03 Connect Doris to DLF"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Create Paimon Catalog"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG paimon_dlf_test PROPERTIES (\n    'type' = 'paimon',\n    'paimon.catalog.type' = 'rest',\n    'uri' = 'http://<region>-vpc.dlf.aliyuncs.com',\n    'warehouse' = '<your-catalog-name>',\n    'paimon.rest.token.provider' = 'dlf',\n    'paimon.rest.dlf.access-key-id' = '<ak>',\n    'paimon.rest.dlf.access-key-secret' = '<sk>'\n);\n"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Doris will use temporary credentials returned by DLF to access OSS object storage, without requiring additional OSS credential information."}),"\n",(0,i.jsx)(n.li,{children:"Only supports accessing DLF within the same VPC, ensure you provide the correct uri address."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Query Data"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"SELECT * FROM users_samples ORDER BY user_id;\n+---------+-----------+-------------------+------+\n| user_id | age_level | final_gender_code | clk  |\n+---------+-----------+-------------------+------+\n|       1 | 25-34     | M                 |    1 |\n|       2 | 18-24     | F                 |    0 |\n|       3 | 25-34     | M                 |    1 |\n|       4 | 18-24     | F                 |    0 |\n|       5 | 25-34     | M                 |    1 |\n|       6 | 18-24     | F                 |    0 |\n+---------+-----------+-------------------+------+\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Query System Tables"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"SELECT snapshot_id, commit_time, total_record_count FROM users_samples$snapshots;\n+-------------+-------------------------+--------------------+\n| snapshot_id | commit_time             | total_record_count |\n+-------------+-------------------------+--------------------+\n|           1 | 2025-08-09 05:56:02.906 |                  2 |\n|           2 | 2025-08-13 03:41:32.732 |                  4 |\n|           3 | 2025-08-13 03:41:35.218 |                  6 |\n+-------------+-------------------------+--------------------+\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Batch Incremental Reading"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"SELECT * FROM users_samples@incr('startSnapshotId'=1, 'endSnapshotId'=2) ORDER BY user_id;\n+---------+-----------+-------------------+------+\n| user_id | age_level | final_gender_code | clk  |\n+---------+-----------+-------------------+------+\n|       3 | 25-34     | M                 |    1 |\n|       4 | 18-24     | F                 |    0 |\n+---------+-----------+-------------------+------+\n"})}),"\n"]}),"\n"]})]})}function p(e={}){let{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},250065:function(e,n,s){s.d(n,{Z:function(){return r},a:function(){return o}});var a=s(667294);let i={},t=a.createContext(i);function o(e){let n=a.useContext(t);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),a.createElement(t.Provider,{value:n},e.children)}}}]);