"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["757449"],{835135:function(e,n,i){i.r(n),i.d(n,{default:()=>h,frontMatter:()=>t,metadata:()=>r,assets:()=>o,toc:()=>c,contentTitle:()=>a});var r=JSON.parse('{"id":"ai/text-search/custom-analyzer","title":"Custom Analyzer","description":"Custom analyzers allow you to overcome the limitations of built-in tokenizers by combining character filters, tokenizers,","source":"@site/docs/ai/text-search/custom-analyzer.md","sourceDirName":"ai/text-search","slug":"/ai/text-search/custom-analyzer","permalink":"/docs/dev/ai/text-search/custom-analyzer","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1770477659000,"frontMatter":{"title":"Custom Analyzer","language":"en","description":"Custom analyzers allow you to overcome the limitations of built-in tokenizers by combining character filters, tokenizers,"},"sidebar":"docs","previous":{"title":"SEARCH Function","permalink":"/docs/dev/ai/text-search/search-function"},"next":{"title":"Custom Normalizer","permalink":"/docs/dev/ai/text-search/custom-normalizer"}}'),l=i("785893"),s=i("250065");let t={title:"Custom Analyzer",language:"en",description:"Custom analyzers allow you to overcome the limitations of built-in tokenizers by combining character filters, tokenizers,"},a=void 0,o={},c=[{value:"Overview",id:"overview",level:2},{value:"Using Custom Analyzers",id:"using-custom-analyzers",level:2},{value:"Creating Components",id:"creating-components",level:3},{value:"1. Creating a char_filter",id:"1-creating-a-char_filter",level:4},{value:"2. Creating a tokenizer",id:"2-creating-a-tokenizer",level:4},{value:"3. Creating a token_filter",id:"3-creating-a-token_filter",level:4},{value:"4. Creating an analyzer",id:"4-creating-an-analyzer",level:4},{value:"Viewing Components",id:"viewing-components",level:3},{value:"Deleting Components",id:"deleting-components",level:3},{value:"Using Custom Analyzers in Table Creation",id:"using-custom-analyzers-in-table-creation",level:2},{value:"Usage Limitations",id:"usage-limitations",level:2},{value:"Notes",id:"notes",level:2},{value:"Complete Examples",id:"complete-examples",level:2},{value:"Example 1: Phone Number Tokenization",id:"example-1-phone-number-tokenization",level:3},{value:"Example 2: Fine-grained Tokenization",id:"example-2-fine-grained-tokenization",level:3},{value:"Example 3: Keyword with Multiple Token Filters",id:"example-3-keyword-with-multiple-token-filters",level:3},{value:"Example 4: Chinese Pinyin Search",id:"example-4-chinese-pinyin-search",level:3},{value:"Using Pinyin Tokenizer",id:"using-pinyin-tokenizer",level:4},{value:"Using Pinyin Filter",id:"using-pinyin-filter",level:4},{value:"Multiple Analyzers on Single Column",id:"multiple-analyzers-on-single-column",level:2},{value:"Use Cases",id:"use-cases",level:3},{value:"Creating Multiple Indexes",id:"creating-multiple-indexes",level:3},{value:"Querying with Specific Analyzer",id:"querying-with-specific-analyzer",level:3},{value:"Adding Indexes to Existing Tables",id:"adding-indexes-to-existing-tables",level:3},{value:"Building Indexes",id:"building-indexes",level:3},{value:"Important Notes",id:"important-notes",level:3}];function d(e){let n={code:"code",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.a)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,l.jsx)(n.p,{children:"Custom analyzers allow you to overcome the limitations of built-in tokenizers by combining character filters, tokenizers, and token filters according to specific needs. This fine-tunes how text is segmented into searchable terms, directly determining search relevance and data analysis accuracy\u2014a foundational key to enhancing search experience and data value."}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.img,{alt:"Custom Analyzer Overview",src:i(203687).Z+"",width:"1636",height:"140"})}),"\n",(0,l.jsx)(n.h2,{id:"using-custom-analyzers",children:"Using Custom Analyzers"}),"\n",(0,l.jsx)(n.h3,{id:"creating-components",children:"Creating Components"}),"\n",(0,l.jsx)(n.h4,{id:"1-creating-a-char_filter",children:"1. Creating a char_filter"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:'CREATE INVERTED INDEX CHAR_FILTER IF NOT EXISTS x_char_filter\nPROPERTIES (\n  "type" = "char_replace"\n  -- configure pattern/replacement parameters as needed\n);\n'})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.code,{children:"char_replace"})," replaces specified characters before tokenization."]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["Parameters\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"char_filter_pattern"}),": characters to replace"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"char_filter_replacement"}),": replacement characters (default: space)\n",(0,l.jsx)(n.code,{children:"icu_normalizer"}),": Preprocess text using ICU normalization."]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["Parameters\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"name"}),": Normalization form (default ",(0,l.jsx)(n.code,{children:"nfkc_cf"}),"). Options: ",(0,l.jsx)(n.code,{children:"nfc"}),", ",(0,l.jsx)(n.code,{children:"nfkc"}),", ",(0,l.jsx)(n.code,{children:"nfkc_cf"}),", ",(0,l.jsx)(n.code,{children:"nfd"}),", ",(0,l.jsx)(n.code,{children:"nfkd"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"mode"}),": Normalization mode (default ",(0,l.jsx)(n.code,{children:"compose"}),"). Options: ",(0,l.jsx)(n.code,{children:"compose"}),", ",(0,l.jsx)(n.code,{children:"decompose"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"unicode_set_filter"}),": Specify the character set to normalize (e.g. ",(0,l.jsx)(n.code,{children:"[a-z]"}),")"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"2-creating-a-tokenizer",children:"2. Creating a tokenizer"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:'CREATE INVERTED INDEX TOKENIZER IF NOT EXISTS x_tokenizer\nPROPERTIES (\n  "type" = "standard"\n);\n'})}),"\n",(0,l.jsx)(n.p,{children:"Available tokenizers:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"standard"}),": Grammar-based tokenization following Unicode text segmentation"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"ngram"}),": Generates N-grams of specified length"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"edge_ngram"}),": Generates N-grams anchored at word start"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"keyword"}),": No-op tokenizer that outputs entire input as single term"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"char_group"}),": Tokenizes on specified characters"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"basic"}),": Simple English, numbers, Chinese, Unicode tokenizer"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"icu"}),": International text segmentation supporting all languages"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"pinyin"}),": Chinese pinyin conversion tokenizer for Chinese text search (Supported from 4.0.2, phrase queries not supported yet)\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"keep_first_letter"}),": When enabled, retains only the first letter of each Chinese character. For example, ",(0,l.jsx)(n.code,{children:"\u5218\u5FB7\u534E"})," becomes ",(0,l.jsx)(n.code,{children:"ldh"}),". Default: true"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"keep_separate_first_letter"}),": When enabled, keeps the first letters of each Chinese character separately. For example, ",(0,l.jsx)(n.code,{children:"\u5218\u5FB7\u534E"})," becomes ",(0,l.jsx)(n.code,{children:"l"}),",",(0,l.jsx)(n.code,{children:"d"}),",",(0,l.jsx)(n.code,{children:"h"}),". Default: false. Note: This may increase query fuzziness due to term frequency"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"limit_first_letter_length"}),": Sets the maximum length of the first letter result. Default: 16"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"keep_full_pinyin"}),": When enabled, preserves the full Pinyin of each Chinese character. For example, ",(0,l.jsx)(n.code,{children:"\u5218\u5FB7\u534E"})," becomes [",(0,l.jsx)(n.code,{children:"liu"}),",",(0,l.jsx)(n.code,{children:"de"}),",",(0,l.jsx)(n.code,{children:"hua"}),"]. Default: true"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"keep_joined_full_pinyin"}),": When enabled, joins the full Pinyin of each Chinese character. For example, ",(0,l.jsx)(n.code,{children:"\u5218\u5FB7\u534E"})," becomes [",(0,l.jsx)(n.code,{children:"liudehua"}),"]. Default: false"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"keep_none_chinese"}),": Keeps non-Chinese letters or numbers in the result. Default: true"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"keep_none_chinese_together"}),": Keeps non-Chinese letters together. Default: true. For example, ",(0,l.jsx)(n.code,{children:"DJ\u97F3\u4E50\u5BB6"})," becomes ",(0,l.jsx)(n.code,{children:"DJ"}),",",(0,l.jsx)(n.code,{children:"yin"}),",",(0,l.jsx)(n.code,{children:"yue"}),",",(0,l.jsx)(n.code,{children:"jia"}),". When set to false, ",(0,l.jsx)(n.code,{children:"DJ\u97F3\u4E50\u5BB6"})," becomes ",(0,l.jsx)(n.code,{children:"D"}),",",(0,l.jsx)(n.code,{children:"J"}),",",(0,l.jsx)(n.code,{children:"yin"}),",",(0,l.jsx)(n.code,{children:"yue"}),",",(0,l.jsx)(n.code,{children:"jia"}),". Note: ",(0,l.jsx)(n.code,{children:"keep_none_chinese"})," should be enabled first"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"keep_none_chinese_in_first_letter"}),": Keeps non-Chinese letters in the first letter. For example, ",(0,l.jsx)(n.code,{children:"\u5218\u5FB7\u534EAT2016"})," becomes ",(0,l.jsx)(n.code,{children:"ldhat2016"}),". Default: true"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"keep_none_chinese_in_joined_full_pinyin"}),": Keeps non-Chinese letters in joined full Pinyin. For example, ",(0,l.jsx)(n.code,{children:"\u5218\u5FB7\u534E2016"})," becomes ",(0,l.jsx)(n.code,{children:"liudehua2016"}),". Default: false"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"none_chinese_pinyin_tokenize"}),": Breaks non-Chinese letters into separate Pinyin terms if they are Pinyin. Default: true. For example, ",(0,l.jsx)(n.code,{children:"liudehuaalibaba13zhuanghan"})," becomes ",(0,l.jsx)(n.code,{children:"liu"}),",",(0,l.jsx)(n.code,{children:"de"}),",",(0,l.jsx)(n.code,{children:"hua"}),",",(0,l.jsx)(n.code,{children:"a"}),",",(0,l.jsx)(n.code,{children:"li"}),",",(0,l.jsx)(n.code,{children:"ba"}),",",(0,l.jsx)(n.code,{children:"ba"}),",",(0,l.jsx)(n.code,{children:"13"}),",",(0,l.jsx)(n.code,{children:"zhuang"}),",",(0,l.jsx)(n.code,{children:"han"}),". Note: ",(0,l.jsx)(n.code,{children:"keep_none_chinese"})," and ",(0,l.jsx)(n.code,{children:"keep_none_chinese_together"})," should be enabled first"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"keep_original"}),": When enabled, keeps the original input as well. Default: false"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"lowercase"}),":  Lowercases non-Chinese letters. Default: true"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"trim_whitespace"}),": Default: true"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"remove_duplicated_term"}),": When enabled, removes duplicated terms to save index space. For example, ",(0,l.jsx)(n.code,{children:"de\u7684"})," becomes ",(0,l.jsx)(n.code,{children:"de"}),". Default: false. Note: Position-related queries may be influenced"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"ignore_pinyin_offset"}),": This parameter currently has no functionality. Default: true"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"3-creating-a-token_filter",children:"3. Creating a token_filter"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:'CREATE INVERTED INDEX TOKEN_FILTER IF NOT EXISTS x_token_filter\nPROPERTIES (\n  "type" = "word_delimiter"\n);\n'})}),"\n",(0,l.jsx)(n.p,{children:"Available token filters:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"word_delimiter"}),": Splits tokens at non-alphanumeric characters"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"ascii_folding"}),": Converts non-ASCII characters to ASCII equivalents"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"lowercase"}),": Converts tokens to lowercase"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"pinyin"}),": Converts Chinese characters to pinyin after tokenization. For parameter details, refer to the ",(0,l.jsx)(n.strong,{children:"pinyin"})," tokenizer above."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"icu_normalizer"}),": Process tokens using ICU normalization.\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"name"}),": Normalization form (default ",(0,l.jsx)(n.code,{children:"nfkc_cf"}),"). Options: ",(0,l.jsx)(n.code,{children:"nfc"}),", ",(0,l.jsx)(n.code,{children:"nfkc"}),", ",(0,l.jsx)(n.code,{children:"nfkc_cf"}),", ",(0,l.jsx)(n.code,{children:"nfd"}),", ",(0,l.jsx)(n.code,{children:"nfkd"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"unicode_set_filter"}),": Specify the character set to normalize"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"4-creating-an-analyzer",children:"4. Creating an analyzer"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:'CREATE INVERTED INDEX ANALYZER IF NOT EXISTS x_analyzer\nPROPERTIES (\n  "tokenizer" = "x_tokenizer",            -- single tokenizer\n  "token_filter" = "x_filter1, x_filter2" -- one or more token_filters, in order\n);\n'})}),"\n",(0,l.jsx)(n.h3,{id:"viewing-components",children:"Viewing Components"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:"SHOW INVERTED INDEX TOKENIZER;\nSHOW INVERTED INDEX TOKEN_FILTER;\nSHOW INVERTED INDEX ANALYZER;\n"})}),"\n",(0,l.jsx)(n.h3,{id:"deleting-components",children:"Deleting Components"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:"DROP INVERTED INDEX TOKENIZER IF EXISTS x_tokenizer;\nDROP INVERTED INDEX TOKEN_FILTER IF EXISTS x_token_filter;\nDROP INVERTED INDEX ANALYZER IF EXISTS x_analyzer;\n"})}),"\n",(0,l.jsx)(n.h2,{id:"using-custom-analyzers-in-table-creation",children:"Using Custom Analyzers in Table Creation"}),"\n",(0,l.jsxs)(n.p,{children:["Custom analyzers are specified using the ",(0,l.jsx)(n.code,{children:"analyzer"})," parameter in index properties:"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE tbl (\n    `a` bigint NOT NULL AUTO_INCREMENT(1),\n    `ch` text NULL,\n    INDEX idx_ch (`ch`) USING INVERTED PROPERTIES("analyzer" = "x_custom_analyzer", "support_phrase" = "true")\n)\ntable_properties;\n'})}),"\n",(0,l.jsx)(n.h2,{id:"usage-limitations",children:"Usage Limitations"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["The ",(0,l.jsx)(n.code,{children:"type"})," and parameters in tokenizer and token_filter must be from the supported list, otherwise table creation will fail"]}),"\n",(0,l.jsx)(n.li,{children:"An analyzer can only be deleted when no tables are using it"}),"\n",(0,l.jsx)(n.li,{children:"Tokenizers and token_filters can only be deleted when no analyzers are using them"}),"\n",(0,l.jsx)(n.li,{children:"After creating custom analyzer syntax, it takes 10 seconds to sync to BE before data loading works normally"}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"Nesting multiple components in a custom analyzer may degrade tokenization performance"}),"\n",(0,l.jsxs)(n.li,{children:["The ",(0,l.jsx)(n.code,{children:"tokenize"})," function supports custom analyzers"]}),"\n",(0,l.jsxs)(n.li,{children:["Predefined tokenization uses ",(0,l.jsx)(n.code,{children:"built_in_analyzer"}),", custom tokenization uses ",(0,l.jsx)(n.code,{children:"analyzer"})," - only one can exist"]}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"complete-examples",children:"Complete Examples"}),"\n",(0,l.jsx)(n.h3,{id:"example-1-phone-number-tokenization",children:"Example 1: Phone Number Tokenization"}),"\n",(0,l.jsx)(n.p,{children:"Using edge_ngram for phone number tokenization:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:'CREATE INVERTED INDEX TOKENIZER IF NOT EXISTS edge_ngram_phone_number_tokenizer\nPROPERTIES\n(\n    "type" = "edge_ngram",\n    "min_gram" = "3",\n    "max_gram" = "10",\n    "token_chars" = "digit"\n);\n\nCREATE INVERTED INDEX ANALYZER IF NOT EXISTS edge_ngram_phone_number\nPROPERTIES\n(\n    "tokenizer" = "edge_ngram_phone_number_tokenizer"\n);\n\nCREATE TABLE tbl (\n    `a` bigint NOT NULL AUTO_INCREMENT(1),\n    `ch` text NULL,\n    INDEX idx_ch (`ch`) USING INVERTED PROPERTIES("support_phrase" = "true", "analyzer" = "edge_ngram_phone_number")\n) ENGINE=OLAP\nDUPLICATE KEY(`a`)\nDISTRIBUTED BY RANDOM BUCKETS 1\nPROPERTIES (\n"replication_allocation" = "tag.location.default: 1"\n);\n'})}),"\n",(0,l.jsx)(n.h3,{id:"example-2-fine-grained-tokenization",children:"Example 2: Fine-grained Tokenization"}),"\n",(0,l.jsx)(n.p,{children:"Using standard + word_delimiter for detailed tokenization:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:'CREATE INVERTED INDEX TOKEN_FILTER IF NOT EXISTS word_splitter\nPROPERTIES\n(\n    "type" = "word_delimiter",\n    "split_on_numerics" = "false",\n    "split_on_case_change" = "false"\n);\n\nCREATE INVERTED INDEX ANALYZER IF NOT EXISTS lowercase_delimited\nPROPERTIES\n(\n    "tokenizer" = "standard",\n    "token_filter" = "asciifolding, word_splitter, lowercase"\n);\n'})}),"\n",(0,l.jsx)(n.h3,{id:"example-3-keyword-with-multiple-token-filters",children:"Example 3: Keyword with Multiple Token Filters"}),"\n",(0,l.jsx)(n.p,{children:"Using keyword to preserve original terms with multiple token filters:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:'CREATE INVERTED INDEX ANALYZER IF NOT EXISTS keyword_lowercase\nPROPERTIES\n(\n"tokenizer" = "keyword",\n"token_filter" = "asciifolding, lowercase"\n);\n'})}),"\n",(0,l.jsx)(n.h3,{id:"example-4-chinese-pinyin-search",children:"Example 4: Chinese Pinyin Search"}),"\n",(0,l.jsx)(n.p,{children:"Using pinyin tokenizer for Chinese name and text search - supports full pinyin, first letter abbreviations, and mixed Chinese-English text."}),"\n",(0,l.jsx)(n.h4,{id:"using-pinyin-tokenizer",children:"Using Pinyin Tokenizer"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:'-- Create pinyin tokenizer with multiple output formats\nCREATE INVERTED INDEX TOKENIZER IF NOT EXISTS pinyin_tokenizer\nPROPERTIES (\n    "type" = "pinyin",\n    "keep_first_letter" = "true",\n    "keep_full_pinyin" = "true",\n    "keep_joined_full_pinyin" = "true",\n    "keep_original" = "true",\n    "keep_none_chinese" = "true",\n    "lowercase" = "true",\n    "remove_duplicated_term" = "true"\n);\n\nCREATE INVERTED INDEX ANALYZER IF NOT EXISTS pinyin_analyzer\nPROPERTIES (\n    "tokenizer" = "pinyin_tokenizer"\n);\n\nCREATE TABLE contacts (\n    id BIGINT NOT NULL AUTO_INCREMENT(1),\n    name TEXT NULL,\n    INDEX idx_name (name) USING INVERTED PROPERTIES("analyzer" = "pinyin_analyzer", "support_phrase" = "true")\n) ENGINE=OLAP\nDUPLICATE KEY(id)\nDISTRIBUTED BY RANDOM BUCKETS 1\nPROPERTIES ("replication_allocation" = "tag.location.default: 1");\n\nINSERT INTO contacts VALUES (1, "\u5218\u5FB7\u534E"), (2, "\u5F20\u5B66\u53CB"), (3, "\u90ED\u5BCC\u57CE");\n\nSELECT * FROM contacts WHERE name MATCH \'\u5218\u5FB7\u534E\';\nSELECT * FROM contacts WHERE name MATCH \'liudehua\';\nSELECT * FROM contacts WHERE name MATCH \'liu\';\nSELECT * FROM contacts WHERE name MATCH \'ldh\';\n'})}),"\n",(0,l.jsx)(n.h4,{id:"using-pinyin-filter",children:"Using Pinyin Filter"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:'-- Create pinyin filter to apply after keyword tokenizer\nCREATE INVERTED INDEX TOKEN_FILTER IF NOT EXISTS pinyin_filter\nPROPERTIES (\n    "type" = "pinyin",\n    "keep_first_letter" = "true",\n    "keep_full_pinyin" = "true",\n    "keep_original" = "true",\n    "lowercase" = "true"\n);\n\nCREATE INVERTED INDEX ANALYZER IF NOT EXISTS keyword_pinyin\nPROPERTIES (\n    "tokenizer" = "keyword",\n    "token_filter" = "pinyin_filter"\n);\n\nCREATE TABLE stars (\n    id BIGINT NOT NULL AUTO_INCREMENT(1),\n    name TEXT NULL,\n    INDEX idx_name (name) USING INVERTED PROPERTIES("analyzer" = "keyword_pinyin")\n) ENGINE=OLAP\nDUPLICATE KEY(id)\nDISTRIBUTED BY RANDOM BUCKETS 1\nPROPERTIES ("replication_allocation" = "tag.location.default: 1");\n\nINSERT INTO stars VALUES (1, "\u5218\u5FB7\u534E"), (2, "\u5F20\u5B66\u53CB"), (3, "\u5218\u5FB7\u534EABC");\n\n-- Supports multiple search modes:\nSELECT * FROM stars WHERE name MATCH \'\u5218\u5FB7\u534E\';\nSELECT * FROM stars WHERE name MATCH \'liu\';\nSELECT * FROM stars WHERE name MATCH \'ldh\';\nSELECT * FROM stars WHERE name MATCH \'zxy\';\n'})}),"\n",(0,l.jsx)(n.h2,{id:"multiple-analyzers-on-single-column",children:"Multiple Analyzers on Single Column"}),"\n",(0,l.jsx)(n.p,{children:"Doris supports creating multiple inverted indexes with different analyzers on a single column. This enables flexible search strategies where the same data can be searched using different tokenization methods."}),"\n",(0,l.jsx)(n.h3,{id:"use-cases",children:"Use Cases"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Multi-language support"}),": Use different analyzers for different languages on the same text column"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Search precision vs. recall"}),": Use keyword analyzer for exact match and standard analyzer for fuzzy search"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Autocomplete"}),": Use edge_ngram analyzer for prefix matching while keeping standard analyzer for regular search"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"creating-multiple-indexes",children:"Creating Multiple Indexes"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:'-- Create analyzers with different tokenization strategies\nCREATE INVERTED INDEX ANALYZER IF NOT EXISTS std_analyzer\nPROPERTIES ("tokenizer" = "standard", "token_filter" = "lowercase");\n\nCREATE INVERTED INDEX ANALYZER IF NOT EXISTS kw_analyzer\nPROPERTIES ("tokenizer" = "keyword", "token_filter" = "lowercase");\n\nCREATE INVERTED INDEX TOKENIZER IF NOT EXISTS edge_ngram_tokenizer\nPROPERTIES (\n    "type" = "edge_ngram",\n    "min_gram" = "1",\n    "max_gram" = "20",\n    "token_chars" = "letter"\n);\n\nCREATE INVERTED INDEX ANALYZER IF NOT EXISTS ngram_analyzer\nPROPERTIES ("tokenizer" = "edge_ngram_tokenizer", "token_filter" = "lowercase");\n\n-- Create table with multiple indexes on same column\nCREATE TABLE articles (\n    id INT,\n    content TEXT,\n    -- Standard analyzer for tokenized search\n    INDEX idx_content_std (content) USING INVERTED\n        PROPERTIES("analyzer" = "std_analyzer", "support_phrase" = "true"),\n    -- Keyword analyzer for exact match\n    INDEX idx_content_kw (content) USING INVERTED\n        PROPERTIES("analyzer" = "kw_analyzer"),\n    -- Edge n-gram analyzer for autocomplete\n    INDEX idx_content_ngram (content) USING INVERTED\n        PROPERTIES("analyzer" = "ngram_analyzer")\n) ENGINE=OLAP\nDUPLICATE KEY(id)\nDISTRIBUTED BY HASH(id) BUCKETS 1\nPROPERTIES ("replication_allocation" = "tag.location.default: 1");\n'})}),"\n",(0,l.jsx)(n.h3,{id:"querying-with-specific-analyzer",children:"Querying with Specific Analyzer"}),"\n",(0,l.jsxs)(n.p,{children:["Use ",(0,l.jsx)(n.code,{children:"USING ANALYZER"})," clause to specify which index to use:"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:"-- Insert test data\nINSERT INTO articles VALUES\n    (1, 'hello world'),\n    (2, 'hello'),\n    (3, 'world'),\n    (4, 'hello world test');\n\n-- Tokenized search: matches rows containing 'hello' token\n-- Returns: 1, 2, 4\nSELECT id FROM articles WHERE content MATCH 'hello' USING ANALYZER std_analyzer ORDER BY id;\n\n-- Exact match: only matches rows with exact 'hello' string\n-- Returns: 2\nSELECT id FROM articles WHERE content MATCH 'hello' USING ANALYZER kw_analyzer ORDER BY id;\n\n-- Prefix match with edge n-gram\n-- Returns: 1, 2, 4 (all rows starting with 'hel')\nSELECT id FROM articles WHERE content MATCH 'hel' USING ANALYZER ngram_analyzer ORDER BY id;\n"})}),"\n",(0,l.jsx)(n.h3,{id:"adding-indexes-to-existing-tables",children:"Adding Indexes to Existing Tables"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:'-- Add a new index with different analyzer\nALTER TABLE articles ADD INDEX idx_content_chinese (content)\nUSING INVERTED PROPERTIES("parser" = "chinese");\n\n-- Wait for schema change to complete\nSHOW ALTER TABLE COLUMN WHERE TableName=\'articles\';\n'})}),"\n",(0,l.jsx)(n.h3,{id:"building-indexes",children:"Building Indexes"}),"\n",(0,l.jsx)(n.p,{children:"After adding an index, you need to build it for existing data:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:"-- Build specific index (non-cloud mode)\nBUILD INDEX idx_content_chinese ON articles;\n\n-- Build all indexes (cloud mode)\nBUILD INDEX ON articles;\n\n-- Check build progress\nSHOW BUILD INDEX WHERE TableName='articles';\n"})}),"\n",(0,l.jsx)(n.h3,{id:"important-notes",children:"Important Notes"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Analyzer Identity"}),": Two analyzers with the same tokenizer and token_filter configuration are considered identical. You cannot create multiple indexes with identical analyzer identities on the same column."]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Index Selection Behavior"}),":"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["When using ",(0,l.jsx)(n.code,{children:"USING ANALYZER"}),", if the specified analyzer's index exists and is built, it will be used"]}),"\n",(0,l.jsx)(n.li,{children:"If the specified index is not built, the query falls back to non-index path (correct results, slower performance)"}),"\n",(0,l.jsxs)(n.li,{children:["Without ",(0,l.jsx)(n.code,{children:"USING ANALYZER"}),", any available index may be used"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Built-in Analyzers"}),": You can also use built-in analyzers directly:"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sql",children:"-- Using built-in analyzers\nSELECT * FROM articles WHERE content MATCH 'hello' USING ANALYZER standard;\nSELECT * FROM articles WHERE content MATCH 'hello' USING ANALYZER none;\nSELECT * FROM articles WHERE content MATCH '\u4F60\u597D' USING ANALYZER chinese;\n"})}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Performance Considerations"}),":"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Each additional index increases storage space and write overhead"}),"\n",(0,l.jsx)(n.li,{children:"Choose analyzers based on actual query patterns"}),"\n",(0,l.jsx)(n.li,{children:"Consider using fewer indexes if query patterns are predictable"}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){let{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(d,{...e})}):d(e)}},203687:function(e,n,i){i.d(n,{Z:function(){return r}});let r=i.p+"assets/images/analyzer-a1a8bdb57c4fa41a7564b4a450ba7121.png"},250065:function(e,n,i){i.d(n,{Z:function(){return a},a:function(){return t}});var r=i(667294);let l={},s=r.createContext(l);function t(e){let n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:t(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);