"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["197749"],{389630:function(e,n,t){t.r(n),t.d(n,{default:()=>p,frontMatter:()=>s,metadata:()=>i,assets:()=>l,toc:()=>c,contentTitle:()=>o});var i=JSON.parse('{"id":"observability/trace","title":"Trace","description":"This article introduces the storage and analysis practices of Trace, one of the core observability data.","source":"@site/versioned_docs/version-3.x/observability/trace.md","sourceDirName":"observability","slug":"/observability/trace","permalink":"/docs/3.x/observability/trace","draft":false,"unlisted":false,"tags":[],"version":"3.x","lastUpdatedAt":1770477659000,"frontMatter":{"title":"Trace","language":"en","description":"This article introduces the storage and analysis practices of Trace, one of the core observability data."},"sidebar":"docs","previous":{"title":"Log","permalink":"/docs/3.x/observability/log"},"next":{"title":"Logstash","permalink":"/docs/3.x/ecosystem/observability/logstash"}}'),r=t("785893"),a=t("250065");let s={title:"Trace",language:"en",description:"This article introduces the storage and analysis practices of Trace, one of the core observability data."},o="Trace",l={},c=[{value:"1. Table Creation",id:"1-table-creation",level:2},{value:"2. Trace Collection",id:"2-trace-collection",level:2},{value:"OpenTelemetry Integration",id:"opentelemetry-integration",level:3},{value:"3. Trace Querying",id:"3-trace-querying",level:2}];function d(e){let n={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"trace",children:"Trace"})}),"\n",(0,r.jsxs)(n.p,{children:["This article introduces the storage and analysis practices of Trace, one of the core observability data. For an overview of the complete observability solution, please refer to ",(0,r.jsx)(n.a,{href:"/docs/3.x/observability/overview",children:"Overview"}),". For resource evaluation, cluster deployment, and optimization, please refer to ",(0,r.jsx)(n.a,{href:"/docs/3.x/observability/log",children:"Log"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"1-table-creation",children:"1. Table Creation"}),"\n",(0,r.jsx)(n.p,{children:"Trace data has distinct characteristics in terms of writing and querying patterns. Targeted configurations during table creation can significantly improve performance. Create your table based on the key guidelines below:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Partitioning and Sorting"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Use RANGE partitioning on the time field, enable dynamic partitioning to manage partitions automatically by day."}),"\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.code,{children:"service_name"})," and a time field of type DATETIME as keys; this provides multiple times acceleration when querying traces for a specific service over a certain period."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Bucketing"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"The number of buckets should be approximately three times the total number of disks in the cluster."}),"\n",(0,r.jsx)(n.li,{children:"Use the RANDOM bucketing strategy. Combined with single-tablet ingestion during writes, it improves batch write efficiency."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Compaction"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Use the time_series compaction strategy to reduce write amplification, which is crucial for optimizing resources under high-throughput ingestion."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"VARIANT Data Type"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Use the semi-structured VARIANT data type for extended Trace fields like ",(0,r.jsx)(n.code,{children:"span_attributes"})," and ",(0,r.jsx)(n.code,{children:"resource_attributes"}),". This automatically splits JSON data into sub-columns for storage, improving compression rates and reducing storage space while also enhancing filtering and sub-column analysis performance."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Indexing"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Build indexes on frequently queried fields."}),"\n",(0,r.jsxs)(n.li,{children:["For fields requiring full-text search, specify the parser parameter. Unicode tokenization generally meets most needs. Enable the ",(0,r.jsx)(n.code,{children:"support_phrase"})," option to support phrase queries. If not needed, set it to false to reduce storage usage."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Storage"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"For hot data, configure 1 replica if using cloud disks or at least 2 replicas if using physical disks."}),"\n",(0,r.jsxs)(n.li,{children:["Use hot-cold tiered storage configuration with ",(0,r.jsx)(n.code,{children:"log_s3"})," object storage and ",(0,r.jsx)(n.code,{children:"log_policy_3day"})," policy to move data older than 3 days to S3."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:'CREATE DATABASE log_db;\nUSE log_db;\n\n-- Not required for compute-storage separation mode\nCREATE RESOURCE "log_s3"\nPROPERTIES\n(\n    "type" = "s3",\n    "s3.endpoint" = "your_endpoint_url",\n    "s3.region" = "your_region",\n    "s3.bucket" = "your_bucket",\n    "s3.root.path" = "your_path",\n    "s3.access_key" = "your_ak",\n    "s3.secret_key" = "your_sk"\n);\n\n-- Not required for compute-storage separation mode\nCREATE STORAGE POLICY log_policy_3day\nPROPERTIES(\n    "storage_resource" = "log_s3",\n    "cooldown_ttl" = "259200"\n);\n\nCREATE TABLE trace_table\n(        \n    service_name          VARCHAR(200),        \n    timestamp             DATETIME(6),\n    service_instance_id   VARCHAR(200),\n    trace_id              VARCHAR(200),        \n    span_id               STRING,        \n    trace_state           STRING,        \n    parent_span_id        STRING,        \n    span_name             STRING,        \n    span_kind             STRING,        \n    end_time              DATETIME(6),        \n    duration              BIGINT,        \n    span_attributes       VARIANT,        \n    events                ARRAY<STRUCT<timestamp:DATETIME(6), name:STRING, attributes:MAP<STRING, STRING>>>,        \n    links                 ARRAY<STRUCT<trace_id:STRING, span_id:STRING, trace_state:STRING, attributes:MAP<STRING, STRING>>>,        \n    status_message        STRING,        \n    status_code           STRING,        \n    resource_attributes   VARIANT,        \n    scope_name            STRING,        \n    scope_version         STRING,\n    INDEX idx_timestamp(timestamp) USING INVERTED,\n    INDEX idx_service_instance_id(service_instance_id) USING INVERTED,\n    INDEX idx_trace_id(trace_id) USING INVERTED,        \n    INDEX idx_span_id(span_id) USING INVERTED,        \n    INDEX idx_trace_state(trace_state) USING INVERTED,        \n    INDEX idx_parent_span_id(parent_span_id) USING INVERTED,        \n    INDEX idx_span_name(span_name) USING INVERTED,        \n    INDEX idx_span_kind(span_kind) USING INVERTED,        \n    INDEX idx_end_time(end_time) USING INVERTED,        \n    INDEX idx_duration(duration) USING INVERTED,        \n    INDEX idx_span_attributes(span_attributes) USING INVERTED,        \n    INDEX idx_status_message(status_message) USING INVERTED,        \n    INDEX idx_status_code(status_code) USING INVERTED,        \n    INDEX idx_resource_attributes(resource_attributes) USING INVERTED,        \n    INDEX idx_scope_name(scope_name) USING INVERTED,        \n    INDEX idx_scope_version(scope_version) USING INVERTED        \n)        \nENGINE = OLAP        \nDUPLICATE KEY(service_name, timestamp)        \nPARTITION BY RANGE(timestamp) ()        \nDISTRIBUTED BY RANDOM BUCKETS 250\nPROPERTIES (\n"compression" = "zstd",\n"compaction_policy" = "time_series",\n"inverted_index_storage_format" = "V2",\n"dynamic_partition.enable" = "true",\n"dynamic_partition.create_history_partition" = "true",\n"dynamic_partition.time_unit" = "DAY",\n"dynamic_partition.start" = "-30",\n"dynamic_partition.end" = "1",\n"dynamic_partition.prefix" = "p",\n"dynamic_partition.buckets" = "250",\n"dynamic_partition.replication_num" = "2", -- Not required for compute-storage separation\n"replication_num" = "2", -- Not required for compute-storage separation\n"storage_policy" = "log_policy_3day" -- Not required for compute-storage separation\n);\n'})}),"\n",(0,r.jsx)(n.h2,{id:"2-trace-collection",children:"2. Trace Collection"}),"\n",(0,r.jsx)(n.p,{children:"Doris provides open and general-purpose Stream HTTP APIs that can integrate with Trace collection systems like OpenTelemetry."}),"\n",(0,r.jsx)(n.h3,{id:"opentelemetry-integration",children:"OpenTelemetry Integration"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"Application-side Integration with OpenTelemetry SDK"})}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Here we use a Spring Boot example application integrated with the OpenTelemetry Java SDK. The example application comes from the official ",(0,r.jsx)(n.a,{href:"https://docs.spring.io/spring-boot/tutorial/first-application/index.html",children:"demo"}),', which returns a simple "Hello World!" string for requests to the path "/".',(0,r.jsx)(n.br,{}),"\nDownload the ",(0,r.jsx)(n.a,{href:"https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases",children:"OpenTelemetry Java Agent"}),". The advantage of using the Java Agent is that no modifications are needed to existing application. For other languages and integration methods, see the OpenTelemetry official website ",(0,r.jsx)(n.a,{href:"https://opentelemetry.io/docs/languages/",children:"Language APIs & SDKs"})," or ",(0,r.jsx)(n.a,{href:"https://opentelemetry.io/docs/zero-code/",children:"Zero-code Instrumentation"}),"."]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"Deploy and Configure OpenTelemetry Collector"})}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Download and extract ",(0,r.jsx)(n.a,{href:"https://github.com/open-telemetry/opentelemetry-collector-releases/releases",children:"OpenTelemetry Collector"}),'. You need to download the package starting with "otelcol-contrib", which includes the Doris Exporter.']}),"\n",(0,r.jsxs)(n.p,{children:["Create the ",(0,r.jsx)(n.code,{children:"otel_demo.yaml"})," configuration file as follows. For more details, refer to the Doris Exporter ",(0,r.jsx)(n.a,{href:"https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/dorisexporter",children:"documentation"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'receivers:\n  otlp: # OTLP protocol, receiving data sent by the OpenTelemetry Java Agent\n    protocols:\n      grpc:\n        endpoint: 0.0.0.0:4317\n      http:\n        endpoint: 0.0.0.0:4318\n\nprocessors:\n  batch:\n    send_batch_size: 100000 # Number of records per batch; recommended batch size between 100MB-1GB\n    timeout: 10s\n\nexporters:\n  doris:\n    endpoint: http://localhost:8030 # FE HTTP address\n    database: doris_db_name\n    username: doris_username\n    password: doris_password\n    table:\n      traces: doris_table_name\n    create_schema: true # Whether to auto-create schema; manual table creation is needed if set to false\n    mysql_endpoint: localhost:9030  # FE MySQL address\n    history_days: 10\n    create_history_days: 10\n    timezone: Asia/Shanghai\n    timeout: 60s # Timeout for HTTP stream load client\n    log_response: true\n    sending_queue:\n      enabled: true\n      num_consumers: 20\n      queue_size: 1000\n    retry_on_failure:\n      enabled: true\n      initial_interval: 5s\n      max_interval: 30s\n    headers:\n      load_to_single_tablet: "true"\n'})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"Run OpenTelemetry Collector"})}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"./otelcol-contrib --config otel_demo.yaml\n"})}),"\n",(0,r.jsxs)(n.ol,{start:"4",children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"Start the Spring Boot Example Application"})}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Before starting the application, simply add a few environment variables without modifying any code."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'export JAVA_TOOL_OPTIONS="${JAVA_TOOL_OPTIONS} -javaagent:/your/path/to/opentelemetry-javaagent.jar" # Path to OpenTelemetry Java Agent\nexport OTEL_JAVAAGENT_LOGGING="none" # Disable Otel logs to prevent interference with application logs\nexport OTEL_SERVICE_NAME="myproject"\nexport OTEL_TRACES_EXPORTER="otlp" # Send trace data using OTLP protocol\nexport OTEL_EXPORTER_OTLP_ENDPOINT="http://localhost:4317" # Address of the OpenTelemetry Collector\n\njava -jar myproject-0.0.1-SNAPSHOT.jar\n'})}),"\n",(0,r.jsxs)(n.ol,{start:"5",children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"Access the Spring Boot Example Service to Generate Trace Data"})}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Running ",(0,r.jsx)(n.code,{children:"curl localhost:8080"})," will trigger a call to the ",(0,r.jsx)(n.code,{children:"hello"})," service. The OpenTelemetry Java Agent will automatically generate Trace data and send it to the OpenTelemetry Collector, which then writes the Trace data to the Doris table (default is ",(0,r.jsx)(n.code,{children:"otel.otel_traces"}),") via the configured Doris Exporter."]}),"\n",(0,r.jsx)(n.h2,{id:"3-trace-querying",children:"3. Trace Querying"}),"\n",(0,r.jsx)(n.p,{children:"Trace querying typically uses visual query interfaces such as Grafana."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Filter by time range and service name to display Trace summaries, including latency distribution charts and detailed individual Traces."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Trace List",src:t(284321).Z+"",width:"1280",height:"647"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Click on the link to view the Trace detail."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Trace Detail",src:t(728136).Z+"",width:"1280",height:"649"})}),"\n"]}),"\n"]})]})}function p(e={}){let{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},728136:function(e,n,t){t.d(n,{Z:function(){return i}});let i=t.p+"assets/images/trace-detail-bedc1a6214e7c51a1a48b525a5047417.png"},284321:function(e,n,t){t.d(n,{Z:function(){return i}});let i=t.p+"assets/images/trace-list-bcebf4404c5cca80cf72a96ceca0f692.png"},250065:function(e,n,t){t.d(n,{Z:function(){return o},a:function(){return s}});var i=t(667294);let r={},a=i.createContext(r);function s(e){let n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);