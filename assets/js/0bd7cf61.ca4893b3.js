"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["964281"],{684718:function(e,i,t){t.r(i),t.d(i,{default:()=>u,frontMatter:()=>s,metadata:()=>n,assets:()=>c,toc:()=>d,contentTitle:()=>o});var n=JSON.parse('{"id":"lakehouse/best-practices/optimization","title":"Data Lake Query Optimization","description":"This document mainly introduces optimization methods and strategies for querying lake data (Hive, Iceberg, Paimon, etc.).","source":"@site/versioned_docs/version-3.x/lakehouse/best-practices/optimization.md","sourceDirName":"lakehouse/best-practices","slug":"/lakehouse/best-practices/optimization","permalink":"/docs/3.x/lakehouse/best-practices/optimization","draft":false,"unlisted":false,"tags":[],"version":"3.x","lastUpdatedAt":1770477659000,"frontMatter":{"title":"Data Lake Query Optimization","language":"en","description":"This document mainly introduces optimization methods and strategies for querying lake data (Hive, Iceberg, Paimon, etc.)."},"sidebar":"docs","previous":{"title":"PostgreSQL SQL Convertor Guide","permalink":"/docs/3.x/lakehouse/sql-convertor/pg-guide"},"next":{"title":"Using Doris and Hudi","permalink":"/docs/3.x/lakehouse/best-practices/doris-hudi"}}'),a=t("785893"),r=t("250065");let s={title:"Data Lake Query Optimization",language:"en",description:"This document mainly introduces optimization methods and strategies for querying lake data (Hive, Iceberg, Paimon, etc.)."},o=void 0,c={},d=[{value:"Partition Pruning",id:"partition-pruning",level:2},{value:"Local Data Cache",id:"local-data-cache",level:2},{value:"HDFS Read Optimization",id:"hdfs-read-optimization",level:2},{value:"Merge IO Optimization",id:"merge-io-optimization",level:2}];function l(e){let i={a:"a",code:"code",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(i.p,{children:"This document mainly introduces optimization methods and strategies for querying lake data (Hive, Iceberg, Paimon, etc.)."}),"\n",(0,a.jsx)(i.h2,{id:"partition-pruning",children:"Partition Pruning"}),"\n",(0,a.jsx)(i.p,{children:"By specifying partition column conditions in queries, unnecessary partitions can be pruned, reducing the amount of data that needs to be read."}),"\n",(0,a.jsxs)(i.p,{children:["You can use ",(0,a.jsx)(i.code,{children:"EXPLAIN <SQL>"})," to view the ",(0,a.jsx)(i.code,{children:"partition"})," section of ",(0,a.jsx)(i.code,{children:"XXX_SCAN_NODE"})," to check whether partition pruning is effective and how many partitions need to be scanned in this query."]}),"\n",(0,a.jsx)(i.p,{children:"For example:"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{children:"0:VPAIMON_SCAN_NODE(88)\n    table: paimon_ctl.db.table\n    predicates: (user_id[#4] = 431304818)\n    inputSplitNum=15775, totalFileSize=951754154566, scanRanges=15775\n    partition=203/0\n"})}),"\n",(0,a.jsx)(i.h2,{id:"local-data-cache",children:"Local Data Cache"}),"\n",(0,a.jsx)(i.p,{children:"Data Cache accelerates subsequent queries accessing the same data by caching recently accessed data files from remote storage systems (HDFS or object storage) to local disk."}),"\n",(0,a.jsxs)(i.p,{children:["The cache feature is disabled by default. Please refer to the ",(0,a.jsx)(i.a,{href:"/docs/3.x/lakehouse/data-cache",children:"Data Cache"})," documentation to configure and enable it."]}),"\n",(0,a.jsx)(i.p,{children:"Since version 4.0.2, cache warmup functionality is supported, which can further actively utilize data cache to improve query performance."}),"\n",(0,a.jsx)(i.h2,{id:"hdfs-read-optimization",children:"HDFS Read Optimization"}),"\n",(0,a.jsxs)(i.p,{children:["Please refer to the ",(0,a.jsx)(i.strong,{children:"HDFS IO Optimization"})," section in the ",(0,a.jsx)(i.a,{href:"/docs/3.x/lakehouse/storages/hdfs",children:"HDFS Documentation"}),"."]}),"\n",(0,a.jsx)(i.h2,{id:"merge-io-optimization",children:"Merge IO Optimization"}),"\n",(0,a.jsx)(i.p,{children:"For remote storage systems like HDFS and object storage, Doris optimizes IO access through Merge IO technology. Merge IO technology essentially merges multiple adjacent small IO requests into one large IO request, which can reduce IOPS and increase IO throughput."}),"\n",(0,a.jsxs)(i.p,{children:["For example, if the original request needs to read parts [0, 10] and [20, 50] of file ",(0,a.jsx)(i.code,{children:"file1"}),":"]}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{children:"Request Range: [0, 10], [20, 50]\n"})}),"\n",(0,a.jsx)(i.p,{children:"Through Merge IO, it will be merged into one request:"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{children:"Request Range: [0, 50]\n"})}),"\n",(0,a.jsx)(i.p,{children:"In this example, two IO requests are merged into one, but it also reads some additional data (data between 10-20). Therefore, while Merge IO reduces the number of IO operations, it may bring potential read amplification issues."}),"\n",(0,a.jsx)(i.p,{children:"You can view specific Merge IO information through Query Profile:"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{children:"- MergedSmallIO:\n    - MergedBytes: 3.00 GB\n    - MergedIO: 424\n    - RequestBytes: 2.50 GB\n    - RequestIO: 65.555K (65555)\n"})}),"\n",(0,a.jsxs)(i.p,{children:["Where ",(0,a.jsx)(i.code,{children:"RequestBytes"})," and ",(0,a.jsx)(i.code,{children:"RequestIO"})," indicate the data volume and number of requests in the original request. ",(0,a.jsx)(i.code,{children:"MergedBytes"})," and ",(0,a.jsx)(i.code,{children:"MergedIO"})," indicate the data volume and number of requests after merging."]}),"\n",(0,a.jsxs)(i.p,{children:["If you find that ",(0,a.jsx)(i.code,{children:"MergedBytes"})," is much larger than ",(0,a.jsx)(i.code,{children:"RequestBytes"}),", it indicates serious read amplification. You can adjust it through the following parameters:"]}),"\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsxs)(i.li,{children:["\n",(0,a.jsx)(i.p,{children:(0,a.jsx)(i.code,{children:"merge_io_read_slice_size_bytes"})}),"\n",(0,a.jsx)(i.p,{children:"Session variable, supported since version 3.1.3. Default is 8MB. If you find serious read amplification, you can reduce this parameter, such as to 64KB, and observe whether the modified IO requests and query latency improve."}),"\n"]}),"\n"]})]})}function u(e={}){let{wrapper:i}={...(0,r.a)(),...e.components};return i?(0,a.jsx)(i,{...e,children:(0,a.jsx)(l,{...e})}):l(e)}},250065:function(e,i,t){t.d(i,{Z:function(){return o},a:function(){return s}});var n=t(667294);let a={},r=n.createContext(a);function s(e){let i=n.useContext(r);return n.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function o(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),n.createElement(r.Provider,{value:i},e.children)}}}]);