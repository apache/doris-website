"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["749767"],{79795:function(e,n,r){r.r(n),r.d(n,{default:()=>h,frontMatter:()=>s,metadata:()=>t,assets:()=>c,toc:()=>d,contentTitle:()=>o});var t=JSON.parse('{"id":"lakehouse/catalogs/kafka-catalog","title":"Kafka Catalog","description":"Apache Doris Kafka Catalog guide: Connect to Kafka data streams through Trino Connector framework to query and integrate Kafka Topic data. Supports Schema Registry, multiple data formats for quick Kafka and Doris data integration.","source":"@site/versioned_docs/version-4.x/lakehouse/catalogs/kafka-catalog.md","sourceDirName":"lakehouse/catalogs","slug":"/lakehouse/catalogs/kafka-catalog","permalink":"/docs/4.x/lakehouse/catalogs/kafka-catalog","draft":false,"unlisted":false,"tags":[],"version":"4.x","lastUpdatedAt":1770477659000,"frontMatter":{"title":"Kafka Catalog","language":"en","description":"Apache Doris Kafka Catalog guide: Connect to Kafka data streams through Trino Connector framework to query and integrate Kafka Topic data. Supports Schema Registry, multiple data formats for quick Kafka and Doris data integration."},"sidebar":"docs","previous":{"title":"Kudu Catalog","permalink":"/docs/4.x/lakehouse/catalogs/kudu-catalog"},"next":{"title":"Elasticsearch Catalog","permalink":"/docs/4.x/lakehouse/catalogs/es-catalog"}}'),i=r("785893"),a=r("250065");let s={title:"Kafka Catalog",language:"en",description:"Apache Doris Kafka Catalog guide: Connect to Kafka data streams through Trino Connector framework to query and integrate Kafka Topic data. Supports Schema Registry, multiple data formats for quick Kafka and Doris data integration."},o=void 0,c={},d=[{value:"Overview",id:"overview",level:2},{value:"Use Cases",id:"use-cases",level:3},{value:"Version Compatibility",id:"version-compatibility",level:3},{value:"Quick Start",id:"quick-start",level:2},{value:"Step 1: Prepare Connector Plugin",id:"step-1-prepare-connector-plugin",level:3},{value:"Step 2: Deploy Plugin",id:"step-2-deploy-plugin",level:3},{value:"Step 3: Create Catalog",id:"step-3-create-catalog",level:3},{value:"Step 4: Query Data",id:"step-4-query-data",level:3},{value:"Schema Registry Integration",id:"schema-registry-integration",level:2},{value:"Configure Schema Registry",id:"configure-schema-registry",level:3},{value:"Schema Registry Parameters",id:"schema-registry-parameters",level:3},{value:"Subject Mapping",id:"subject-mapping",level:3},{value:"Configuration",id:"configuration",level:2},{value:"Catalog Configuration Parameters",id:"catalog-configuration-parameters",level:3},{value:"TrinoProperties Parameters",id:"trinoproperties-parameters",level:4},{value:"CommonProperties Parameters",id:"commonproperties-parameters",level:4},{value:"Kafka Client Configuration",id:"kafka-client-configuration",level:3},{value:"Data Type Mapping",id:"data-type-mapping",level:2},{value:"Kafka Internal Columns",id:"kafka-internal-columns",level:2},{value:"Limitations",id:"limitations",level:2},{value:"Feature Debugging",id:"feature-debugging",level:2},{value:"References",id:"references",level:2}];function l(e){let n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsxs)(n.p,{children:["Kafka Catalog uses the Trino Kafka Connector through the ",(0,i.jsx)(n.a,{href:"https://doris.apache.org/community/how-to-contribute/trino-connector-developer-guide/",children:"Trino Connector"})," compatibility framework to access Kafka Topic data."]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"This is an experimental feature, supported since version 3.0.1."}),"\n",(0,i.jsx)(n.li,{children:"This feature does not depend on a Trino cluster environment; it only uses Trino-compatible plugins."}),"\n"]})}),"\n",(0,i.jsx)(n.h3,{id:"use-cases",children:"Use Cases"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Scenario"}),(0,i.jsx)(n.th,{children:"Support Status"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Data Integration"}),(0,i.jsx)(n.td,{children:"Read Kafka Topic data and write to Doris internal tables"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Data Write-back"}),(0,i.jsx)(n.td,{children:"Not supported"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"version-compatibility",children:"Version Compatibility"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Doris Version"}),": 3.0.1 and above"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Trino Connector Version"}),": 435"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Kafka Version"}),": For supported versions, please refer to ",(0,i.jsx)(n.a,{href:"https://trino.io/docs/435/connector/kafka.html",children:"Trino Documentation"})]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,i.jsx)(n.h3,{id:"step-1-prepare-connector-plugin",children:"Step 1: Prepare Connector Plugin"}),"\n",(0,i.jsx)(n.p,{children:"You can obtain the Kafka Connector plugin using one of the following methods:"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Method 1: Use Pre-compiled Package (Recommended)"})}),"\n",(0,i.jsxs)(n.p,{children:["Download and extract the pre-compiled plugin package from ",(0,i.jsx)(n.a,{href:"https://github.com/apache/doris-thirdparty/releases/tag/trino-435-20240724",children:"here"}),"."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Method 2: Manual Compilation"})}),"\n",(0,i.jsx)(n.p,{children:"If you need custom compilation, follow these steps (requires JDK 17):"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"git clone https://github.com/apache/doris-thirdparty.git\ncd doris-thirdparty\ngit checkout trino-435\ncd plugin/trino-kafka\nmvn clean package -Dmaven.test.skip=true\n"})}),"\n",(0,i.jsxs)(n.p,{children:["After compilation, you will get the ",(0,i.jsx)(n.code,{children:"trino-kafka-435/"})," directory under ",(0,i.jsx)(n.code,{children:"trino/plugin/trino-kafka/target/"}),"."]}),"\n",(0,i.jsx)(n.h3,{id:"step-2-deploy-plugin",children:"Step 2: Deploy Plugin"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Place the ",(0,i.jsx)(n.code,{children:"trino-kafka-435/"})," directory in the ",(0,i.jsx)(n.code,{children:"connectors/"})," directory of all FE and BE deployment paths (create the directory manually if it doesn't exist):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"\u251C\u2500\u2500 bin\n\u251C\u2500\u2500 conf\n\u251C\u2500\u2500 plugins\n\u2502   \u251C\u2500\u2500 connectors\n\u2502       \u251C\u2500\u2500 trino-kafka-435\n...\n"})}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:["You can also customize the plugin path by modifying the ",(0,i.jsx)(n.code,{children:"trino_connector_plugin_dir"})," configuration in ",(0,i.jsx)(n.code,{children:"fe.conf"}),". For example: ",(0,i.jsx)(n.code,{children:"trino_connector_plugin_dir=/path/to/connectors/"})]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Restart all FE and BE nodes to ensure the connector is properly loaded."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"step-3-create-catalog",children:"Step 3: Create Catalog"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Basic Configuration"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG kafka PROPERTIES (\n    'type' = 'trino-connector',\n    'trino.connector.name' = 'kafka',\n    'trino.kafka.nodes' = '<broker1>:<port1>,<broker2>:<port2>',\n    'trino.kafka.table-names' = 'test_db.topic_name',\n    'trino.kafka.hide-internal-columns' = 'false'\n);\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Using Configuration File"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG kafka PROPERTIES (\n    'type' = 'trino-connector',\n    'trino.connector.name' = 'kafka',\n    'trino.kafka.nodes' = '<broker1>:<port1>,<broker2>:<port2>',\n    'trino.kafka.config.resources' = '/path/to/kafka-client.properties',\n    'trino.kafka.hide-internal-columns' = 'false'\n);\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Configure Default Schema"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG kafka PROPERTIES (\n    'type' = 'trino-connector',\n    'trino.connector.name' = 'kafka',\n    'trino.kafka.nodes' = '<broker1>:<port1>,<broker2>:<port2>',\n    'trino.kafka.default-schema' = 'default_db',\n    'trino.kafka.hide-internal-columns' = 'false'\n);\n"})}),"\n",(0,i.jsx)(n.h3,{id:"step-4-query-data",children:"Step 4: Query Data"}),"\n",(0,i.jsx)(n.p,{children:"After creating the catalog, you can query Kafka Topic data using one of three methods:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"-- Method 1: Switch to catalog and query\nSWITCH kafka;\nUSE kafka_schema;\nSELECT * FROM topic_name LIMIT 10;\n\n-- Method 2: Use two-level path\nUSE kafka.kafka_schema;\nSELECT * FROM topic_name LIMIT 10;\n\n-- Method 3: Use fully qualified name\nSELECT * FROM kafka.kafka_schema.topic_name LIMIT 10;\n"})}),"\n",(0,i.jsx)(n.h2,{id:"schema-registry-integration",children:"Schema Registry Integration"}),"\n",(0,i.jsx)(n.p,{children:"Kafka Catalog supports automatic schema retrieval through Confluent Schema Registry, eliminating the need to manually define table structures."}),"\n",(0,i.jsx)(n.h3,{id:"configure-schema-registry",children:"Configure Schema Registry"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Basic Authentication"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG kafka PROPERTIES (\n    'type' = 'trino-connector',\n    'trino.connector.name' = 'kafka',\n    'trino.kafka.nodes' = '<broker1>:<port1>',\n    'trino.kafka.table-description-supplier' = 'CONFLUENT',\n    'trino.kafka.confluent-schema-registry-url' = 'http://<schema-registry-host>:<schema-registry-port>',\n    'trino.kafka.confluent-schema-registry-auth-type' = 'BASIC_AUTH',\n    'trino.kafka.confluent-schema-registry.basic-auth.username' = 'admin',\n    'trino.kafka.confluent-schema-registry.basic-auth.password' = 'admin123',\n    'trino.kafka.hide-internal-columns' = 'false'\n);\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Complete Configuration Example"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG kafka PROPERTIES (\n    'type' = 'trino-connector',\n    'trino.connector.name' = 'kafka',\n    'trino.kafka.nodes' = '<broker1>:<port1>',\n    'trino.kafka.default-schema' = 'nrdp',\n    'trino.kafka.table-description-supplier' = 'CONFLUENT',\n    'trino.kafka.confluent-schema-registry-url' = 'http://<schema-registry-host>:<schema-registry-port>',\n    'trino.kafka.confluent-schema-registry-auth-type' = 'BASIC_AUTH',\n    'trino.kafka.confluent-schema-registry.basic-auth.username' = 'admin',\n    'trino.kafka.confluent-schema-registry.basic-auth.password' = 'admin123',\n    'trino.kafka.config.resources' = '/path/to/kafka-client.properties',\n    'trino.kafka.confluent-schema-registry-subject-mapping' = 'nrdp.topic1:NRDP.topic1',\n    'trino.kafka.hide-internal-columns' = 'false'\n);\n"})}),"\n",(0,i.jsx)(n.h3,{id:"schema-registry-parameters",children:"Schema Registry Parameters"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Parameter Name"}),(0,i.jsx)(n.th,{children:"Required"}),(0,i.jsx)(n.th,{children:"Default"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"trino.kafka.table-description-supplier"})}),(0,i.jsx)(n.td,{children:"No"}),(0,i.jsx)(n.td,{children:"-"}),(0,i.jsxs)(n.td,{children:["Set to ",(0,i.jsx)(n.code,{children:"CONFLUENT"})," to enable Schema Registry support"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"trino.kafka.confluent-schema-registry-url"})}),(0,i.jsx)(n.td,{children:"Yes*"}),(0,i.jsx)(n.td,{children:"-"}),(0,i.jsx)(n.td,{children:"Schema Registry service address"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"trino.kafka.confluent-schema-registry-auth-type"})}),(0,i.jsx)(n.td,{children:"No"}),(0,i.jsx)(n.td,{children:"NONE"}),(0,i.jsx)(n.td,{children:"Authentication type: NONE, BASIC_AUTH, BEARER"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"trino.kafka.confluent-schema-registry.basic-auth.username"})}),(0,i.jsx)(n.td,{children:"No"}),(0,i.jsx)(n.td,{children:"-"}),(0,i.jsx)(n.td,{children:"Basic Auth username"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"trino.kafka.confluent-schema-registry.basic-auth.password"})}),(0,i.jsx)(n.td,{children:"No"}),(0,i.jsx)(n.td,{children:"-"}),(0,i.jsx)(n.td,{children:"Basic Auth password"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"trino.kafka.confluent-schema-registry-subject-mapping"})}),(0,i.jsx)(n.td,{children:"No"}),(0,i.jsx)(n.td,{children:"-"}),(0,i.jsxs)(n.td,{children:["Subject name mapping, format: ",(0,i.jsx)(n.code,{children:"<db1>.<tbl1>:<topic_name1>,<db2>.<tbl2>:<topic_name2>"})]})]})]})]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsx)(n.p,{children:"When using Schema Registry, Doris will automatically retrieve Topic schema information from Schema Registry, eliminating the need to manually create table structures."})}),"\n",(0,i.jsx)(n.h3,{id:"subject-mapping",children:"Subject Mapping"}),"\n",(0,i.jsxs)(n.p,{children:["In some cases, the Subject name registered in Schema Registry may not match the Topic name in Kafka, preventing data queries. In such cases, you need to manually specify the mapping relationship through ",(0,i.jsx)(n.code,{children:"confluent-schema-registry-subject-mapping"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"-- Map schema.topic to SCHEMA.topic Subject in Schema Registry\n'trino.kafka.confluent-schema-registry-subject-mapping' = '<db1>.<tbl1>:<topic_name1>'\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Where ",(0,i.jsx)(n.code,{children:"db1"})," and ",(0,i.jsx)(n.code,{children:"tbl1"})," are the actual Database and Table names seen in Doris, and ",(0,i.jsx)(n.code,{children:"topic_name1"})," is the actual Topic name in Kafka (case-sensitive)."]}),"\n",(0,i.jsx)(n.p,{children:"Multiple mappings can be separated by commas:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"'trino.kafka.confluent-schema-registry-subject-mapping' = '<db1>.<tbl1>:<topic_name1>,<db2>.<tbl2>:<topic_name2>'\n"})}),"\n",(0,i.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,i.jsx)(n.h3,{id:"catalog-configuration-parameters",children:"Catalog Configuration Parameters"}),"\n",(0,i.jsx)(n.p,{children:"The basic syntax for creating a Kafka Catalog is as follows:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG [IF NOT EXISTS] catalog_name PROPERTIES (\n    'type' = 'trino-connector',          -- Required, fixed value\n    'trino.connector.name' = 'kafka',    -- Required, fixed value\n    {TrinoProperties},                   -- Trino Connector related properties\n    {CommonProperties}                   -- Common properties\n);\n"})}),"\n",(0,i.jsx)(n.h4,{id:"trinoproperties-parameters",children:"TrinoProperties Parameters"}),"\n",(0,i.jsxs)(n.p,{children:["TrinoProperties are used to configure Trino Kafka Connector-specific properties, which are prefixed with ",(0,i.jsx)(n.code,{children:"trino."}),". Common parameters include:"]}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Parameter Name"}),(0,i.jsx)(n.th,{children:"Required"}),(0,i.jsx)(n.th,{children:"Default"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"trino.kafka.nodes"})}),(0,i.jsx)(n.td,{children:"Yes"}),(0,i.jsx)(n.td,{children:"-"}),(0,i.jsxs)(n.td,{children:["Kafka Broker node address list, format: ",(0,i.jsx)(n.code,{children:"host1:port1,host2:port2"})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"trino.kafka.table-names"})}),(0,i.jsx)(n.td,{children:"No"}),(0,i.jsx)(n.td,{children:"-"}),(0,i.jsxs)(n.td,{children:["List of Topics to map, format: ",(0,i.jsx)(n.code,{children:"schema.topic1,schema.topic2"})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"trino.kafka.default-schema"})}),(0,i.jsx)(n.td,{children:"No"}),(0,i.jsx)(n.td,{children:"default"}),(0,i.jsx)(n.td,{children:"Default schema name"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"trino.kafka.hide-internal-columns"})}),(0,i.jsx)(n.td,{children:"No"}),(0,i.jsx)(n.td,{children:"true"}),(0,i.jsxs)(n.td,{children:["Whether to hide Kafka internal columns (such as ",(0,i.jsx)(n.code,{children:"_partition_id"}),", ",(0,i.jsx)(n.code,{children:"_partition_offset"}),", etc.)"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"trino.kafka.config.resources"})}),(0,i.jsx)(n.td,{children:"No"}),(0,i.jsx)(n.td,{children:"-"}),(0,i.jsx)(n.td,{children:"Kafka client configuration file path"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"trino.kafka.table-description-supplier"})}),(0,i.jsx)(n.td,{children:"No"}),(0,i.jsx)(n.td,{children:"-"}),(0,i.jsxs)(n.td,{children:["Table structure provider, set to ",(0,i.jsx)(n.code,{children:"CONFLUENT"})," to use Schema Registry"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"trino.kafka.confluent-schema-registry-url"})}),(0,i.jsx)(n.td,{children:"No"}),(0,i.jsx)(n.td,{children:"-"}),(0,i.jsx)(n.td,{children:"Schema Registry service address"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:["For more Kafka Connector configuration parameters, please refer to ",(0,i.jsx)(n.a,{href:"https://trino.io/docs/435/connector/kafka.html",children:"Trino Official Documentation"}),"."]}),"\n",(0,i.jsx)(n.h4,{id:"commonproperties-parameters",children:"CommonProperties Parameters"}),"\n",(0,i.jsxs)(n.p,{children:['CommonProperties are used to configure general catalog properties, such as metadata refresh policies and permission control. For detailed information, please refer to the "Common Properties" section in ',(0,i.jsx)(n.a,{href:"/docs/4.x/lakehouse/catalog-overview",children:"Catalog Overview"}),"."]}),"\n",(0,i.jsx)(n.h3,{id:"kafka-client-configuration",children:"Kafka Client Configuration"}),"\n",(0,i.jsxs)(n.p,{children:["When you need to configure advanced Kafka client parameters (such as security authentication, SSL, etc.), you can specify them through a configuration file. Create a configuration file (e.g., ",(0,i.jsx)(n.code,{children:"kafka-client.properties"}),"):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-properties",children:'# ============================================\n# Kerberos/SASL Authentication Configuration\n# ============================================\nsasl.mechanism=GSSAPI\nsasl.kerberos.service.name=kafka\n\n# JAAS Configuration - Using keytab method\nsasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required \\\n    useKeyTab=true \\\n    storeKey=true \\\n    useTicketCache=false \\\n    serviceName="kafka" \\\n    keyTab="/opt/trino/security/keytabs/kafka.keytab" \\\n    principal="kafka@EXAMPLE.COM";\n\n# ============================================\n# Avro Deserializer Configuration\n# ============================================\nkey.deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer\nvalue.deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer\n'})}),"\n",(0,i.jsx)(n.p,{children:"Then specify the configuration file when creating the catalog:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"CREATE CATALOG kafka PROPERTIES (\n    'type' = 'trino-connector',\n    'trino.connector.name' = 'kafka',\n    'trino.kafka.nodes' = '<broker1>:<port1>',\n    'trino.kafka.config.resources' = '/path/to/kafka-client.properties'\n);\n"})}),"\n",(0,i.jsx)(n.h2,{id:"data-type-mapping",children:"Data Type Mapping"}),"\n",(0,i.jsx)(n.p,{children:"When using Kafka Catalog, data types are mapped according to the following rules:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Kafka/Avro Type"}),(0,i.jsx)(n.th,{children:"Trino Type"}),(0,i.jsx)(n.th,{children:"Doris Type"}),(0,i.jsx)(n.th,{children:"Notes"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"boolean"}),(0,i.jsx)(n.td,{children:"boolean"}),(0,i.jsx)(n.td,{children:"boolean"}),(0,i.jsx)(n.td,{})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"int"}),(0,i.jsx)(n.td,{children:"integer"}),(0,i.jsx)(n.td,{children:"int"}),(0,i.jsx)(n.td,{})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"long"}),(0,i.jsx)(n.td,{children:"bigint"}),(0,i.jsx)(n.td,{children:"bigint"}),(0,i.jsx)(n.td,{})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"float"}),(0,i.jsx)(n.td,{children:"real"}),(0,i.jsx)(n.td,{children:"float"}),(0,i.jsx)(n.td,{})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"double"}),(0,i.jsx)(n.td,{children:"double"}),(0,i.jsx)(n.td,{children:"double"}),(0,i.jsx)(n.td,{})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"bytes"}),(0,i.jsx)(n.td,{children:"varbinary"}),(0,i.jsx)(n.td,{children:"string"}),(0,i.jsxs)(n.td,{children:["Use ",(0,i.jsx)(n.code,{children:"HEX(col)"})," function to query"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"string"}),(0,i.jsx)(n.td,{children:"varchar"}),(0,i.jsx)(n.td,{children:"string"}),(0,i.jsx)(n.td,{})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"array"}),(0,i.jsx)(n.td,{children:"array"}),(0,i.jsx)(n.td,{children:"array"}),(0,i.jsx)(n.td,{})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"map"}),(0,i.jsx)(n.td,{children:"map"}),(0,i.jsx)(n.td,{children:"map"}),(0,i.jsx)(n.td,{})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"record"}),(0,i.jsx)(n.td,{children:"row"}),(0,i.jsx)(n.td,{children:"struct"}),(0,i.jsx)(n.td,{children:"Complex nested structure"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"enum"}),(0,i.jsx)(n.td,{children:"varchar"}),(0,i.jsx)(n.td,{children:"string"}),(0,i.jsx)(n.td,{})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"fixed"}),(0,i.jsx)(n.td,{children:"varbinary"}),(0,i.jsx)(n.td,{children:"string"}),(0,i.jsx)(n.td,{})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"null"}),(0,i.jsx)(n.td,{children:"-"}),(0,i.jsx)(n.td,{children:"-"}),(0,i.jsx)(n.td,{})]})]})]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["For ",(0,i.jsx)(n.code,{children:"bytes"})," type, use the ",(0,i.jsx)(n.code,{children:"HEX()"})," function to display in hexadecimal format."]}),"\n",(0,i.jsx)(n.li,{children:"The data types supported by Kafka Catalog depend on the serialization format used (JSON, Avro, Protobuf, etc.) and Schema Registry configuration."}),"\n"]})}),"\n",(0,i.jsx)(n.h2,{id:"kafka-internal-columns",children:"Kafka Internal Columns"}),"\n",(0,i.jsx)(n.p,{children:"Kafka Connector provides some internal columns to access metadata information of Kafka messages:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Column Name"}),(0,i.jsx)(n.th,{children:"Type"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"_partition_id"})}),(0,i.jsx)(n.td,{children:"bigint"}),(0,i.jsx)(n.td,{children:"Partition ID where the message is located"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"_partition_offset"})}),(0,i.jsx)(n.td,{children:"bigint"}),(0,i.jsx)(n.td,{children:"Message offset within the partition"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"_message_timestamp"})}),(0,i.jsx)(n.td,{children:"timestamp"}),(0,i.jsx)(n.td,{children:"Message timestamp"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"_key"})}),(0,i.jsx)(n.td,{children:"varchar"}),(0,i.jsx)(n.td,{children:"Message key"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"_key_corrupt"})}),(0,i.jsx)(n.td,{children:"boolean"}),(0,i.jsx)(n.td,{children:"Whether the key is corrupted"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"_key_length"})}),(0,i.jsx)(n.td,{children:"bigint"}),(0,i.jsx)(n.td,{children:"Key byte length"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"_message"})}),(0,i.jsx)(n.td,{children:"varchar"}),(0,i.jsx)(n.td,{children:"Raw message content"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"_message_corrupt"})}),(0,i.jsx)(n.td,{children:"boolean"}),(0,i.jsx)(n.td,{children:"Whether the message is corrupted"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"_message_length"})}),(0,i.jsx)(n.td,{children:"bigint"}),(0,i.jsx)(n.td,{children:"Message byte length"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"_headers"})}),(0,i.jsx)(n.td,{children:"map"}),(0,i.jsx)(n.td,{children:"Message header information"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"By default, these internal columns are hidden. If you need to query these columns, set when creating the catalog:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"'trino.kafka.hide-internal-columns' = 'false'\n"})}),"\n",(0,i.jsx)(n.p,{children:"Query example:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"SELECT \n    _partition_id,\n    _partition_offset,\n    _message_timestamp,\n    *\nFROM kafka.schema.topic_name\nLIMIT 10;\n"})}),"\n",(0,i.jsx)(n.h2,{id:"limitations",children:"Limitations"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Read-only Access"}),": Kafka Catalog only supports reading data; write operations (INSERT, UPDATE, DELETE) are not supported."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Table Names Configuration"}),": When not using Schema Registry, you need to explicitly specify the list of Topics to access through the ",(0,i.jsx)(n.code,{children:"trino.kafka.table-names"})," parameter."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Schema Definition"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"When using Schema Registry, schema information is automatically retrieved from Schema Registry."}),"\n",(0,i.jsx)(n.li,{children:"When not using Schema Registry, you need to manually create table definitions or use Trino's Topic description files."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Data Format"}),": Supported data formats depend on the serialization method used by the Topic (JSON, Avro, Protobuf, etc.). For details, please refer to ",(0,i.jsx)(n.a,{href:"https://trino.io/docs/435/connector/kafka.html",children:"Trino Official Documentation"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Performance Considerations"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Kafka Catalog reads Kafka data in real-time; querying large amounts of data may affect performance."}),"\n",(0,i.jsxs)(n.li,{children:["It is recommended to use the ",(0,i.jsx)(n.code,{children:"LIMIT"})," clause or time filter conditions to limit the amount of data scanned."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"feature-debugging",children:"Feature Debugging"}),"\n",(0,i.jsxs)(n.p,{children:["You can refer to ",(0,i.jsx)(n.a,{href:"https://github.com/morningman/demo-env/tree/main/kafka",children:"here"})," to quickly build a Kafka environment for feature verification."]}),"\n",(0,i.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://trino.io/docs/435/connector/kafka.html",children:"Trino Kafka Connector Official Documentation"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://doris.apache.org/community/how-to-contribute/trino-connector-developer-guide/",children:"Trino Connector Development Guide"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://docs.confluent.io/platform/current/schema-registry/index.html",children:"Confluent Schema Registry Documentation"})}),"\n"]})]})}function h(e={}){let{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},250065:function(e,n,r){r.d(n,{Z:function(){return o},a:function(){return s}});var t=r(667294);let i={},a=t.createContext(i);function s(e){let n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);