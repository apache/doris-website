"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["454245"],{881199:function(e,n,t){t.r(n),t.d(n,{default:()=>h,frontMatter:()=>s,metadata:()=>i,assets:()=>l,toc:()=>d,contentTitle:()=>a});var i=JSON.parse('{"id":"ecosystem/observability/fluentbit","title":"FluentBit","description":"Fluent Bit is a fast log processor and forwarder that supports custom output plugins to write data into storage systems, with the Fluent Bit Doris output plugin being the one for outputting to Doris.","source":"@site/docs/ecosystem/observability/fluentbit.md","sourceDirName":"ecosystem/observability","slug":"/ecosystem/observability/fluentbit","permalink":"/docs/dev/ecosystem/observability/fluentbit","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"FluentBit","language":"en"},"sidebar":"docs","previous":{"title":"OpenTelemetry","permalink":"/docs/dev/ecosystem/observability/opentelemetry"},"next":{"title":"Overview","permalink":"/docs/dev/compute-storage-decoupled/overview"}}'),o=t("785893"),r=t("250065");let s={title:"FluentBit",language:"en"},a=void 0,l={},d=[{value:"Installation (alpha)",id:"installation-alpha",level:2},{value:"Download",id:"download",level:3},{value:"Compile from Source Code",id:"compile-from-source-code",level:3},{value:"Configuration",id:"configuration",level:2},{value:"Usage Example",id:"usage-example",level:2},{value:"TEXT Log Collection Example",id:"text-log-collection-example",level:3},{value:"JSON Log Collection Example",id:"json-log-collection-example",level:3}];function c(e){let n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,r.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://fluentbit.io/",children:"Fluent Bit"})," is a fast log processor and forwarder that supports custom output plugins to write data into storage systems, with the Fluent Bit Doris output plugin being the one for outputting to Doris."]}),"\n",(0,o.jsxs)(n.p,{children:["By invoking the ",(0,o.jsx)(n.a,{href:"../data-operate/import/import-way/stream-load-manual",children:"Doris Stream Load"})," HTTP interface, the Fluent Bit Doris output plugin writes data into Doris in real-time, offering capabilities such as multi-threaded concurrency, failure retries, custom Stream Load formats and parameters, and output write speed."]}),"\n",(0,o.jsx)(n.p,{children:"To use the Fluent Bit Doris output plugin, there are three main steps:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Download or compile the Fluent Bit binary program that includes the Doris output plugin."}),"\n",(0,o.jsx)(n.li,{children:"Configure the Fluent Bit output address and other parameters."}),"\n",(0,o.jsx)(n.li,{children:"Start Fluent Bit to write data into Doris in real-time."}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"installation-alpha",children:"Installation (alpha)"}),"\n",(0,o.jsx)(n.h3,{id:"download",children:"Download"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://apache-doris-releases.oss-accelerate.aliyuncs.com/integrations/fluent-bit-doris-3.1.9",children:"https://apache-doris-releases.oss-accelerate.aliyuncs.com/integrations/fluent-bit-doris-3.1.9"})}),"\n",(0,o.jsx)(n.h3,{id:"compile-from-source-code",children:"Compile from Source Code"}),"\n",(0,o.jsxs)(n.p,{children:["Clone the dev branch of ",(0,o.jsx)(n.a,{href:"https://github.com/joker-star-l/fluent-bit",children:"https://github.com/joker-star-l/fluent-bit"})," and run the following commands in the build/ directory"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"cmake -DFLB_RELEASE=ON ..\nmake\n"})}),"\n",(0,o.jsx)(n.p,{children:"The build output is build/bin/fluent-bit."}),"\n",(0,o.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,o.jsx)(n.p,{children:"The configuration for the Fluent Bit Doris output plugin is as follows:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Configuration"}),(0,o.jsx)(n.th,{children:"Description"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"host"})}),(0,o.jsx)(n.td,{children:"Stream Load HTTP host"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"port"})}),(0,o.jsx)(n.td,{children:"Stream Load HTTP port"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"user"})}),(0,o.jsx)(n.td,{children:"Doris username, this user needs to have import permissions for the corresponding Doris database and table"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"password"})}),(0,o.jsx)(n.td,{children:"Doris user's password"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"database"})}),(0,o.jsx)(n.td,{children:"The Doris database name to write into"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"table"})}),(0,o.jsx)(n.td,{children:"The Doris table name to write into"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"label_prefix"})}),(0,o.jsxs)(n.td,{children:["Doris Stream Load Label prefix\uFF0Cthe final generated Label is ",(0,o.jsx)(n.em,{children:"{label_prefix}_{timestamp}_{uuid}"})," \uFF0Cthe default value is fluentbit. If set to false, no Label will be added"]})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"time_key"})}),(0,o.jsx)(n.td,{children:"The name of the timestamp column to add to the data. The default value is date. If set to false, the column will not be added"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"header"})}),(0,o.jsx)(n.td,{children:"Doris Stream Load headers parameter, can be set more than one"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"log_request"})}),(0,o.jsx)(n.td,{children:"Whether to output Doris Stream Load request and response metadata in logs for troubleshooting, default is true"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"log_progress_interval"})}),(0,o.jsx)(n.td,{children:"Time interval for outputting speed in logs, unit is seconds, default is 10, setting to 0 can disable this type of logging"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"retry_limit"})}),(0,o.jsx)(n.td,{children:"Doris Stream Load request failure retry number, default value is 1, if set to false will not limit the number of retries"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"workers"})}),(0,o.jsx)(n.td,{children:"Number of workers to perform Doris Stream Load, default value is 2"})]})]})]}),"\n",(0,o.jsx)(n.h2,{id:"usage-example",children:"Usage Example"}),"\n",(0,o.jsx)(n.h3,{id:"text-log-collection-example",children:"TEXT Log Collection Example"}),"\n",(0,o.jsx)(n.p,{children:"This example demonstrates TEXT log collection using Doris FE logs as an example."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"1. Data"})}),"\n",(0,o.jsx)(n.p,{children:"FE log files are typically located at the fe/log/fe.log file under the Doris installation directory. They are typical Java program logs, including fields such as timestamp, log level, thread name, code location, and log content. Not only do they contain normal logs, but also exception logs with stacktraces, which are multiline. Log collection and storage need to combine the main log and stacktrace into a single log entry."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"2024-07-08 21:18:01,432 INFO (Statistics Job Appender|61) [StatisticsJobAppender.runAfterCatalogReady():70] Stats table not available, skip\n2024-07-08 21:18:53,710 WARN (STATS_FETCH-0|208) [StmtExecutor.executeInternalQuery():3332] Failed to run internal SQL: OriginStatement{originStmt='SELECT * FROM __internal_schema.column_statistics WHERE part_id is NULL  ORDER BY update_time DESC LIMIT 500000', idx=0}\norg.apache.doris.common.UserException: errCode = 2, detailMessage = tablet 10031 has no queryable replicas. err: replica 10032's backend 10008 does not exist or not alive\n        at org.apache.doris.planner.OlapScanNode.addScanRangeLocations(OlapScanNode.java:931) ~[doris-fe.jar:1.2-SNAPSHOT]\n        at org.apache.doris.planner.OlapScanNode.computeTabletInfo(OlapScanNode.java:1197) ~[doris-fe.jar:1.2-SNAPSHOT]\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"2. Table Creation"})}),"\n",(0,o.jsx)(n.p,{children:"The table structure includes fields such as the log's creation time, collection time, hostname, log file path, log type, log level, thread name, code location, and log content."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'CREATE TABLE `doris_log` (\n  `log_time` datetime NULL COMMENT \'log content time\',\n  `collect_time` datetime NULL COMMENT \'log agent collect time\',\n  `host` text NULL COMMENT \'hostname or ip\',\n  `path` text NULL COMMENT \'log file path\',\n  `type` text NULL COMMENT \'log type\',\n  `level` text NULL COMMENT \'log level\',\n  `thread` text NULL COMMENT \'log thread\',\n  `position` text NULL COMMENT \'log code position\',\n  `message` text NULL COMMENT \'log message\',\n  INDEX idx_host (`host`) USING INVERTED COMMENT \'\',\n  INDEX idx_path (`path`) USING INVERTED COMMENT \'\',\n  INDEX idx_type (`type`) USING INVERTED COMMENT \'\',\n  INDEX idx_level (`level`) USING INVERTED COMMENT \'\',\n  INDEX idx_thread (`thread`) USING INVERTED COMMENT \'\',\n  INDEX idx_position (`position`) USING INVERTED COMMENT \'\',\n  INDEX idx_message (`message`) USING INVERTED PROPERTIES("parser" = "unicode", "support_phrase" = "true") COMMENT \'\'\n) ENGINE=OLAP\nDUPLICATE KEY(`log_time`)\nCOMMENT \'OLAP\'\nPARTITION BY RANGE(`log_time`) ()\nDISTRIBUTED BY RANDOM BUCKETS 10\nPROPERTIES (\n"replication_num" = "1",\n"dynamic_partition.enable" = "true",\n"dynamic_partition.time_unit" = "DAY",\n"dynamic_partition.start" = "-7",\n"dynamic_partition.end" = "1",\n"dynamic_partition.prefix" = "p",\n"dynamic_partition.buckets" = "10",\n"dynamic_partition.create_history_partition" = "true",\n"compaction_policy" = "time_series"\n);\n'})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"3. Configuration"})}),"\n",(0,o.jsx)(n.p,{children:"The configuration file of Fluent Bit log collection is as follows, doris_log.conf is used to define various parts of ETL components, and parsers.conf is used to define different log parsers."}),"\n",(0,o.jsx)(n.p,{children:"doris_log.conf:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"# config for Fluent Bit service\n[SERVICE]\n    log_level info\n    # parsers file\n    parsers_file parsers.conf\n\n# use input tail\n[INPUT]\n    name tail\n    path /path/to/your/log\n    # add log file name to the record, key is 'path'\n    path_key path\n    # set multiline parser\n    multiline.parser multiline_java \n\n# parse log\n[FILTER]\n    match *\n    name parser\n    key_name log\n    parser fe_log\n    reserve_data true\n\n# add host info\n[FILTER]\n    name sysinfo\n    match *\n    # add hostname to the record, key is 'host'\n    hostname_key host\n\n# output to doris\n[OUTPUT]\n    name doris\n    match *\n    host fehost\n    port feport\n    user your_username\n    password your_password\n    database your_db\n    table your_table\n    # add 'collect_time' to the record\n    time_key collect_time\n    # 'collect_time' is timestamp, change it to datatime\n    header columns collect_time=from_unixtime(collect_time)\n    log_request true\n    log_progress_interval 10\n"})}),"\n",(0,o.jsx)(n.p,{children:"parsers.conf:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'[MULTILINE_PARSER]\n    name          multiline_java\n    type          regex\n    flush_timeout 1000\n    # Regex rules for multiline parsing\n    # ---------------------------------\n    #\n    # configuration hints:\n    #\n    #  - first state always has the name: start_state\n    #  - every field in the rule must be inside double quotes\n    #\n    # rules   |   state name   | regex pattern | next state name\n    # --------|----------------|---------------|-----------------\n    rule         "start_state"   "/(^[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2})(.*)/"  "cont"\n    rule         "cont"          "/(^(?![0-9]{4}-[0-9]{2}-[0-9]{2}))(.*)/"     "cont"\n\n\n[PARSER]\n    name        fe_log\n    format      regex\n    # parse and add \'log_time\', \'level\', \'thread\', \'position\', \'message\' to the record\n    regex       ^(?<log_time>[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2},[0-9]{3}) (?<level>[^ ]+) \\((?<thread>[^\\)]+)\\) \\[(?<position>[^\\]]+)\\] (?<message>(\\n|.)*)\\n$\n'})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"4. Running Fluent Bit"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'fluent-bit -c doris_log.conf\n\n# log stream load response\n\n[2024/10/31 18:39:55] [ info] [output:doris:doris.1] 127.0.0.1:8040, HTTP status=200\n{\n    "TxnId": 32155,\n    "Label": "fluentbit_1730371195_91cca1aa-c15f-45d2-b503-fe7d2e839c2a",\n    "Comment": "",\n    "TwoPhaseCommit": "false",\n    "Status": "Success",\n    "Message": "OK",\n    "NumberTotalRows": 1,\n    "NumberLoadedRows": 1,\n    "NumberFilteredRows": 0,\n    "NumberUnselectedRows": 0,\n    "LoadBytes": 836,\n    "LoadTimeMs": 298,\n    "BeginTxnTimeMs": 0,\n    "StreamLoadPutTimeMs": 3,\n    "ReadDataTimeMs": 0,\n    "WriteDataTimeMs": 268,\n    "CommitAndPublishTimeMs": 25\n}\n\n# log speed info\n\n[2024/10/31 18:40:13] [ info] [output:doris:doris.1] total 0 MB 2 ROWS, total speed 0 MB/s 0 R/s, last 10 seconds speed 0 MB/s 0 R/s\n'})}),"\n",(0,o.jsx)(n.h3,{id:"json-log-collection-example",children:"JSON Log Collection Example"}),"\n",(0,o.jsx)(n.p,{children:"This example demonstrates JSON log collection using data from the GitHub events archive."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"1. Data"})}),"\n",(0,o.jsxs)(n.p,{children:["The GitHub events archive contains archived data of GitHub user actions, formatted as JSON. It can be downloaded from ",(0,o.jsx)(n.a,{href:"https://data.gharchive.org/",children:"here"}),", for example, the data for January 1, 2024, at 3 PM."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"wget https://data.gharchive.org/2024-01-01-15.json.gz\n"})}),"\n",(0,o.jsx)(n.p,{children:"Below is a sample of the data. Normally, each piece of data is on a single line, but for ease of display, it has been formatted here."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'{\n  "id": "37066529221",\n  "type": "PushEvent",\n  "actor": {\n    "id": 46139131,\n    "login": "Bard89",\n    "display_login": "Bard89",\n    "gravatar_id": "",\n    "url": "https://api.github.com/users/Bard89",\n    "avatar_url": "https://avatars.githubusercontent.com/u/46139131?"\n  },\n  "repo": {\n    "id": 780125623,\n    "name": "Bard89/talk-to-me",\n    "url": "https://api.github.com/repos/Bard89/talk-to-me"\n  },\n  "payload": {\n    "repository_id": 780125623,\n    "push_id": 17799451992,\n    "size": 1,\n    "distinct_size": 1,\n    "ref": "refs/heads/add_mvcs",\n    "head": "f03baa2de66f88f5f1754ce3fa30972667f87e81",\n    "before": "85e6544ede4ae3f132fe2f5f1ce0ce35a3169d21"\n  },\n  "public": true,\n  "created_at": "2024-04-01T23:00:00Z"\n}\n'})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"2. Table Creation"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'CREATE DATABASE log_db;\nUSE log_db;\n\n\nCREATE TABLE github_events\n(\n  `created_at` DATETIME,\n  `id` BIGINT,\n  `type` TEXT,\n  `public` BOOLEAN,\n  `actor` VARIANT,\n  `repo` VARIANT,\n  `payload` TEXT,\n  INDEX `idx_id` (`id`) USING INVERTED,\n  INDEX `idx_type` (`type`) USING INVERTED,\n  INDEX `idx_actor` (`actor`) USING INVERTED,\n  INDEX `idx_host` (`repo`) USING INVERTED,\n  INDEX `idx_payload` (`payload`) USING INVERTED PROPERTIES("parser" = "unicode", "support_phrase" = "true")\n)\nENGINE = OLAP\nDUPLICATE KEY(`created_at`)\nPARTITION BY RANGE(`created_at`) ()\nDISTRIBUTED BY RANDOM BUCKETS 10\nPROPERTIES (\n"replication_num" = "1",\n"compaction_policy" = "time_series",\n"enable_single_replica_compaction" = "true",\n"dynamic_partition.enable" = "true",\n"dynamic_partition.create_history_partition" = "true",\n"dynamic_partition.time_unit" = "DAY",\n"dynamic_partition.start" = "-30",\n"dynamic_partition.end" = "1",\n"dynamic_partition.prefix" = "p",\n"dynamic_partition.buckets" = "10",\n"dynamic_partition.replication_num" = "1"\n);\n'})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"3. Configuration"})}),"\n",(0,o.jsx)(n.p,{children:"In contrast to the previous TEXT log collection, this configuration does not use FILTER because no additional processing transformations are required."}),"\n",(0,o.jsx)(n.p,{children:"github_events.conf:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"[SERVICE]\n    log_level info\n    parsers_file github_parsers.conf\n\n[INPUT]\n    name tail\n    parser github\n    path /path/to/your/log\n\n[OUTPUT]\n    name doris\n    match *\n    host fehost\n    port feport\n    user your_username\n    password your_password\n    database your_db\n    table your_table\n    time_key false\n    log_request true\n    log_progress_interval 10\n"})}),"\n",(0,o.jsx)(n.p,{children:"github_parsers.conf:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"[PARSER]\n    name github\n    format json\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"4. Running Fluent Bit"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"fluent-bit -c github_events.conf\n"})})]})}function h(e={}){let{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},250065:function(e,n,t){t.d(n,{Z:function(){return a},a:function(){return s}});var i=t(667294);let o={},r=i.createContext(o);function s(e){let n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);