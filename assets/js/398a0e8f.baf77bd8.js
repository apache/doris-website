"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["581539"],{752807:function(e,n,t){t.r(n),t.d(n,{default:()=>h,frontMatter:()=>s,metadata:()=>r,assets:()=>l,toc:()=>d,contentTitle:()=>o});var r=JSON.parse('{"id":"ecosystem/datax","title":"DataX Doriswriter","description":"The DataX Doriswriter plugin supports synchronizing data from various data sources, such as MySQL, Oracle, and SQL Server,","source":"@site/versioned_docs/version-3.x/ecosystem/datax.md","sourceDirName":"ecosystem","slug":"/ecosystem/datax","permalink":"/docs/3.x/ecosystem/datax","draft":false,"unlisted":false,"tags":[],"version":"3.x","lastUpdatedAt":1770477659000,"frontMatter":{"title":"DataX Doriswriter","language":"en","description":"The DataX Doriswriter plugin supports synchronizing data from various data sources, such as MySQL, Oracle, and SQL Server,"},"sidebar":"docs","previous":{"title":"BladePipe","permalink":"/docs/3.x/ecosystem/cloudcanal"},"next":{"title":"DBT Doris Adapter","permalink":"/docs/3.x/ecosystem/dbt-doris-adapter"}}'),a=t("785893"),i=t("250065");let s={title:"DataX Doriswriter",language:"en",description:"The DataX Doriswriter plugin supports synchronizing data from various data sources, such as MySQL, Oracle, and SQL Server,"},o="DataX Doriswriter",l={},d=[{value:"Usage",id:"usage",level:2},{value:"Directly Download the DataX Installation Package",id:"directly-download-the-datax-installation-package",level:3},{value:"Compile the DorisWriter Plugin Manually",id:"compile-the-doriswriter-plugin-manually",level:3},{value:"Datax DorisWriter parameter introduction:",id:"datax-doriswriter-parameter-introduction",level:3},{value:"Example",id:"example",level:3},{value:"1. Stream reads the data and imports it to Doris",id:"1-stream-reads-the-data-and-imports-it-to-doris",level:4},{value:"2.Mysql reads the data and imports it to Doris",id:"2mysql-reads-the-data-and-imports-it-to-doris",level:4}];function c(e){let n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"datax-doriswriter",children:"DataX Doriswriter"})}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.a,{href:"https://github.com/alibaba/DataX",children:"DataX"})," Doriswriter plugin supports synchronizing data from various data sources, such as MySQL, Oracle, and SQL Server, into Doris using the Stream Load method."]}),"\n",(0,a.jsx)(n.admonition,{title:"Note",type:"info",children:(0,a.jsx)(n.p,{children:"This plugin needs to be used together with the DataX service.\nDataX supports multiple data sources. For more details, see here."})}),"\n",(0,a.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n",(0,a.jsx)(n.h3,{id:"directly-download-the-datax-installation-package",children:"Directly Download the DataX Installation Package"}),"\n",(0,a.jsxs)(n.p,{children:["DataX provides an official installation package that already includes DataX, which can be downloaded and used directly. For more details, refer to ",(0,a.jsx)(n.a,{href:"https://github.com/alibaba/DataX?tab=readme-ov-file#download-datax%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80",children:"here"}),"."]}),"\n",(0,a.jsx)(n.h3,{id:"compile-the-doriswriter-plugin-manually",children:"Compile the DorisWriter Plugin Manually"}),"\n",(0,a.jsxs)(n.p,{children:["Download the ",(0,a.jsx)(n.a,{href:"https://github.com/apache/doris/tree/master/extension/DataX",children:"source code"})," for the DorisWriter plugin."]}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Run ",(0,a.jsx)(n.code,{children:"init-env.sh"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Modify code of doriswriter in ",(0,a.jsx)(n.code,{children:"DataX/doriswriter"})," if you need."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Build doriswriter"}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsx)(n.p,{children:"Build doriswriter along:"}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:" `mvn clean install -pl plugin-rdbms-util,doriswriter -DskipTests`\n"})}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:["If you need to compile the entire DataX project, please refer to ",(0,a.jsx)(n.a,{href:"https://github.com/alibaba/DataX/blob/master/userGuid.md#quick-start",children:"here"})]}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsx)(n.p,{children:"Compilation error"}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:" If you encounter the following compilation errors:\n\n ```\n Could not find artifact com.alibaba.datax:datax-all:pom:0.0.1-SNAPSHOT ...\n ```\n\n You can try the following solutions:\n\n 1. Download [alibaba-datax-maven-m2-20210928.tar.gz](https://doris-thirdparty-repo.bj.bcebos.com/thirdparty/alibaba-datax-maven-m2-20210928.tar.gz)\n 2. After decompression, copy the resulting `alibaba/datax/` directory to `.m2/repository/com/alibaba/` corresponding to the maven used, and try to compile again. \n"})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"datax-doriswriter-parameter-introduction",children:"Datax DorisWriter parameter introduction:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"jdbcUrl"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Description: Doris's JDBC connection string, the user executes preSql or postSQL."}),"\n",(0,a.jsx)(n.li,{children:"Mandatory: Yes"}),"\n",(0,a.jsx)(n.li,{children:"Default: None"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"loadUrl"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:['Description: As a connection target for Stream Load. The format is "ip:port". Where IP is the FE node IP, port is the http_port of the FE node. You can fill in more than one, separated by commas in English: ',(0,a.jsx)(n.code,{children:","}),", doriswriter will visit in a polling manner."]}),"\n",(0,a.jsx)(n.li,{children:"Mandatory: Yes"}),"\n",(0,a.jsx)(n.li,{children:"Default: None"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"username"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Description: The username to access the Doris database"}),"\n",(0,a.jsx)(n.li,{children:"Mandatory: Yes"}),"\n",(0,a.jsx)(n.li,{children:"Default: None"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"password"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Description: Password to access Doris database"}),"\n",(0,a.jsx)(n.li,{children:"Mandatory: No"}),"\n",(0,a.jsx)(n.li,{children:"Default: empty"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"connection.selectedDatabase"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Description: The name of the Doris database that needs to be written."}),"\n",(0,a.jsx)(n.li,{children:"Mandatory: Yes"}),"\n",(0,a.jsx)(n.li,{children:"Default: None"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"connection. table"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Description: The name of the Doris table that needs to be written.\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Mandatory: Yes"}),"\n",(0,a.jsx)(n.li,{children:"Default: None"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"flushInterval"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Description: The time interval at which data is written in batches. If this time interval is set too small, it will cause Doris write blocking problem, error code -235, and if you set this time interval too small, ",(0,a.jsx)(n.code,{children:"maxBatchRows"})," and ",(0,a.jsx)(n.code,{children:"batchSize"})," parameters are set too large, then it may not be able to reach you The data size set by this will also be imported."]}),"\n",(0,a.jsx)(n.li,{children:"Mandatory: No"}),"\n",(0,a.jsx)(n.li,{children:"Default: 30000 (ms)"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"column"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:'Description: The fields that the destination table needs to write data into, these fields will be used as the field names of the generated Json data. Fields are separated by commas. For example: "column": ["id","name","age"].'}),"\n",(0,a.jsx)(n.li,{children:"Mandatory: Yes"}),"\n",(0,a.jsx)(n.li,{children:"Default: No"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"preSql"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Description: Before writing data to the destination table, the standard statement here will be executed first."}),"\n",(0,a.jsx)(n.li,{children:"Mandatory: No"}),"\n",(0,a.jsx)(n.li,{children:"Default: None"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"postSql"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Description: After writing data to the destination table, the standard statement here will be executed."}),"\n",(0,a.jsx)(n.li,{children:"Mandatory: No"}),"\n",(0,a.jsx)(n.li,{children:"Default: None"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"maxBatchRows"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Description: The maximum number of rows for each batch of imported data. Together with ",(0,a.jsx)(n.strong,{children:"batchSize"}),", it controls the number of imported record rows per batch. When each batch of data reaches one of the two thresholds, the data of this batch will start to be imported."]}),"\n",(0,a.jsx)(n.li,{children:"Mandatory: No"}),"\n",(0,a.jsx)(n.li,{children:"Default: 500000"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"batchSize"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Description: The maximum amount of data imported in each batch. Works with ",(0,a.jsx)(n.strong,{children:"maxBatchRows"})," to control the number of imports per batch. When each batch of data reaches one of the two thresholds, the data of this batch will start to be imported."]}),"\n",(0,a.jsx)(n.li,{children:"Mandatory: No"}),"\n",(0,a.jsx)(n.li,{children:"Default: 94371840"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"maxRetries"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Description: The number of retries after each batch of failed data imports."}),"\n",(0,a.jsx)(n.li,{children:"Mandatory: No"}),"\n",(0,a.jsx)(n.li,{children:"Default: 3"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"labelPrefix"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Description: The label prefix for each batch of imported tasks. The final label will have ",(0,a.jsx)(n.code,{children:"labelPrefix + UUID"})," to form a globally unique label to ensure that data will not be imported repeatedly"]}),"\n",(0,a.jsx)(n.li,{children:"Mandatory: No"}),"\n",(0,a.jsxs)(n.li,{children:["Default: ",(0,a.jsx)(n.code,{children:"datax_doris_writer_"})]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"loadProps"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Description: The request parameter of StreamLoad. For details, refer to the StreamLoad introduction page. ",(0,a.jsx)(n.a,{href:"https://doris.apache.org/docs/data-operate/import/stream-load-manual",children:"Stream load - Apache Doris"})]}),"\n",(0,a.jsx)(n.p,{children:"This includes the imported data format: format, etc. The imported data format defaults to csv, which supports JSON. For details, please refer to the type conversion section below, or refer to the official information of Stream load above."}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Mandatory: No"}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Default: None"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"example",children:"Example"}),"\n",(0,a.jsx)(n.h4,{id:"1-stream-reads-the-data-and-imports-it-to-doris",children:"1. Stream reads the data and imports it to Doris"}),"\n",(0,a.jsxs)(n.p,{children:["For instructions on using the doriswriter plug-in, please refer to ",(0,a.jsx)(n.a,{href:"https://github.com/apache/doris/blob/master/extension/DataX/doriswriter/doc/doriswriter.md",children:"here"}),"."]}),"\n",(0,a.jsx)(n.h4,{id:"2mysql-reads-the-data-and-imports-it-to-doris",children:"2.Mysql reads the data and imports it to Doris"}),"\n",(0,a.jsx)(n.p,{children:"1.Mysql table structure"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE `t_test`(\n `id`bigint(30) NOT NULL,\n `order_code` varchar(30) DEFAULT NULL COMMENT '',\n `line_code` varchar(30) DEFAULT NULL COMMENT '',\n `remark` varchar(30) DEFAULT NULL COMMENT '',\n `unit_no` varchar(30) DEFAULT NULL COMMENT '',\n `unit_name` varchar(30) DEFAULT NULL COMMENT '',\n `price` decimal(12,2) DEFAULT NULL COMMENT '',\n PRIMARY KEY(`id`) USING BTREE\n)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 ROW_FORMAT=DYNAMIC COMMENT='';\n"})}),"\n",(0,a.jsx)(n.p,{children:"2.Doris table structure"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE `ods_t_test` (\n `id`bigint(30) NOT NULL,\n `order_code` varchar(30) DEFAULT NULL COMMENT '',\n `line_code` varchar(30) DEFAULT NULL COMMENT '',\n `remark` varchar(30) DEFAULT NULL COMMENT '',\n `unit_no` varchar(30) DEFAULT NULL COMMENT '',\n `unit_name` varchar(30) DEFAULT NULL COMMENT '',\n `price` decimal(12,2) DEFAULT NULL COMMENT ''\n\uFF09ENGINE=OLAP\nUNIQUE KEY(id`, `order_code`)\nDISTRIBUTED BY HASH(`order_code`) BUCKETS 1\nPROPERTIES (\n\"replication_allocation\" = \"tag.location.default: 3\",\n\"in_memory\" = \"false\",\n\"storage_format\" = \"V2\"\n);\n"})}),"\n",(0,a.jsx)(n.p,{children:"3.Create datax script"}),"\n",(0,a.jsx)(n.p,{children:"my_import.json"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-json",children:'{\n    "job": {\n        "content": [\n            {\n                "reader": {\n                    "name": "mysqlreader",\n                    "parameter": {\n                        "column": ["id","order_code","line_code","remark","unit_no","unit_name","price"],\n                        "connection": [\n                            {\n                                "jdbcUrl": ["jdbc:mysql://localhost:3306/demo"],\n                                "table": ["employees_1"]\n                            }\n                        ],\n                        "username": "root",\n                        "password": "xxxxx",\n                        "where": ""\n                    }\n                },\n                "writer": {\n                    "name": "doriswriter",\n                    "parameter": {\n                        "loadUrl": ["127.0.0.1:8030"],\n                        "column": ["id","order_code","line_code","remark","unit_no","unit_name","price"],\n                        "username": "root",\n                        "password": "xxxxxx",\n                        "postSql": ["select count(1) from all_employees_info"],\n                        "preSql": [],\n                        "flushInterval":30000,\n                        "connection": [\n                          {\n                            "jdbcUrl": "jdbc:mysql://127.0.0.1:9030/demo",\n                            "selectedDatabase": "demo",\n                            "table": ["all_employees_info"]\n                          }\n                        ],\n                        "loadProps": {\n                            "format": "json",\n                            "strip_outer_array":"true",\n                            "line_delimiter": "\\\\x02"\n                        }\n                    }\n                }\n            }\n        ],\n        "setting": {\n            "speed": {\n                "channel": "1"\n            }\n        }\n    }\n}\n'})}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsx)(n.p,{children:"Remark:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-json",children:'"loadProps": {\n  "format": "json",\n  "strip_outer_array": "true",\n  "line_delimiter": "\\\\x02"\n}\n'})}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Here we use JSON format to import data"}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"line_delimiter"})," defaults to a newline character, which may conflict with the value in the data, we can use some special characters or invisible characters to avoid import errors"]}),"\n",(0,a.jsx)(n.li,{children:"strip_outer_array : Represents multiple rows of data in a batch of imported data. Doris will expand the array when parsing, and then parse each Object in it as a row of data in turn."}),"\n",(0,a.jsxs)(n.li,{children:["For more parameters of Stream load, please refer to ",(0,a.jsx)(n.a,{href:"../data-operate/import/import-way/stream-load-manual",children:"Stream load - Apache Doris"})]}),"\n",(0,a.jsx)(n.li,{children:"If it is in CSV format, we can use it like this"}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-json",children:'"loadProps": {\n   "format": "csv",\n   "column_separator": "\\\\x01",\n   "line_delimiter": "\\\\x02"\n}\n'})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"CSV format should pay special attention to row and column separators to avoid conflicts with special characters in the data. Hidden characters are recommended here. The default column separator is: \\t, row separator: \\n"})}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["4.Execute the datax task, refer to the specific ",(0,a.jsx)(n.a,{href:"https://github.com/alibaba/DataX/blob/master/userGuid.md",children:"datax official website"})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"python bin/datax.py my_import.json\n"})}),"\n",(0,a.jsx)(n.p,{children:"After execution, we can see the following information"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:'2022-11-16 14:28:54.012 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...\n2022-11-16 14:28:54.012 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .\n2022-11-16 14:28:54.013 [job-0] INFO  JobContainer - DataX Writer.Job [doriswriter] do prepare work .\n2022-11-16 14:28:54.020 [job-0] INFO  JobContainer - jobContainer starts to do split ...\n2022-11-16 14:28:54.020 [job-0] INFO  JobContainer - Job set Channel-Number to 1 channels.\n2022-11-16 14:28:54.023 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.\n2022-11-16 14:28:54.023 [job-0] INFO  JobContainer - DataX Writer.Job [doriswriter] splits to [1] tasks.\n2022-11-16 14:28:54.033 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...\n2022-11-16 14:28:54.036 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.\n2022-11-16 14:28:54.037 [job-0] INFO  JobContainer - Running by standalone Mode.\n2022-11-16 14:28:54.041 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.\n2022-11-16 14:28:54.043 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.\n2022-11-16 14:28:54.043 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.\n2022-11-16 14:28:54.049 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started\n2022-11-16 14:28:54.052 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select taskid,projectid,taskflowid,templateid,template_name,status_task from dwd_universal_tb_task \n] jdbcUrl:[jdbc:mysql://localhost:3306/demo?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].\nWed Nov 16 14:28:54 GMT+08:00 2022 WARN: Establishing SSL connection without server\'s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn\'t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to \'false\'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n2022-11-16 14:28:54.071 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select taskid,projectid,taskflowid,templateid,template_name,status_task from dwd_universal_tb_task \n] jdbcUrl:[jdbc:mysql://localhost:3306/demo?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].\n2022-11-16 14:28:54.104 [Thread-1] INFO  DorisStreamLoadObserver - Start to join batch data: rows[2] bytes[438] label[datax_doris_writer_c4e08cb9-c157-4689-932f-db34acc45b6f].\n2022-11-16 14:28:54.104 [Thread-1] INFO  DorisStreamLoadObserver - Executing stream load to: \'http://127.0.0.1:8030/api/demo/dwd_universal_tb_task/_stream_load\', size: \'441\'\n2022-11-16 14:28:54.224 [Thread-1] INFO  DorisStreamLoadObserver - StreamLoad response :{"Status":"Success","BeginTxnTimeMs":0,"Message":"OK","NumberUnselectedRows":0,"CommitAndPublishTimeMs":17,"Label":"datax_doris_writer_c4e08cb9-c157-4689-932f-db34acc45b6f","LoadBytes":441,"StreamLoadPutTimeMs":1,"NumberTotalRows":2,"WriteDataTimeMs":11,"TxnId":217056,"LoadTimeMs":31,"TwoPhaseCommit":"false","ReadDataTimeMs":0,"NumberLoadedRows":2,"NumberFilteredRows":0}\n2022-11-16 14:28:54.225 [Thread-1] INFO  DorisWriterManager - Async stream load finished: label[datax_doris_writer_c4e08cb9-c157-4689-932f-db34acc45b6f].\n2022-11-16 14:28:54.249 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[201]ms\n2022-11-16 14:28:54.250 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it\'s tasks.\n2022-11-16 14:29:04.048 [job-0] INFO  StandAloneJobContainerCommunicator - Total 2 records, 214 bytes | Speed 21B/s, 0 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%\n2022-11-16 14:29:04.049 [job-0] INFO  AbstractScheduler - Scheduler accomplished all tasks.\n2022-11-16 14:29:04.049 [job-0] INFO  JobContainer - DataX Writer.Job [doriswriter] do post work.\nWed Nov 16 14:29:04 GMT+08:00 2022 WARN: Establishing SSL connection without server\'s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn\'t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to \'false\'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n2022-11-16 14:29:04.187 [job-0] INFO  DorisWriter$Job - Start to execute preSqls:[select count(1) from dwd_universal_tb_task]. context info:jdbc:mysql://172.16.0.13:9030/demo.\n2022-11-16 14:29:04.204 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do post work.\n2022-11-16 14:29:04.204 [job-0] INFO  JobContainer - DataX jobId [0] completed successfully.\n2022-11-16 14:29:04.204 [job-0] INFO  HookInvoker - No hook invoked, because base dir not exists or is a file: /data/datax/hook\n2022-11-16 14:29:04.205 [job-0] INFO  JobContainer - \n         [total cpu info] => \n                averageCpu                     | maxDeltaCpu                    | minDeltaCpu                    \n                -1.00%                         | -1.00%                         | -1.00%\n                        \n\n         [total gc info] => \n                 NAME                 | totalGCCount       | maxDeltaGCCount    | minDeltaGCCount    | totalGCTime        | maxDeltaGCTime     | minDeltaGCTime     \n                 PS MarkSweep         | 1                  | 1                  | 1                  | 0.017s             | 0.017s             | 0.017s             \n                 PS Scavenge          | 1                  | 1                  | 1                  | 0.007s             | 0.007s             | 0.007s             \n\n2022-11-16 14:29:04.205 [job-0] INFO  JobContainer - PerfTrace not enable!\n2022-11-16 14:29:04.206 [job-0] INFO  StandAloneJobContainerCommunicator - Total 2 records, 214 bytes | Speed 21B/s, 0 records/s | Error 0 records, 0 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%\n2022-11-16 14:29:04.206 [job-0] INFO  JobContainer - \nTask Start Time                        : 2022-11-16 14:28:53\nTask End Time                          : 2022-11-16 14:29:04\nTotal Task Duration                    : 10s\nAverage Task Throughput                : 21B/s\nRecord Write Speed                     : 0rec/s\nTotal Records Read                     : 2\nTotal Read/Write Failures              : 0\n\n'})})]})}function h(e={}){let{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},250065:function(e,n,t){t.d(n,{Z:function(){return o},a:function(){return s}});var r=t(667294);let a={},i=r.createContext(a);function s(e){let n=r.useContext(i);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);