"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["774110"],{375140:function(e,n,t){t.r(n),t.d(n,{default:()=>h,frontMatter:()=>l,metadata:()=>s,assets:()=>o,toc:()=>d,contentTitle:()=>a});var s=JSON.parse('{"id":"install/deploy-manually/separating-storage-compute-deploy-manually","title":"Deploy Separating Storage Compute Cluster Manually","description":"After completing the prerequisite checks and planning, such as environment checks, cluster planning, and operating system checks, you can begin deploying the cluster. The deployment process consists of eight steps:","source":"@site/versioned_docs/version-3.x/install/deploy-manually/separating-storage-compute-deploy-manually.md","sourceDirName":"install/deploy-manually","slug":"/install/deploy-manually/separating-storage-compute-deploy-manually","permalink":"/docs/3.x/install/deploy-manually/separating-storage-compute-deploy-manually","draft":false,"unlisted":false,"tags":[],"version":"3.x","frontMatter":{"title":"Deploy Separating Storage Compute Cluster Manually","language":"en"},"sidebar":"docs","previous":{"title":"Deploy Integrated Storage Compute Cluster Manually","permalink":"/docs/3.x/install/deploy-manually/integrated-storage-compute-deploy-manually"},"next":{"title":"Deploy Doris Operator","permalink":"/docs/3.x/install/deploy-on-kubernetes/integrated-storage-compute/install-doris-operator"}}'),i=t("785893"),r=t("250065");let l={title:"Deploy Separating Storage Compute Cluster Manually",language:"en"},a=void 0,o={},d=[{value:"Step 1: Prepare FoundationDB",id:"step-1-prepare-foundationdb",level:2},{value:"Step 2: Install S3/HDFS Service (Optional)",id:"step-2-install-s3hdfs-service-optional",level:2},{value:"Step 3: Meta Service Deployment",id:"step-3-meta-service-deployment",level:2},{value:"Step 4: Independent Deployment of Data Recycling Function (Optional)",id:"step-4-independent-deployment-of-data-recycling-function-optional",level:2},{value:"Step 5: Start FE Master Node",id:"step-5-start-fe-master-node",level:2},{value:"Step 6: Register and Add FE Follower/Observer Nodes",id:"step-6-register-and-add-fe-followerobserver-nodes",level:2},{value:"Step 7: Add BE Nodes",id:"step-7-add-be-nodes",level:2},{value:"Step 8: Add Storage Vault",id:"step-8-add-storage-vault",level:2},{value:"Notes",id:"notes",level:2}];function c(e){let n={a:"a",admonition:"admonition",code:"code",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:"After completing the prerequisite checks and planning, such as environment checks, cluster planning, and operating system checks, you can begin deploying the cluster. The deployment process consists of eight steps:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Prepare the FoundationDB cluster: You can use an existing FoundationDB cluster or create a new one;"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Deploy S3 or HDFS service: You can use existing shared storage or create new shared storage;"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Deploy Meta Service: Deploy Meta Service for the Doris cluster;"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Deploy data reclamation process: Optionally, deploy a separate data reclamation process for the Doris cluster;"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Start the FE Master node: Start the first FE node as the Master FE node;"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Create the FE Master cluster: Add FE Follower/Observer nodes to form the FE cluster;"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Add BE nodes: Add and register BE nodes to the cluster;"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Add Storage Vault: Create one or more Storage Vaults using shared storage."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"step-1-prepare-foundationdb",children:"Step 1: Prepare FoundationDB"}),"\n",(0,i.jsxs)(n.p,{children:["This section provides step-by-step instructions for configuring, deploying, and starting the FoundationDB (FDB) service using the ",(0,i.jsx)(n.code,{children:"fdb_vars.sh"})," and ",(0,i.jsx)(n.code,{children:"fdb_ctl.sh"})," scripts. You can download the ",(0,i.jsx)(n.a,{href:"http://apache-doris-releases.oss-accelerate.aliyuncs.com/apache-doris-3.0.2-tools.tar.gz",children:"doris tools"})," and retrieve the ",(0,i.jsx)(n.code,{children:"fdb_vars.sh"})," and ",(0,i.jsx)(n.code,{children:"fdb_ctl.sh"})," from the ",(0,i.jsx)(n.code,{children:"fdb"})," directory."]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsx)(n.p,{children:"Doris currently relies on FDB version 7.1.x by default. If you have already installed FDB separately, please ensure it is version 7.1.x; otherwise, the Meta Service will fail to start."})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Machine Requirements"}),"\n",(0,i.jsx)(n.p,{children:"Typically, at least 3 machines with SSDs are needed to form a FoundationDB cluster with double data replicas, allowing for a single machine failure. If in a testing/development environment, a single machine can be used to set up FoundationDB."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Configure the ",(0,i.jsx)(n.code,{children:"fdb_vars.sh"})," script"]}),"\n",(0,i.jsx)(n.p,{children:"When configuring the fdb_vars.sh script, the following configurations must be specified:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Parameter"}),(0,i.jsx)(n.th,{children:"Description"}),(0,i.jsx)(n.th,{children:"Type"}),(0,i.jsx)(n.th,{children:"Example"}),(0,i.jsx)(n.th,{children:"Notes"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"DATA_DIRS"}),(0,i.jsx)(n.td,{children:"Specifies the FoundationDB data directory"}),(0,i.jsx)(n.td,{children:"A comma-separated list of absolute paths"}),(0,i.jsx)(n.td,{children:"/mnt/foundationdb/data1,/mnt/foundationdb/data2,/mnt/foundationdb/data3"}),(0,i.jsx)(n.td,{children:"- Ensure the directories are created before running the script - SSDs and separate directories are recommended in production"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"FDB_CLUSTER_IPS"}),(0,i.jsx)(n.td,{children:"Defines the cluster IPs"}),(0,i.jsx)(n.td,{children:"String (comma-separated IP addresses)"}),(0,i.jsx)(n.td,{children:"172.200.0.2,172.200.0.3,172.200.0.4"}),(0,i.jsx)(n.td,{children:"- At least 3 IP addresses are required in production clusters - The first IP will be used as the coordinator - For high availability, place machines in different racks"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"FDB_HOME"}),(0,i.jsx)(n.td,{children:"Defines the FoundationDB home directory"}),(0,i.jsx)(n.td,{children:"Absolute path"}),(0,i.jsx)(n.td,{children:"/fdbhome"}),(0,i.jsx)(n.td,{children:"- Default path is /fdbhome - Ensure this path is absolute"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"FDB_CLUSTER_ID"}),(0,i.jsx)(n.td,{children:"Defines the cluster ID"}),(0,i.jsx)(n.td,{children:"String"}),(0,i.jsx)(n.td,{children:"SAQESzbh"}),(0,i.jsxs)(n.td,{children:["- The ID must be unique for each cluster - Use ",(0,i.jsx)(n.code,{children:"mktemp -u XXXXXXXX"})," to generate it"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"FDB_CLUSTER_DESC"}),(0,i.jsx)(n.td,{children:"Defines the description of the FDB cluster"}),(0,i.jsx)(n.td,{children:"String"}),(0,i.jsx)(n.td,{children:"dorisfdb"}),(0,i.jsx)(n.td,{children:"- It is recommended to change this to something meaningful for the deployment"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"You can also specify the following optional custom configurations:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Parameter"}),(0,i.jsx)(n.th,{children:"Description"}),(0,i.jsx)(n.th,{children:"Type"}),(0,i.jsx)(n.th,{children:"Example"}),(0,i.jsx)(n.th,{children:"Notes"})]})}),(0,i.jsx)(n.tbody,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"MEMORY_LIMIT_GB"}),(0,i.jsx)(n.td,{children:"Defines the FDB memory limit"}),(0,i.jsx)(n.td,{children:"Integer"}),(0,i.jsx)(n.td,{children:"32"}),(0,i.jsx)(n.td,{children:"- Set the memory limit based on the available system memory"})]})})]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Deploy FDB Cluster"}),"\n",(0,i.jsxs)(n.p,{children:["After configuring the environment using ",(0,i.jsx)(n.code,{children:"fdb_vars.sh"}),", you can deploy the FDB cluster on each node using the ",(0,i.jsx)(n.code,{children:"fdb_ctl.sh"})," script."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"./fdb_ctl.sh deploy\n"})}),"\n",(0,i.jsx)(n.p,{children:"This command initiates the deployment process for the FDB cluster."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Start FDB Service"}),"\n",(0,i.jsxs)(n.p,{children:["After the FDB cluster is deployed, you can use the ",(0,i.jsx)(n.code,{children:"fdb_ctl.sh"})," script to start the FDB service."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"./fdb_ctl.sh start\n"})}),"\n",(0,i.jsx)(n.p,{children:"This command starts the FDB service, bringing the cluster online and obtaining the FDB cluster connection string, which can be used for configuring MetaService."}),"\n",(0,i.jsx)(n.admonition,{title:"Note",type:"caution",children:(0,i.jsx)(n.p,{children:"The 'clean' command in the fdb_ctl.sh script will clear all FDB metadata, which may result in data loss. It is strictly prohibited to use this command in production environments!"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"step-2-install-s3hdfs-service-optional",children:"Step 2: Install S3/HDFS Service (Optional)"}),"\n",(0,i.jsx)(n.p,{children:"Apache Doris in a storage-compute separation mode stores data on S3 or HDFS services. If you already have these services set up, you can directly use them.\nIf not, this document provides a simple deployment guide for MinIO:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Visit the ",(0,i.jsx)(n.a,{href:"https://min.io/download?license=agpl&platform=linux",children:"MinIO download page"})," to select the appropriate version and operating system, and download the corresponding Server and Client binary or installation packages."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Start MinIO Server"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"export MINIO_REGION_NAME=us-east-1\nexport MINIO_ROOT_USER=minio # In older versions, this configuration was MINIO_ACCESS_KEY=minio\nexport MINIO_ROOT_PASSWORD=minioadmin # In older versions, this configuration was MINIO_SECRET_KEY=minioadmin\nnohup ./minio server /mnt/data 2>&1 &\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Configure MinIO Client"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# If you installed the client using the installation package, the client name is mcli. If you downloaded the client binary package, it is named mc  \n./mc config host add myminio http://127.0.0.1:9000 minio minioadmin\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Create a Bucket"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"./mc mb myminio/doris\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Verify it's working correctly"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Upload a file  \n./mc mv test_file myminio/doris\n# List the file  \n./mc ls myminio/doris\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"step-3-meta-service-deployment",children:"Step 3: Meta Service Deployment"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Configuration"}),"\n",(0,i.jsxs)(n.p,{children:["In the ",(0,i.jsx)(n.code,{children:"./conf/doris_cloud.conf"})," file, the following two parameters need to be modified:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"brpc_listen_port"}),"\uFF1AThe listening port for Meta Service, default is 5000."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"fdb_cluster"}),"\uFF1AThe connection information for the FoundationDB cluster, which can be obtained during the FoundationDB deployment. (If you are using the ",(0,i.jsx)(n.code,{children:"fdb_ctl.s"}),"h provided by Doris, this value can be found in the ",(0,i.jsx)(n.code,{children:"$FDB_HOME/conf/fdb.cluster"})," file)."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Example configuration:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"brpc_listen_port = 5000\nfdb_cluster = xxx:yyy@127.0.0.1:4500\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Note: The value of ",(0,i.jsx)(n.code,{children:"fdb_cluster"})," should match the contents of the ",(0,i.jsx)(n.code,{children:"/etc/foundationdb/fdb.cluster"})," file on the FoundationDB deployment machine (if using the fdb_ctl.sh provided by Doris, this value can be obtained from the ",(0,i.jsx)(n.code,{children:"$FDB_HOME/conf/fdb.cluster"})," file)."]}),"\n",(0,i.jsxs)(n.p,{children:["Example, the last line of the file is the value to be filled in the ",(0,i.jsx)(n.code,{children:"fdb_cluster"})," field in the doris_cloud.conf file:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"cat /etc/foundationdb/fdb.cluster\n\nDO NOT EDIT!\nThis file is auto-generated, it is not to be edited by hand.\ncloud_ssb:A83c8Y1S3ZbqHLL4P4HHNTTw0A83CuHj@127.0.0.1:4500\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Start and Stop"}),"\n",(0,i.jsxs)(n.p,{children:["Before starting, ensure that the ",(0,i.jsx)(n.code,{children:"JAVA_HOME"})," environment variable is correctly set to point to OpenJDK 17, and enter the ",(0,i.jsx)(n.code,{children:"ms"})," directory."]}),"\n",(0,i.jsx)(n.p,{children:"The start command is as follows:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"export JAVA_HOME=${path_to_jdk_17}\nbin/start.sh --daemon\n"})}),"\n",(0,i.jsx)(n.p,{children:'A return value of 0 from the start script indicates a successful start; otherwise, the start has failed. If started successfully, the last line of the standard output will display "doris_cloud start successfully".'}),"\n",(0,i.jsx)(n.p,{children:"The stop command is as follows:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"bin/stop.sh\n"})}),"\n",(0,i.jsx)(n.p,{children:"In a production environment, ensure that at least 3 Meta Service nodes are available."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"step-4-independent-deployment-of-data-recycling-function-optional",children:"Step 4: Independent Deployment of Data Recycling Function (Optional)"}),"\n",(0,i.jsx)(n.admonition,{title:"Information",type:"info",children:(0,i.jsx)(n.p,{children:"Meta Service itself has metadata management and recycling functions, and these two functions can be deployed independently. If you want to deploy them independently, refer to this section."})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Create a new working directory (e.g., ",(0,i.jsx)(n.code,{children:"recycler"}),") and copy the contents of the ",(0,i.jsx)(n.code,{children:"ms"})," directory to the new directory:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"cp -r ms recycler\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Modify the BRPC listen port ",(0,i.jsx)(n.code,{children:"brpc_listen_port"})," and ",(0,i.jsx)(n.code,{children:"fdb_cluster"})," values in the configuration file of the new directory."]}),"\n",(0,i.jsx)(n.p,{children:"To start the data recycling function:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"export JAVA_HOME=${path_to_jdk_17}\nbin/start.sh --recycler --daemon\n"})}),"\n",(0,i.jsx)(n.p,{children:"To start only the metadata operation function:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-shell",children:"export JAVA_HOME=${path_to_jdk_17}\nbin/start.sh --meta-service --daemon\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"step-5-start-fe-master-node",children:"Step 5: Start FE Master Node"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Configure the ",(0,i.jsx)(n.code,{children:"fe.conf"})," File"]}),"\n",(0,i.jsxs)(n.p,{children:["In the ",(0,i.jsx)(n.code,{children:"fe.conf"})," file, the following key parameters need to be configured:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"deploy_mode"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Description: Specifies the Doris startup mode"}),"\n",(0,i.jsxs)(n.li,{children:["Format: ",(0,i.jsx)(n.code,{children:"cloud"})," for storage-compute separation mode, other modes for storage-compute integration"]}),"\n",(0,i.jsxs)(n.li,{children:["Example: ",(0,i.jsx)(n.code,{children:"cloud"})]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"cluster_id"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Description: A unique identifier for the cluster in the storage-compute separation architecture. Different clusters must have different ",(0,i.jsx)(n.code,{children:"cluster_id"}),"."]}),"\n",(0,i.jsx)(n.li,{children:"Format: Integer type"}),"\n",(0,i.jsxs)(n.li,{children:["Example: You can use the following shell script ",(0,i.jsx)(n.code,{children:"echo $(($((RANDOM << 15)) | $RANDOM))"})," to generate a random ID."]}),"\n",(0,i.jsxs)(n.li,{children:["Note: Different clusters must have different ",(0,i.jsx)(n.code,{children:"cluster_id"}),"."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"meta_service_endpoint"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Description: The address and port of the Meta Service"}),"\n",(0,i.jsxs)(n.li,{children:["Format: ",(0,i.jsx)(n.code,{children:"IP address:port"})]}),"\n",(0,i.jsxs)(n.li,{children:["Example: ",(0,i.jsx)(n.code,{children:"127.0.0.1:5000"}),", multiple Meta Services can be configured by separating them with commas."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Start FE Master Node"}),"\n",(0,i.jsx)(n.p,{children:"Example start command:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"bin/start_fe.sh --daemon\n"})}),"\n",(0,i.jsxs)(n.p,{children:["The first FE process initializes the cluster and works as a FOLLOWER role. Use the MySQL client to connect to FE and use ",(0,i.jsx)(n.code,{children:"show frontends"})," to confirm that the FE you just started is the master."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"step-6-register-and-add-fe-followerobserver-nodes",children:"Step 6: Register and Add FE Follower/Observer Nodes"}),"\n",(0,i.jsx)(n.p,{children:"Other nodes should also modify their configuration files and start following the same steps. Connect to the Master role FE using the MySQL client and add additional FE nodes with the following SQL command:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:'ALTER SYSTEM ADD FOLLOWER "host:port";\n'})}),"\n",(0,i.jsxs)(n.p,{children:["Replace ",(0,i.jsx)(n.code,{children:"host:port"})," with the actual address of the FE node and edit the log port. For more information, see ",(0,i.jsx)(n.a,{href:"../../sql-manual/sql-statements/cluster-management/instance-management/ADD-FOLLOWER",children:"ADD FOLLOWER"})," and ",(0,i.jsx)(n.a,{href:"../../sql-manual/sql-statements/cluster-management/instance-management/ADD-OBSERVER",children:"ADD OBSERVER"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"In a production environment, make sure the total number of FE nodes in the FOLLOWER role, including the first FE, remains odd. Typically, three FOLLOWER nodes are sufficient. The number of FE nodes in the OBSERVER role can be arbitrary."}),"\n",(0,i.jsx)(n.h2,{id:"step-7-add-be-nodes",children:"Step 7: Add BE Nodes"}),"\n",(0,i.jsx)(n.p,{children:"To add Backend nodes to the cluster, perform the following steps for each Backend:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Configure ",(0,i.jsx)(n.code,{children:"be.conf"})]}),"\n",(0,i.jsxs)(n.p,{children:["In the ",(0,i.jsx)(n.code,{children:"be.conf"})," file, you need to configure the following key parameters:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["deploy_mode\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Description: Specifies the startup mode of doris"}),"\n",(0,i.jsx)(n.li,{children:"Format: cloud indicates separation of storage and computing mode, others indicate integration of storage and computing mode"}),"\n",(0,i.jsx)(n.li,{children:"Example: cloud"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["file_cache_path\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Description: Disk path and other parameters used for file caching, represented in array form, each disk is an item. path specifies the disk path, total_size limits the cache size; -1 or 0 will use the entire disk space."}),"\n",(0,i.jsx)(n.li,{children:'Format: [{"path":"/path/to/file_cache", "total_size":21474836480}, {"path":"/path/to/file_cache2", "total_size":21474836480}]'}),"\n",(0,i.jsx)(n.li,{children:'Example: [{"path":"/path/to/file_cache", "total_size":21474836480}, {"path":"/path/to/file_cache2", "total_size":21474836480}] - Default: [{"path":"${DORIS_HOME}/file_cache"}]'}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Start the BE process"}),"\n",(0,i.jsx)(n.p,{children:"Use the following command to start the Backend:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"bin/start_be.sh --daemon\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Add BE to the cluster:"}),"\n",(0,i.jsx)(n.p,{children:"Connect to any Frontend using MySQL client and execute:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:'ALTER SYSTEM ADD BACKEND "<ip>:<heartbeat_service_port>" [PROPERTIES properties];\n'})}),"\n",(0,i.jsxs)(n.p,{children:["Replace ",(0,i.jsx)(n.code,{children:"<ip>"})," with the IP address of the new Backend, and ",(0,i.jsx)(n.code,{children:"<heartbeat_service_port>"})," with its configured heartbeat service port (default is 9050)."]}),"\n",(0,i.jsx)(n.p,{children:"You can use PROPERTIES to specify the compute group where the BE is located."}),"\n",(0,i.jsxs)(n.p,{children:["For more detailed usage, refer to ",(0,i.jsx)(n.a,{href:"../../sql-manual/sql-statements/cluster-management/instance-management/ADD-BACKEND",children:"ADD BACKEND"})," and ",(0,i.jsx)(n.a,{href:"../../sql-manual/sql-statements/cluster-management/instance-management/DROP-BACKEND",children:"REMOVE BACKEND"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Verify BE status"}),"\n",(0,i.jsxs)(n.p,{children:["Check the Backend log files (",(0,i.jsx)(n.code,{children:"be.log"}),") to ensure it has successfully started and joined the cluster."]}),"\n",(0,i.jsx)(n.p,{children:"You can also check the Backend status using the following SQL command:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"SHOW BACKENDS;\n"})}),"\n",(0,i.jsx)(n.p,{children:"This will display all the Backend nodes in the cluster and their current status."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"step-8-add-storage-vault",children:"Step 8: Add Storage Vault"}),"\n",(0,i.jsx)(n.p,{children:"Storage Vault is an important component in Doris' separation of storage and computing architecture. It represents the shared storage layer where data is stored. You can create one or more Storage Vaults using HDFS or S3-compatible object storage. One Storage Vault can be set as the default Storage Vault, and system tables and tables that do not specify a Storage Vault will be stored in this default Storage Vault. The default Storage Vault cannot be deleted. Below are the steps to create a Storage Vault for your Doris cluster:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Create HDFS Storage Vault"}),"\n",(0,i.jsx)(n.p,{children:"To create a Storage Vault using SQL, connect to your Doris cluster using the MySQL client:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:'CREATE STORAGE VAULT IF_NOT_EXISTS hdfs_vault\n    PROPERTIES (\n    "type"="hdfs",\n    "fs.defaultFS"="hdfs://127.0.0.1:8020"\n);\n'})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Create S3 Storage Vault"}),"\n",(0,i.jsx)(n.p,{children:"To create a Storage Vault using S3-compatible object storage, follow these steps:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Connect to your Doris cluster using the MySQL client."}),"\n",(0,i.jsx)(n.li,{children:"Execute the following SQL command to create the S3 Storage Vault:"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:'CREATE STORAGE VAULT IF_NOT_EXISTS s3_vault\n    PROPERTIES (\n    "type"="S3",\n    "s3.endpoint"="s3.us-east-1.amazonaws.com",\n    "s3.access_key" = "ak",\n    "s3.secret_key" = "sk",\n    "s3.region" = "us-east-1",\n    "s3.root.path" = "ssb_sf1_p2_s3",\n    "s3.bucket" = "doris-build-1308700295",\n    "provider" = "S3"\n);\n'})}),"\n",(0,i.jsxs)(n.p,{children:["To create a Storage Vault on other object storage, please refer to ",(0,i.jsx)(n.a,{href:"../../sql-manual/sql-statements/cluster-management/storage-management/CREATE-STORAGE-VAULT",children:"Create Storage Vault"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Set Default Storage Vault"}),"\n",(0,i.jsx)(n.p,{children:"Use the following SQL statement to set a default Storage Vault."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"SET <storage_vault_name> AS DEFAULT STORAGE VAULT\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Only the Meta Service process with metadata operation functionality should be configured as the ",(0,i.jsx)(n.code,{children:"meta_service_endpoint"})," for FE and BE."]}),"\n",(0,i.jsxs)(n.li,{children:["The data recycling function process should not be configured as the ",(0,i.jsx)(n.code,{children:"meta_service_endpoint"}),"."]}),"\n"]})]})}function h(e={}){let{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},250065:function(e,n,t){t.d(n,{Z:function(){return a},a:function(){return l}});var s=t(667294);let i={},r=s.createContext(i);function l(e){let n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);