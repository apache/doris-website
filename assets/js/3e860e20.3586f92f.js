"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["257983"],{100403:function(e,n,r){r.r(n),r.d(n,{default:()=>o,frontMatter:()=>d,metadata:()=>i,assets:()=>l,toc:()=>c,contentTitle:()=>a});var i=JSON.parse('{"id":"ai/vector-search/hnsw","title":"HNSW","description":"HNSW (Malkov & Yashunin, 2016) has become the de facto standard for high\u2011performance online vector search thanks to its ability to achieve high ","source":"@site/docs/ai/vector-search/hnsw.md","sourceDirName":"ai/vector-search","slug":"/ai/vector-search/hnsw","permalink":"/docs/dev/ai/vector-search/hnsw","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1770477659000,"frontMatter":{"title":"HNSW","language":"en","description":"HNSW (Malkov & Yashunin, 2016) has become the de facto standard for high\u2011performance online vector search thanks to its ability to achieve high "},"sidebar":"docs","previous":{"title":"Overview","permalink":"/docs/dev/ai/vector-search/overview"},"next":{"title":"IVF","permalink":"/docs/dev/ai/vector-search/ivf"}}'),s=r("785893"),t=r("250065");let d={title:"HNSW",language:"en",description:"HNSW (Malkov & Yashunin, 2016) has become the de facto standard for high\u2011performance online vector search thanks to its ability to achieve high "},a="HNSW and How to use it in Apaceh Doris",l={},c=[{value:"Before HNSW",id:"before-hnsw",level:2},{value:"Proximate Graph",id:"proximate-graph",level:3},{value:"Navigable Small World",id:"navigable-small-world",level:3},{value:"Hierarchical Navigable Small World",id:"hierarchical-navigable-small-world",level:2},{value:"HNSW in Apache Doris",id:"hnsw-in-apache-doris",level:2},{value:"Index Construction",id:"index-construction",level:3},{value:"CREATE/BUILD INDEX",id:"createbuild-index",level:4},{value:"DROP INDEX",id:"drop-index",level:4},{value:"Querying",id:"querying",level:3},{value:"Recall Optimization",id:"recall-optimization",level:3},{value:"Index Hyperparameters",id:"index-hyperparameters",level:4},{value:"Number of Rows Covered per Index",id:"number-of-rows-covered-per-index",level:4},{value:"Impact of Compaction on Recall",id:"impact-of-compaction-on-recall",level:4},{value:"Query Performance",id:"query-performance",level:3},{value:"Cold Loading of Index Files",id:"cold-loading-of-index-files",level:4},{value:"Memory Footprint vs. Performance",id:"memory-footprint-vs-performance",level:4},{value:"Benchmark",id:"benchmark",level:3},{value:"Performance768D1M",id:"performance768d1m",level:4}];function h(e){let n={a:"a",blockquote:"blockquote",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"hnsw-and-how-to-use-it-in-apaceh-doris",children:"HNSW and How to use it in Apaceh Doris"})}),"\n",(0,s.jsx)(n.p,{children:"HNSW (Malkov & Yashunin, 2016) has become the de facto standard for high\u2011performance online vector search thanks to its ability to achieve high recall and low latency with relatively modest resource consumption. Since Apache Doris 4.x, an ANN index based on HNSW has been supported. This document walks through the HNSW algorithm, key parameters, and engineering practices, and explains how to build and tune HNSW\u2011based ANN indexes in production Doris clusters."}),"\n",(0,s.jsx)(n.h2,{id:"before-hnsw",children:"Before HNSW"}),"\n",(0,s.jsxs)(n.p,{children:["The HNSW (Hierarchical Navigable Small World) algorithm was proposed in the paper ",(0,s.jsx)(n.a,{href:"https://arxiv.org/abs/1603.09320",children:"Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs"}),". Before HNSW, many algorithms had already been proposed for approximate k\u2011NN search, but each came with its own limitations."]}),"\n",(0,s.jsx)(n.h3,{id:"proximate-graph",children:"Proximate Graph"}),"\n",(0,s.jsx)(n.p,{children:"The basic idea of this family of algorithms is to start from an entry point in the graph (which can be a random vertex or a vertex chosen by some heuristic), and then iteratively traverse the graph. At each iteration, the algorithm computes the distance between the query vector and all neighbors of the current node, picks the closest neighbor as the new base node for the next iteration, and continuously maintains the current best candidate set. When certain stopping conditions are met\u2014such as no closer node being found in the last iteration\u2014the algorithm terminates and the top K nearest nodes in the candidate set are returned as the final result."}),"\n",(0,s.jsx)(n.p,{children:"These proximity\u2011graph algorithms can be seen as approximations of a Delaunay graph, because a Delaunay graph has an important property: a greedy search always finds the nearest neighbor."}),"\n",(0,s.jsx)(n.p,{children:"However, this family of algorithms has two main issues:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"As the dataset grows, the number of iterations in the routing phase increases roughly following a power\u2011law."}),"\n",(0,s.jsx)(n.li,{children:"It is difficult to build a high\u2011quality proximity graph; local clusters and poor global connectivity are very common."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"low_quality_pgraph",src:r(554149).Z+"",width:"1626",height:"1058"})}),"\n",(0,s.jsx)(n.p,{children:"The figure above intuitively shows the shape of a problematic proximity graph. Darker points represent nodes with poorer connectivity; some nodes barely have any neighbors at all, which makes them very hard to reach during search."}),"\n",(0,s.jsx)(n.h3,{id:"navigable-small-world",children:"Navigable Small World"}),"\n",(0,s.jsx)(n.p,{children:"To address the above issues, there are two main ideas:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Hybrid approaches: perform a coarse\u2011grained search first to find a better entry point, then run a greedy search on the proximity graph."}),"\n",(0,s.jsx)(n.li,{children:"Use a navigable small\u2011world structure that maintains good connectivity while limiting each node\u2019s maximum degree to control search complexity."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"NSW (Navigable Small World) adopts the second idea."}),"\n",(0,s.jsxs)(n.p,{children:["The NSW model was first proposed in ",(0,s.jsx)(n.a,{href:"https://www.nature.com/articles/35022643",children:"J. Kleinberg"})," as part of a social experiment to study how people are connected in society. You might have heard of the ",(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Small-world_experiment",children:"small\u2011world experiment / six degrees of separation"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"For k\u2011NN graph algorithms, any small\u2011world network that achieves logarithmic or polylogarithmic search complexity is often called a Navigable Small World Network. There are many concrete implementations, which we will not detail here."}),"\n",(0,s.jsx)(n.p,{children:"On some datasets, NSW represented state\u2011of\u2011the\u2011art search performance at the time. However, because NSW does not have strictly logarithmic complexity, its performance can be suboptimal in certain benchmarks, especially on low\u2011dimensional vector spaces."}),"\n",(0,s.jsx)(n.h2,{id:"hierarchical-navigable-small-world",children:"Hierarchical Navigable Small World"}),"\n",(0,s.jsx)(n.p,{children:"The NSW search process can be viewed as consisting of two phases: zoom\u2011out and zoom\u2011in."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"zoom-out"}),": Start from a randomly chosen low\u2011degree vertex and search while preferring nodes with higher degrees, until the average distance to neighbors exceeds the distance from the current node to the query."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"zoom-in"}),": Once a sufficiently \u201Chigh\u201D node under those conditions is found, perform greedy search to obtain the final Top\u2011N neighbors."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The reason NSW achieves polylogarithmic complexity is that the total number of distance evaluations is roughly proportional to the product of the number of jumps made during search and the average degree of the visited nodes. Both the number of jumps and the average degree grow approximately logarithmically with the data size, which leads to an overall polylogarithmic complexity."}),"\n",(0,s.jsx)(n.p,{children:"HNSW reduces the query time complexity to logarithmic by accelerating the zoom\u2011out phase."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"hnsw",src:r(367681).Z+"",width:"642",height:"628"})}),"\n",(0,s.jsx)(n.p,{children:"More concretely, the \u201Chierarchical\u201D structure in HNSW is obtained by splitting the NSW graph into multiple layers based on the characteristic radius (typical edge length) of nodes."}),"\n",(0,s.jsx)(n.p,{children:"During search, HNSW chooses the top\u2011layer node as the entry point and performs greedy search layer by layer. Once the nearest node is found at the current layer, the search descends to the next layer and repeats the process until reaching the bottom layer. The maximum degree of nodes in each layer is capped, which helps keep the overall time complexity logarithmic."}),"\n",(0,s.jsxs)(n.p,{children:["To build this layered structure, HNSW assigns each node a level ",(0,s.jsx)(n.code,{children:"l"})," according to a geometric distribution, ensuring that the structure does not grow too tall. HNSW also does not require shuffling the data before indexing (while NSW does, otherwise the graph quality suffers) because the random level assignment itself provides sufficient randomness. This design enables efficient incremental updates in HNSW."]}),"\n",(0,s.jsx)(n.h2,{id:"hnsw-in-apache-doris",children:"HNSW in Apache Doris"}),"\n",(0,s.jsx)(n.p,{children:"Apache Doris supports building HNSW\u2011based ANN indexes starting from version 4.0."}),"\n",(0,s.jsx)(n.h3,{id:"index-construction",children:"Index Construction"}),"\n",(0,s.jsxs)(n.p,{children:["The index type used here is ANN. There are two ways to create an ANN index: you can define it when creating the table, or you can use the ",(0,s.jsx)(n.code,{children:"CREATE/BUILD INDEX"})," syntax. The two approaches differ in how and when the index is built, and therefore fit different scenarios."]}),"\n",(0,s.jsx)(n.p,{children:"Approach 1: define an ANN index on a vector column when creating the table. As data is loaded, an ANN index is built for each segment as it is created. The advantage is that once data loading completes, the index is already built and queries can immediately use it for acceleration. The downside is that synchronous index building slows down data ingestion and may cause extra index rebuilds during compaction, leading to some waste of resources."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE sift_1M (\n  id int NOT NULL,\n  embedding array<float>  NOT NULL  COMMENT "",\n  INDEX ann_index (embedding) USING ANN PROPERTIES(\n      "index_type"="hnsw",\n      "metric_type"="l2_distance",\n      "dim"="128"\n  )\n) ENGINE=OLAP\nDUPLICATE KEY(id) COMMENT "OLAP"\nDISTRIBUTED BY HASH(id) BUCKETS 1\nPROPERTIES (\n  "replication_num" = "1"\n);\n\nINSERT INTO sift_1M\nSELECT *\nFROM S3(\n  "uri" = "https://selectdb-customers-tools-bj.oss-cn-beijing.aliyuncs.com/sift_database.tsv",\n  "format" = "csv");\n'})}),"\n",(0,s.jsx)(n.h4,{id:"createbuild-index",children:"CREATE/BUILD INDEX"}),"\n",(0,s.jsxs)(n.p,{children:["Approach 2: ",(0,s.jsx)(n.code,{children:"CREATE/BUILD INDEX"}),"."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE sift_1M (\n  id int NOT NULL,\n  embedding array<float>  NOT NULL  COMMENT ""\n) ENGINE=OLAP\nDUPLICATE KEY(id) COMMENT "OLAP"\nDISTRIBUTED BY HASH(id) BUCKETS 1\nPROPERTIES (\n  "replication_num" = "1"\n);\n\nINSERT INTO sift_1M\nSELECT *\nFROM S3(\n  "uri" = "https://selectdb-customers-tools-bj.oss-cn-beijing.aliyuncs.com/sift_database.tsv",\n  "format" = "csv");\n'})}),"\n",(0,s.jsxs)(n.p,{children:["After data is loaded, you can run ",(0,s.jsx)(n.code,{children:"CREATE INDEX"}),". At this point the index is defined on the table, but no index is yet built for the existing data."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:'CREATE INDEX idx_test_ann ON sift_1M (`embedding`) USING ANN PROPERTIES (\n  "index_type"="hnsw",\n  "metric_type"="l2_distance",\n  "dim"="128"\n);\n\nSHOW DATA ALL FROM sift_1M\n\n+-----------+-----------+--------------+----------+----------------+---------------+----------------+-----------------+----------------+-----------------+\n| TableName | IndexName | ReplicaCount | RowCount | LocalTotalSize | LocalDataSize | LocalIndexSize | RemoteTotalSize | RemoteDataSize | RemoteIndexSize |\n+-----------+-----------+--------------+----------+----------------+---------------+----------------+-----------------+----------------+-----------------+\n| sift_1M   | sift_1M   | 1            | 1000000  | 170.001 MB     | 170.001 MB    | 0.000          | 0.000           | 0.000          | 0.000           |\n|           | Total     | 1            |          | 170.001 MB     | 170.001 MB    | 0.000          | 0.000           | 0.000          | 0.000           |\n+-----------+-----------+--------------+----------+----------------+---------------+----------------+-----------------+----------------+-----------------+\n2 rows in set (0.01 sec)\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Then you can build the index using the ",(0,s.jsx)(n.code,{children:"BUILD INDEX"})," statement:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"BUILD INDEX idx_test_ann ON sift_1M;\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"BUILD INDEX"})," is executed asynchronously. You can use ",(0,s.jsx)(n.code,{children:"SHOW BUILD INDEX"})," (in some versions ",(0,s.jsx)(n.code,{children:"SHOW ALTER"}),") to check the job status."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:'SHOW BUILD INDEX WHERE TableName = "sift_1M";\n\n+---------------+-----------+---------------+------------------------------------------------------------------------------------------------------------------------------------+-------------------------+-------------------------+---------------+----------+------+----------+\n| JobId         | TableName | PartitionName | AlterInvertedIndexes                                                                                                               | CreateTime              | FinishTime              | TransactionId | State    | Msg  | Progress |\n+---------------+-----------+---------------+------------------------------------------------------------------------------------------------------------------------------------+-------------------------+-------------------------+---------------+----------+------+----------+\n| 1763603913428 | sift_1M   | sift_1M       | [ADD INDEX idx_test_ann (`embedding`) USING ANN PROPERTIES("dim" = "128", "index_type" = "hnsw", "metric_type" = "l2_distance")],  | 2025-11-20 11:14:55.253 | 2025-11-20 11:15:10.622 | 126128        | FINISHED |      | NULL     |\n+---------------+-----------+---------------+------------------------------------------------------------------------------------------------------------------------------------+-------------------------+-------------------------+---------------+----------+------+----------+\n'})}),"\n",(0,s.jsx)(n.h4,{id:"drop-index",children:"DROP INDEX"}),"\n",(0,s.jsxs)(n.p,{children:["You can drop an unsuitable ANN index with ",(0,s.jsx)(n.code,{children:"ALTER TABLE sift_1M DROP INDEX idx_test_ann"}),". Dropping and recreating indexes is common during hyperparameter tuning, when you need to test different parameter combinations to achieve the desired recall."]}),"\n",(0,s.jsx)(n.h3,{id:"querying",children:"Querying"}),"\n",(0,s.jsx)(n.p,{children:"ANN indexes support both Top\u2011N search and range search."}),"\n",(0,s.jsx)(n.p,{children:"When the vector column has high dimensionality, the literal representation of the query vector itself can incur extra parsing overhead. Therefore, directly embedding the full query vector into raw SQL is not recommended in production, especially under high concurrency. A better practice is to use prepared statements, which avoid repetitive SQL parsing."}),"\n",(0,s.jsxs)(n.p,{children:["We recommend using the ",(0,s.jsx)(n.a,{href:"https://github.com/uchenily/doris_vector_search",children:"doris-vector-search"})," python library, which wraps the necessary operations for vector search in Doris based on prepared statements, and includes data conversion utilities that map Doris query results into Pandas ",(0,s.jsx)(n.code,{children:"DataFrame"}),"s for convenient downstream AI application development."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from doris_vector_search import DorisVectorClient, AuthOptions\n\nauth = AuthOptions(\n    host="localhost",\n    query_port=9030,\n    user="root",\n    password="",\n)\n\nclient = DorisVectorClient(database="demo", auth_options=auth)\n\ntbl = client.open_table("sift_1M")\n\nquery = [0.1] * 128  # Example 128-dimensional vector\n\n# SELECT id FROM sift_1M ORDER BY l2_distance_approximate(embedding, query) LIMIT 10;\nresult = tbl.search(query, metric_type="l2_distance").limit(10).select(["id"]).to_pandas()\n\nprint(result)\n'})}),"\n",(0,s.jsx)(n.p,{children:"Sample output:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:"       id\n0  123911\n1   11743\n2  108584\n3  123739\n4   73311\n5  124746\n6  620941\n7  124493\n8  177392\n9  153178\n"})}),"\n",(0,s.jsx)(n.h3,{id:"recall-optimization",children:"Recall Optimization"}),"\n",(0,s.jsx)(n.p,{children:"In vector search, recall is the most important metric; performance numbers only make sense under a given recall level. The main factors that affect recall are:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Index\u2011time parameters of HNSW (",(0,s.jsx)(n.code,{children:"max_degree"}),", ",(0,s.jsx)(n.code,{children:"ef_construction"}),") and query\u2011time parameter (",(0,s.jsx)(n.code,{children:"ef_search"}),")."]}),"\n",(0,s.jsx)(n.li,{children:"Vector quantization."}),"\n",(0,s.jsx)(n.li,{children:"Segment size and the number of segments."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"This article focuses on the impact of (1) and (3) on recall. Vector quantization will be covered in a separate document."}),"\n",(0,s.jsx)(n.h4,{id:"index-hyperparameters",children:"Index Hyperparameters"}),"\n",(0,s.jsx)(n.p,{children:"An HNSW index organizes vectors into a multi\u2011layer graph. During index construction, vectors are inserted one by one and connected with neighbors across layers. The process is roughly as follows:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Layer assignment"}),": Each vector is randomly assigned a level following a geometric distribution. Higher\u2011level nodes are sparser and act as shortcuts for navigation."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:["Search for candidate neighbors using ",(0,s.jsx)(n.code,{children:"ef_construction"})]}),":\nAt each level, HNSW uses a candidate queue of maximum size ",(0,s.jsx)(n.code,{children:"ef_construction"})," to perform a local search.\nLarger ",(0,s.jsx)(n.code,{children:"ef_construction"})," values generally yield better neighbors and higher\u2011quality graphs (and thus higher recall), at the cost of longer index\u2011building time."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:["Limit connections using ",(0,s.jsx)(n.code,{children:"max_degree"})]}),":\nThe number of neighbors for each node is capped by ",(0,s.jsx)(n.code,{children:"max_degree"}),", which prevents the graph from becoming too dense."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"At query time:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Greedy search on upper layers (coarse search)"}),":\nStarting from the entry node on the highest layer, HNSW performs greedy search on the upper layers to quickly move into the vicinity of the query."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:["Breadth\u2011like search on the bottom layer using ",(0,s.jsx)(n.code,{children:"ef_search"})," (fine search)"]}),":\nOn layer 0, HNSW uses a candidate queue of maximum size ",(0,s.jsx)(n.code,{children:"ef_search"})," to expand neighbors more thoroughly."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"In summary:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"max_degree"})," defines the maximum number of (bidirectional) edges per node. It affects recall, memory usage, and query performance. Larger ",(0,s.jsx)(n.code,{children:"max_degree"})," usually yields higher recall but slower queries."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"ef_construction"})," defines the maximum length of the candidate queue during index construction. Larger values improve graph quality and recall, but increase index\u2011build time."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"ef_search"})," defines the maximum length of the candidate queue during query. Larger values improve recall, but increase the number of distance computations, which raises query latency and CPU usage."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["By default, Doris uses ",(0,s.jsx)(n.code,{children:"max_degree = 32"}),", ",(0,s.jsx)(n.code,{children:"ef_construction = 40"}),", and ",(0,s.jsx)(n.code,{children:"ef_search = 32"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"The above is a qualitative analysis of these three hyperparameters. The following table shows empirical results on the SIFT_1M dataset:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"max_degree"}),(0,s.jsx)(n.th,{children:"ef_construction"}),(0,s.jsx)(n.th,{children:"ef_search"}),(0,s.jsx)(n.th,{children:"recall_at_1"}),(0,s.jsx)(n.th,{children:"recall_at_100"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"80"}),(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"0.955"}),(0,s.jsx)(n.td,{children:"0.75335"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"80"}),(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"0.98"}),(0,s.jsx)(n.td,{children:"0.88015"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"80"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"0.995"}),(0,s.jsx)(n.td,{children:"0.9328"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"120"}),(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"0.96"}),(0,s.jsx)(n.td,{children:"0.7736"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"120"}),(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"0.975"}),(0,s.jsx)(n.td,{children:"0.89865"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"120"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"0.99"}),(0,s.jsx)(n.td,{children:"0.94575"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"160"}),(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"0.955"}),(0,s.jsx)(n.td,{children:"0.78745"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"160"}),(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"0.98"}),(0,s.jsx)(n.td,{children:"0.9097"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"160"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"0.995"}),(0,s.jsx)(n.td,{children:"0.95485"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"48"}),(0,s.jsx)(n.td,{children:"80"}),(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"0.985"}),(0,s.jsx)(n.td,{children:"0.85895"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"48"}),(0,s.jsx)(n.td,{children:"80"}),(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"0.99"}),(0,s.jsx)(n.td,{children:"0.9453"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"48"}),(0,s.jsx)(n.td,{children:"80"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"0.97325"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"48"}),(0,s.jsx)(n.td,{children:"120"}),(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"0.97"}),(0,s.jsx)(n.td,{children:"0.78335"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"48"}),(0,s.jsx)(n.td,{children:"120"}),(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"0.9089"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"48"}),(0,s.jsx)(n.td,{children:"120"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"0.95325"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"48"}),(0,s.jsx)(n.td,{children:"160"}),(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"0.975"}),(0,s.jsx)(n.td,{children:"0.79745"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"48"}),(0,s.jsx)(n.td,{children:"160"}),(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"0.995"}),(0,s.jsx)(n.td,{children:"0.9192"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"48"}),(0,s.jsx)(n.td,{children:"160"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"0.995"}),(0,s.jsx)(n.td,{children:"0.9601"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"80"}),(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"0.9026"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"80"}),(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"0.97025"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"80"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"0.9862"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"120"}),(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"0.985"}),(0,s.jsx)(n.td,{children:"0.8548"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"120"}),(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"0.99"}),(0,s.jsx)(n.td,{children:"0.94755"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"120"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"0.995"}),(0,s.jsx)(n.td,{children:"0.97645"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"160"}),(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"0.97"}),(0,s.jsx)(n.td,{children:"0.80585"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"160"}),(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"0.99"}),(0,s.jsx)(n.td,{children:"0.91925"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"160"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"0.995"}),(0,s.jsx)(n.td,{children:"0.96165"})]})]})]}),"\n",(0,s.jsx)(n.p,{children:"The results show that multiple hyperparameter combinations can reach similar recall levels. For example, suppose you want recall@100 > 0.95. The following combinations all meet the requirement:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"max_degree"}),(0,s.jsx)(n.th,{children:"ef_construction"}),(0,s.jsx)(n.th,{children:"ef_search"}),(0,s.jsx)(n.th,{children:"recall_at_1"}),(0,s.jsx)(n.th,{children:"recall_at_100"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"160"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"0.995"}),(0,s.jsx)(n.td,{children:"0.95485"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"48"}),(0,s.jsx)(n.td,{children:"80"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"0.97325"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"48"}),(0,s.jsx)(n.td,{children:"120"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"0.95325"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"48"}),(0,s.jsx)(n.td,{children:"160"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"0.995"}),(0,s.jsx)(n.td,{children:"0.9601"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"80"}),(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"0.97025"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"80"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"0.9862"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"120"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"0.995"}),(0,s.jsx)(n.td,{children:"0.97645"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"64"}),(0,s.jsx)(n.td,{children:"160"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"0.995"}),(0,s.jsx)(n.td,{children:"0.96165"})]})]})]}),"\n",(0,s.jsx)(n.p,{children:"It is hard to provide one single optimal setting in advance, but you can follow a practical workflow for hyperparameter selection:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Create a table ",(0,s.jsx)(n.code,{children:"table_multi_index"})," without indexes. It can contain 2 or 3 vector columns."]}),"\n",(0,s.jsxs)(n.li,{children:["Load data into ",(0,s.jsx)(n.code,{children:"table_multi_index"})," using Stream Load or other ingestion methods."]}),"\n",(0,s.jsxs)(n.li,{children:["Use ",(0,s.jsx)(n.code,{children:"CREATE INDEX"})," and ",(0,s.jsx)(n.code,{children:"BUILD INDEX"})," to build ANN indexes on all vector columns."]}),"\n",(0,s.jsx)(n.li,{children:"Use different index parameter configurations on different columns. After index building finishes, compute recall on each column and choose the best parameter combination."}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"number-of-rows-covered-per-index",children:"Number of Rows Covered per Index"}),"\n",(0,s.jsx)(n.p,{children:"Internally, Doris organizes data in multiple layers."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["At the top is a ",(0,s.jsx)(n.strong,{children:"table"}),", which is partitioned into N ",(0,s.jsx)(n.strong,{children:"tablets"})," using a distribution key. Tablets serve as units for data sharding, relocation, and rebalance."]}),"\n",(0,s.jsxs)(n.li,{children:["Each data ingestion or compaction produces a new ",(0,s.jsx)(n.strong,{children:"rowset"})," under a tablet. A rowset is a versioned collection of data."]}),"\n",(0,s.jsxs)(n.li,{children:["Data in a rowset is actually stored in ",(0,s.jsx)(n.strong,{children:"segment"})," files."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Similar to inverted indexes, vector indexes are built at the ",(0,s.jsx)(n.strong,{children:"segment"})," level. The segment size is determined by BE configuration options like ",(0,s.jsx)(n.code,{children:"write_buffer_size"})," and ",(0,s.jsx)(n.code,{children:"vertical_compaction_max_segment_size"}),". During ingestion and compaction, when the in\u2011memory memtable reaches a certain size, it is flushed to disk as a segment file, and a vector index (or multiple indexes for multiple vector columns) is built for that segment. The index only covers the rows in that segment."]}),"\n",(0,s.jsx)(n.p,{children:"Given a fixed set of HNSW parameters, there is always a limit to the number of vectors for which the index can still maintain high recall. Once the number of vectors in a segment grows beyond that limit, recall starts to degrade."}),"\n",(0,s.jsx)(n.p,{children:"Below are some empirical values for how many rows a segment can hold under certain hyperparameters while still maintaining good recall:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"max_degree"}),(0,s.jsx)(n.th,{children:"ef_construction"}),(0,s.jsx)(n.th,{children:"ef_search"}),(0,s.jsx)(n.th,{children:"num_segment"}),(0,s.jsx)(n.th,{children:"recall_at_100"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"160"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"1M"}),(0,s.jsx)(n.td,{children:"0.95485"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"48"}),(0,s.jsx)(n.td,{children:"80"}),(0,s.jsx)(n.td,{children:"96"}),(0,s.jsx)(n.td,{children:"1M"}),(0,s.jsx)(n.td,{children:"0.97325"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"160"}),(0,s.jsx)(n.td,{children:"32"}),(0,s.jsx)(n.td,{children:"3M"}),(0,s.jsx)(n.td,{children:"0.66983"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"128"}),(0,s.jsx)(n.td,{children:"512"}),(0,s.jsx)(n.td,{children:"128"}),(0,s.jsx)(n.td,{children:"3M"}),(0,s.jsx)(n.td,{children:"0.9931"})]})]})]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:["You can use ",(0,s.jsx)(n.code,{children:"SHOW TABLETS FROM table"})," to inspect the compaction status of a table. By following the corresponding URL, you can see how many segments it has."]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"impact-of-compaction-on-recall",children:"Impact of Compaction on Recall"}),"\n",(0,s.jsx)(n.p,{children:"Compaction can affect recall because it may create larger segments, which can exceed the \u201Ccoverage capacity\u201D implied by the original hyperparameters. As a result, the recall level achieved before compaction may no longer hold after compaction."}),"\n",(0,s.jsxs)(n.p,{children:["We recommend triggering a full compaction before running ",(0,s.jsx)(n.code,{children:"BUILD INDEX"}),". Building indexes on fully compacted segments stabilizes recall and also reduces write amplification caused by index rebuilds."]}),"\n",(0,s.jsx)(n.h3,{id:"query-performance",children:"Query Performance"}),"\n",(0,s.jsx)(n.h4,{id:"cold-loading-of-index-files",children:"Cold Loading of Index Files"}),"\n",(0,s.jsxs)(n.p,{children:["The HNSW ANN index in Doris is implemented using Meta\u2019s open\u2011source library ",(0,s.jsx)(n.a,{href:"https://github.com/facebookresearch/faiss",children:"Faiss"}),". HNSW indexes only become effective after the full graph structure of a segment has been loaded into memory. Therefore, before running high\u2011concurrency workloads, it is recommended to run some warm\u2011up queries to make sure that all relevant segment indexes are loaded into memory; otherwise, disk I/O overhead can significantly hurt query performance."]}),"\n",(0,s.jsx)(n.h4,{id:"memory-footprint-vs-performance",children:"Memory Footprint vs. Performance"}),"\n",(0,s.jsx)(n.p,{children:"Without quantization or compression, the memory footprint of an HNSW index is roughly 1.2\u20131.3\xd7 the memory footprint of all vectors it indexes."}),"\n",(0,s.jsx)(n.p,{children:"For example, with 1 million 128\u2011dimensional vectors, an HNSW\u2011FLAT index requires approximately:"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"128 * 4 * 1,000,000 * 1.3 \u2248 650 MB"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"Some reference values:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"dim"}),(0,s.jsx)(n.th,{children:"rows"}),(0,s.jsx)(n.th,{children:"estimated memory"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"128"}),(0,s.jsx)(n.td,{children:"1M"}),(0,s.jsx)(n.td,{children:"650 MB"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"768"}),(0,s.jsx)(n.td,{children:"10M"}),(0,s.jsx)(n.td,{children:"48 GB"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"768"}),(0,s.jsx)(n.td,{children:"100M"}),(0,s.jsx)(n.td,{children:"110 GB"})]})]})]}),"\n",(0,s.jsx)(n.p,{children:"To maintain stable performance, ensure that each BE has enough memory; otherwise, frequent swapping and I/O on index files will severely degrade query latency."}),"\n",(0,s.jsx)(n.h3,{id:"benchmark",children:"Benchmark"}),"\n",(0,s.jsx)(n.p,{children:"We benchmarked Doris HNSW index query performance on a 16\u2011core, 64\u2011GB machine. In a typical production deployment, FE and BE are on separate machines, so two such machines are needed. We provide results for both the typical (separate FE/BE) deployment and a mixed FE/BE deployment on a single machine."}),"\n",(0,s.jsxs)(n.p,{children:["The benchmark framework is ",(0,s.jsx)(n.a,{href:"https://github.com/zilliztech/VectorDBBench",children:"VectorDBBench"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"The load generator runs on another 16\u2011core machine."}),"\n",(0,s.jsx)(n.h4,{id:"performance768d1m",children:"Performance768D1M"}),"\n",(0,s.jsx)(n.p,{children:"Benchmark command:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"NUM_PER_BATCH=1000000 python3.11 -m vectordbbench doris --host 127.0.0.1 --port 9030 --case-type Performance768D1M --db-name Performance768D1M --search-concurrent --search-serial --num-concurrency 10,40,80 --stream-load-rows-per-batch 500000 --index-prop max_degree=128,ef_construction=512 --session-var hnsw_ef_search=128\n"})}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{children:"Doris (FE/BE separate)"}),(0,s.jsx)(n.th,{children:"Doris (FE/BE mixed)"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Index prop"})}),(0,s.jsx)(n.td,{children:"max_degree=128, ef_construction=512, hnsw_ef_search=128"}),(0,s.jsx)(n.td,{children:"max_degree=128, ef_construction=512, hnsw_ef_search=156"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Recall@100"})}),(0,s.jsx)(n.td,{children:"0.9931"}),(0,s.jsx)(n.td,{children:"0.9929"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Concurrency (Client)"})}),(0,s.jsx)(n.td,{children:"10, 40, 80"}),(0,s.jsx)(n.td,{children:"10, 40, 80"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Result QPS"})}),(0,s.jsxs)(n.td,{children:["163.1567 (10)",(0,s.jsx)(n.br,{}),"606.6832 (40)",(0,s.jsx)(n.br,{}),"859.3842 (80)"]}),(0,s.jsxs)(n.td,{children:["162.3002 (10)",(0,s.jsx)(n.br,{}),"542.3488 (40)",(0,s.jsx)(n.br,{}),"607.7951 (80)"]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Avg Latency (s)"})}),(0,s.jsxs)(n.td,{children:["0.06123 (10)",(0,s.jsx)(n.br,{}),"0.06579 (40)",(0,s.jsx)(n.br,{}),"0.09281 (80)"]}),(0,s.jsxs)(n.td,{children:["0.06154 (10)",(0,s.jsx)(n.br,{}),"0.07351 (40)",(0,s.jsx)(n.br,{}),"0.13093 (80)"]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"P95 Latency (s)"})}),(0,s.jsxs)(n.td,{children:["0.06560 (10)",(0,s.jsx)(n.br,{}),"0.07747 (40)",(0,s.jsx)(n.br,{}),"0.12967 (80)"]}),(0,s.jsxs)(n.td,{children:["0.06726 (10)",(0,s.jsx)(n.br,{}),"0.08789 (40)",(0,s.jsx)(n.br,{}),"0.18719 (80)"]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"P99 Latency (s)"})}),(0,s.jsxs)(n.td,{children:["0.06889 (10)",(0,s.jsx)(n.br,{}),"0.08618 (40)",(0,s.jsx)(n.br,{}),"0.14605 (80)"]}),(0,s.jsxs)(n.td,{children:["0.06154 (10)",(0,s.jsx)(n.br,{}),"0.07351 (40)",(0,s.jsx)(n.br,{}),"0.13093 (80)"]})]})]})]})]})}function o(e={}){let{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},367681:function(e,n,r){r.d(n,{Z:function(){return i}});let i=r.p+"assets/images/hnsw-db17c0a1f9b8f89ee61f2f3ccae47a20.png"},554149:function(e,n,r){r.d(n,{Z:function(){return i}});let i=r.p+"assets/images/low_quality_pgraph-c36df166fe69b31be53b574980641d4a.png"},250065:function(e,n,r){r.d(n,{Z:function(){return a},a:function(){return d}});var i=r(667294);let s={},t=i.createContext(s);function d(e){let n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:d(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);