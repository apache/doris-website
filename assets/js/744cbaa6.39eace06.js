"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["118504"],{469952:function(e,n,r){r.r(n),r.d(n,{default:()=>h,frontMatter:()=>i,metadata:()=>s,assets:()=>l,toc:()=>c,contentTitle:()=>a});var s=JSON.parse('{"id":"admin-manual/workload-management/workload-group","title":"Workload Group","description":"Workload Group is an in-process mechanism for isolating workloads. It achieves resource isolation by finely partitioning or limiting resources (CPU,","source":"@site/versioned_docs/version-4.x/admin-manual/workload-management/workload-group.md","sourceDirName":"admin-manual/workload-management","slug":"/admin-manual/workload-management/workload-group","permalink":"/docs/4.x/admin-manual/workload-management/workload-group","draft":false,"unlisted":false,"tags":[],"version":"4.x","lastUpdatedAt":1770477659000,"frontMatter":{"title":"Workload Group","language":"en","description":"Workload Group is an in-process mechanism for isolating workloads. It achieves resource isolation by finely partitioning or limiting resources (CPU,"},"sidebar":"docs","previous":{"title":"Compute Group","permalink":"/docs/4.x/admin-manual/workload-management/compute-group"},"next":{"title":"Workload Group Bind Compute Group","permalink":"/docs/4.x/admin-manual/workload-management/workload-group-bind-compute-group"}}'),o=r("785893"),t=r("250065");let i={title:"Workload Group",language:"en",description:"Workload Group is an in-process mechanism for isolating workloads. It achieves resource isolation by finely partitioning or limiting resources (CPU,"},a=void 0,l={},c=[{value:"Version Notes",id:"version-notes",level:2},{value:"Core Concepts",id:"core-concepts",level:2},{value:"Configuring Workload Group",id:"configuring-workload-group",level:2},{value:"Setting Up the CGroup Environment",id:"setting-up-the-cgroup-environment",level:3},{value:"Considerations for Using Workload Group in Containers",id:"considerations-for-using-workload-group-in-containers",level:4},{value:"Create Workload Group",id:"create-workload-group",level:3},{value:"Set Workload Group for user",id:"set-workload-group-for-user",level:2},{value:"Show Workload Group",id:"show-workload-group",level:2},{value:"Alter Workload Group",id:"alter-workload-group",level:2},{value:"Drop Workload Group",id:"drop-workload-group",level:2},{value:"Testing",id:"testing",level:2},{value:"Memory hard limit",id:"memory-hard-limit",level:3},{value:"CPU hard limit",id:"cpu-hard-limit",level:3},{value:"Limit local IO",id:"limit-local-io",level:3},{value:"Limit remote IO",id:"limit-remote-io",level:3},{value:"Frequently Asked Questions",id:"frequently-asked-questions",level:2}];function d(e){let n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.p,{children:"Workload Group is an in-process mechanism for isolating workloads.\nIt achieves resource isolation by finely partitioning or limiting resources (CPU, IO, Memory) within the BE process.\nIts principle is illustrated in the diagram below:"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"Workload Group Architecture",src:r(356631).Z+"",width:"1618",height:"554"})}),"\n",(0,o.jsx)(n.p,{children:"The currently supported isolation capabilities include:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Managing CPU resources, with support for both cpu hard limit and cpu soft limit;"}),"\n",(0,o.jsx)(n.li,{children:"Managing memory resources, with support for both memory hard limit and memory soft limit;"}),"\n",(0,o.jsx)(n.li,{children:"Managing IO resources, including IO generated by reading local and remote files."}),"\n"]}),"\n",(0,o.jsxs)(n.admonition,{type:"tip",children:[(0,o.jsx)(n.p,{children:"Workload Group provides in-process resource isolation capabilities, which differ from inter-process resource isolation methods (such as Resource Group and Compute Group) in the following ways:"}),(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"In-process resource isolation cannot achieve complete isolation. For example, when high-load and low-load queries run within the same process, even if CPU usage for the high-load group is restricted using Workload Group to keep overall CPU usage within a reasonable range, the latency of the low-load group may still be affected. However, it will perform better compared to having no CPU control at all. This limitation arises because certain shared components within the process, such as common caches and shared RPC thread pools, are difficult to isolate entirely."}),"\n",(0,o.jsx)(n.li,{children:"The choice of a resource isolation strategy depends on the trade-off between isolation and cost. If some degree of latency can be tolerated while prioritizing lower costs, the Workload Group isolation approach may be suitable. On the other hand, if complete isolation is required and higher costs are acceptable, an inter-process resource isolation approach (i.e., placing isolated workloads in separate processes) should be considered. For example, using Resource Group or Compute Group to allocate high-priority workloads to independent BE nodes can achieve a more thorough isolation."}),"\n"]})]}),"\n",(0,o.jsx)(n.h2,{id:"version-notes",children:"Version Notes"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"The Workload Group feature has been available since Doris 2.0. In Doris 2.0, the Workload Group feature does not rely on CGroup, but starting with Doris 2.1, it requires CGroup."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Upgrading from Doris 1.2 to 2.0: It is recommended to enable the Workload Group feature only after the entire cluster has been upgraded. If only some follower FE nodes are upgraded, queries on the upgraded follower FE nodes may fail due to the absence of Workload Group metadata on the non-upgraded FE nodes."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Upgrading from Doris 2.0 to 2.1: Since the Workload Group feature in Doris 2.1 relies on CGroup, you need to configure the CGroup environment before upgrading to Doris 2.1."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"In version Doris 4.0, the original concepts of CPU soft limit and hard limit have been modified to min_cpu_percent and max_cpu_percent, and the concepts of memory soft limit and hard limit have been modified to min_memory_percent and max_memory_percent."}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"MIN_CPU_PERCENT and MAX_CPU_PERCENT"})}),"\n",(0,o.jsx)(n.p,{children:"The value range is [0%, 100%]. These settings define the minimum and maximum guaranteed CPU bandwidth for all requests in a Workload Group when there is CPU contention."}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"MAX_CPU_PERCENT (maximum CPU percentage) is the upper limit of CPU bandwidth for the group. Regardless of the current CPU usage, the CPU usage of the current Workload Group will never exceed MAX_CPU_PERCENT."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"MIN_CPU_PERCENT (minimum CPU percentage) is the CPU bandwidth reserved for the Workload Group. When there is contention, other groups cannot use this portion of bandwidth. However, when resources are idle, bandwidth exceeding MIN_CPU_PERCENT can be used."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"The sum of MIN_CPU_PERCENT across all Workload Groups must not exceed 100%, and MIN_CPU_PERCENT cannot be greater than MAX_CPU_PERCENT."}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"For example, assume the Sales and Marketing departments of a company share the same Doris instance. The Sales department has a CPU-intensive workload with high-priority queries, while the Marketing department also has a CPU-intensive workload but with lower-priority queries. By creating separate Workload Groups for each department, you can assign a minimum CPU percentage of 40% to the Sales Workload Group and a maximum CPU percentage of 30% to the Marketing Workload Group. This configuration ensures that the Sales workload gets the required CPU resources, while the Marketing workload does not affect the CPU demands of the Sales workload."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"MIN_MEMORY_PERCENT and MAX_MEMORY_PERCENT"})}),"\n",(0,o.jsx)(n.p,{children:"The value range is [0%, 100%]. These settings represent the minimum and maximum amount of memory that a Workload Group can use."}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"MAX_MEMORY_PERCENT means that when requests are running in the group, their memory usage will never exceed this percentage of the total memory. Once exceeded, the query will either trigger disk spilling or be killed."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"MIN_MEMORY_PERCENT sets the minimum memory value for a group. When resources are idle, memory exceeding MIN_MEMORY_PERCENT can be used. However, when memory is insufficient, the system will allocate memory according to MIN_MEMORY_PERCENT (minimum memory percentage). It may select some queries to kill, reducing the memory usage of the Workload Group to MIN_MEMORY_PERCENT to ensure that other Workload Groups have sufficient memory available."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"The sum of MIN_MEMORY_PERCENT across all Workload Groups must not exceed 100%, and MIN_MEMORY_PERCENT cannot be greater than MAX_MEMORY_PERCENT."}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Other Settings"})}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Property"}),(0,o.jsx)(n.th,{children:"Data type"}),(0,o.jsx)(n.th,{children:"Default value"}),(0,o.jsx)(n.th,{children:"Value range"}),(0,o.jsx)(n.th,{children:"Description"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"max_concurrency"}),(0,o.jsx)(n.td,{children:"Integer"}),(0,o.jsx)(n.td,{children:"2147483647"}),(0,o.jsx)(n.td,{children:"[0, 2147483647]"}),(0,o.jsx)(n.td,{children:"Optional. Specifies the maximum query concurrency. The default value is the maximum value of an integer, meaning no concurrency limit. When the number of running queries reaches the maximum concurrency, new queries will enter a queue."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"max_queue_size"}),(0,o.jsx)(n.td,{children:"Integer"}),(0,o.jsx)(n.td,{children:"0"}),(0,o.jsx)(n.td,{children:"[0, 2147483647]"}),(0,o.jsx)(n.td,{children:"Optional. Specifies the length of the query waiting queue. When the queue is full, new queries will be rejected. The default value is 0, which means no queuing. If the queue is full, new queries will fail directly."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"queue_timeout"}),(0,o.jsx)(n.td,{children:"Integer"}),(0,o.jsx)(n.td,{children:"0"}),(0,o.jsx)(n.td,{children:"[0, 2147483647]"}),(0,o.jsx)(n.td,{children:"Optional. Specifies the maximum waiting time for a query in the waiting queue, in milliseconds. If the query's waiting time in the queue exceeds this value, an exception will be thrown directly to the client. The default value is 0, meaning no queuing; queries will immediately fail upon entering the queue."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"scan_thread_num"}),(0,o.jsx)(n.td,{children:"Integer"}),(0,o.jsx)(n.td,{children:"-1"}),(0,o.jsx)(n.td,{children:"[1, 2147483647]"}),(0,o.jsx)(n.td,{children:"Optional. Specifies the number of threads used for scanning in the current Workload Group. When this property is set to -1, it means it is not active, and the actual scan thread num on the BE will default to the doris_scanner_thread_pool_thread_num configuration in the BE."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"max_remote_scan_thread_num"}),(0,o.jsx)(n.td,{children:"Integer"}),(0,o.jsx)(n.td,{children:"-1"}),(0,o.jsx)(n.td,{children:"[1, 2147483647]"}),(0,o.jsx)(n.td,{children:"Optional. Specifies the maximum number of threads in the scan thread pool for reading external data sources. When this property is set to -1, the actual number of threads is determined by the BE, typically based on the number of CPU cores."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"min_remote_scan_thread_num"}),(0,o.jsx)(n.td,{children:"Integer"}),(0,o.jsx)(n.td,{children:"-1"}),(0,o.jsx)(n.td,{children:"[1, 2147483647]"}),(0,o.jsx)(n.td,{children:"Optional. Specifies the minimum number of threads in the scan thread pool for reading external data sources. When this property is set to -1, the actual number of threads is determined by the BE, typically based on the number of CPU cores."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"read_bytes_per_second"}),(0,o.jsx)(n.td,{children:"Integer"}),(0,o.jsx)(n.td,{children:"-1"}),(0,o.jsx)(n.td,{children:"[1, 9223372036854775807]"}),(0,o.jsx)(n.td,{children:"Optional. Specifies the maximum I/O throughput when reading internal tables in Doris. The default value is -1, meaning no I/O bandwidth limit is applied. It is important to note that this value is not tied to individual disks but to directories. For example, if Doris is configured with two directories to store internal table data, the maximum read I/O for each directory will not exceed this value. If both directories are placed on the same disk, the maximum throughput will be doubled (i.e., 2 times read_bytes_per_second). The file directory for spill disk is also subject to this limit."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"remote_read_bytes_per_second"}),(0,o.jsx)(n.td,{children:"Integer"}),(0,o.jsx)(n.td,{children:"-1"}),(0,o.jsx)(n.td,{children:"[1, 9223372036854775807]"}),(0,o.jsx)(n.td,{children:"Optional. Specifies the maximum I/O throughput when reading external tables in Doris. The default value is -1, meaning no I/O bandwidth limit is applied."})]})]})]}),"\n",(0,o.jsx)(n.h2,{id:"configuring-workload-group",children:"Configuring Workload Group"}),"\n",(0,o.jsx)(n.h3,{id:"setting-up-the-cgroup-environment",children:"Setting Up the CGroup Environment"}),"\n",(0,o.jsx)(n.p,{children:"Workload Group supports managing CPU, memory, and IO. CPU management relies on the CGroup component.\nTo use Workload Group for CPU resource management, you must first configure the CGroup environment."}),"\n",(0,o.jsx)(n.p,{children:"The following are the steps for configuring the CGroup environment:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"First, verify whether the node where the BE is located has CGroup installed.\nIf the output includes cgroup, it indicates that CGroup V1 is installed in the current environment.\nIf it includes cgroup2, it indicates that CGroup V2 is installed. You can determine which version is active in the next step."}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"cat /proc/filesystems | grep cgroup\nnodev	cgroup\nnodev	cgroup2\nnodev	cgroupfs\n"})}),"\n",(0,o.jsxs)(n.ol,{start:"2",children:["\n",(0,o.jsx)(n.li,{children:"The active CGroup version can be confirmed based on the path name."}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"If this path exists, it indicates that CGroup V1 is currently active.\n/sys/fs/cgroup/cpu/\n\n\nIf this path exists, it indicates that CGroup V2 is currently active.\n/sys/fs/cgroup/cgroup.controllers\n"})}),"\n",(0,o.jsxs)(n.ol,{start:"3",children:["\n",(0,o.jsx)(n.li,{children:"Create a directory named doris under the CGroup path. The directory name can be customized by the user."}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"If using CGroup V1, create the directory under the cpu directory.\nmkdir /sys/fs/cgroup/cpu/doris\n\n\nIf using CGroup V2, create the directory directly under the cgroup directory.\nmkdir /sys/fs/cgroup/doris\n"})}),"\n",(0,o.jsxs)(n.ol,{start:"4",children:["\n",(0,o.jsx)(n.li,{children:"Ensure that the Doris BE process has read, write, and execute permissions for this directory."}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"// If using CGroup V1, the command is as follows:\n// 1. Modify the directory's permissions to be readable, writable, and executable.\nchmod 770 /sys/fs/cgroup/cpu/doris\n// 2. Change the ownership of this directory to the doris account.\nchown -R doris:doris /sys/fs/cgroup/cpu/doris\n\n\n// If using CGroup V2, the command is as follows:\n// 1.Modify the directory's permissions to be readable, writable, and executable.\nchmod 770 /sys/fs/cgroup/doris\n// 2. Change the ownership of this directory to the doris account.\nchown -R doris:doris /sys/fs/cgroup/doris\n"})}),"\n",(0,o.jsxs)(n.ol,{start:"5",children:["\n",(0,o.jsx)(n.li,{children:"If the current environment is using CGroup v2, the following steps are required. If it is CGroup v1, this step can be skipped."}),"\n"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Modify the permissions of the cgroup.procs file in the root directory. This is necessary because CGroup v2 has stricter permission controls,\nand write permissions to the cgroup.procs file in the root directory are required to move processes between CGroup directories."}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"chmod a+w /sys/fs/cgroup/cgroup.procs\n"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"In CGroup v2, the cgroup.controllers file lists the available controllers for the current directory, and the cgroup.subtree_control file lists the controllers available for the subdirectories.\nTherefore, it is necessary to check if the doris directory has the cpu controller enabled. If the cgroup.controllers file in the doris directory does not include cpu, it means the cpu controller is not enabled. You can enable it by executing the following command in the doris directory.\nThis command works by modifying the cgroup.subtree_control file in the parent directory to allow the doris directory to use the cpu controller."}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"// After running this command, you should be able to see the cpu.max file in the doris directory, \n// and the output of cgroup.controllers should include cpu.\n// If the command fails, it means that the parent directory of doris also does not have the cpu controller enabled, \n// and you will need to enable the cpu controller for the parent directory.\necho +cpu > ../cgroup.subtree_control\n"})}),"\n",(0,o.jsxs)(n.ol,{start:"6",children:["\n",(0,o.jsx)(n.li,{children:"Modify the BE configuration to specify the path of the cgroup."}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"If using CGroup V1, the configuration path is as follows:\ndoris_cgroup_cpu_path = /sys/fs/cgroup/cpu/doris\n\nIf using CGroup V2, the configuration path is as follows:\ndoris_cgroup_cpu_path = /sys/fs/cgroup/doris\n"})}),"\n",(0,o.jsxs)(n.ol,{start:"7",children:["\n",(0,o.jsx)(n.li,{children:"Restart the BE, and in the log (be.INFO), the phrase 'add thread xxx to group' indicates that the configuration was successful."}),"\n"]}),"\n",(0,o.jsx)(n.admonition,{type:"tip",children:(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"It is recommended to deploy only one BE per machine, as the current Workload Group feature does not support deploying multiple BE instances on a single machine."}),"\n",(0,o.jsx)(n.li,{children:"After a machine is restarted, all configurations under the CGroup path will be cleared.\nTo persist the CGroup configuration, you can use systemd to set the operation as a custom system service,\nso that the creation and authorization operations can be automatically performed each time the machine restarts."}),"\n",(0,o.jsx)(n.li,{children:"If using CGroup within a container, the container must have permission to operate on the host machine."}),"\n"]})}),"\n",(0,o.jsx)(n.h4,{id:"considerations-for-using-workload-group-in-containers",children:"Considerations for Using Workload Group in Containers"}),"\n",(0,o.jsx)(n.p,{children:"Workload's CPU management is based on CGroup. If you want to use Workload Group inside a container,\nthe container needs to be started in privileged mode so that the BE process inside the container has permission to read and write CGroup files on the host machine."}),"\n",(0,o.jsx)(n.p,{children:"When BE runs inside a container, the CPU resource usage for Workload Group is partitioned based on the available resources of the container.\nFor example, if the host machine has 64 cores and the container is allocated 8 cores,\nand the Workload Group is configured with a 50% CPU hard limit, the actual available CPU cores for the Workload Group will be 4 (8 cores * 50%)."}),"\n",(0,o.jsx)(n.p,{children:"The memory and IO management functions of Workload Group are implemented internally by Doris and do not rely on external components,\nso there is no difference in deployment between containers and physical machines."}),"\n",(0,o.jsx)(n.p,{children:"If you want to use Doris on K8S, it is recommended to deploy it using the Doris Operator, which can shield underlying permission issues."}),"\n",(0,o.jsx)(n.h3,{id:"create-workload-group",children:"Create Workload Group"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'mysql [information_schema]>create workload group if not exists g1\n    -> properties (\n    ->     "cpu_share"="1024"\n    -> );\nQuery OK, 0 rows affected (0.03 sec)\n\n'})}),"\n",(0,o.jsxs)(n.p,{children:["You can refer to ",(0,o.jsx)(n.a,{href:"../../sql-manual/sql-statements/cluster-management/compute-management/CREATE-WORKLOAD-GROUP",children:"CREATE-WORKLOAD-GROUP"}),"\u3002"]}),"\n",(0,o.jsx)(n.p,{children:"The CPU limit configured at this point is a soft limit. Since version 2.1, Doris will automatically create a group named normal, which cannot be deleted."}),"\n",(0,o.jsx)(n.h2,{id:"set-workload-group-for-user",children:"Set Workload Group for user"}),"\n",(0,o.jsx)(n.p,{children:"Before binding a user to a specific Workload Group, it is necessary to ensure that the user has the necessary permissions for the Workload Group.\nYou can use the user to query the information_schema.workload_groups system table, and the result will show the Workload Groups that the current user has permission to access.\nThe following query result indicates that the current user has access to the g1 and normal Workload Groups:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"SELECT name FROM information_schema.workload_groups;\n+--------+\n| name   |\n+--------+\n| normal |\n| g1     |\n+--------+\n"})}),"\n",(0,o.jsx)(n.p,{children:"If the g1 Workload Group is not visible, you can use the ADMIN account to execute the GRANT statement to authorize the user. For example:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"GRANT USAGE_PRIV ON WORKLOAD GROUP 'g1' TO 'user_1'@'%';\n"})}),"\n",(0,o.jsxs)(n.p,{children:["This statement means granting the user_1 the permission to use the Workload Group named g1.\nMore details can be found in ",(0,o.jsx)(n.a,{href:"../../sql-manual/sql-statements/account-management/GRANT-TO",children:"grant"}),"\u3002"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Two ways to bind Workload Group to user"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"By setting the user property, you can bind the user to a default Workload Group. The default is normal. It's important to note that the value here cannot be left empty; otherwise, the statement will fail."}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"set property 'default_workload_group' = 'g1';\n"})}),"\n",(0,o.jsx)(n.p,{children:"After executing this statement, the current user's queries will default to using the 'g1' Workload Group."}),"\n",(0,o.jsxs)(n.ol,{start:"2",children:["\n",(0,o.jsx)(n.li,{children:"By specifying the Workload Group through a session variable, the default is empty:"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"set workload_group = 'g1';\n"})}),"\n",(0,o.jsx)(n.p,{children:"When both methods are used to specify a Workload Group for the user, the session variable takes priority over the user property."}),"\n",(0,o.jsx)(n.h2,{id:"show-workload-group",children:"Show Workload Group"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"You can use the SHOW statement to view the Workload Group:"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"show workload groups;\n"})}),"\n",(0,o.jsxs)(n.p,{children:["More details can be found in ",(0,o.jsx)(n.a,{href:"../../sql-manual/sql-statements/cluster-management/compute-management/SHOW-WORKLOAD-GROUPS",children:"SHOW-WORKLOAD-GROUPS"})]}),"\n",(0,o.jsxs)(n.ol,{start:"2",children:["\n",(0,o.jsx)(n.li,{children:"You can view the Workload Group through the system table:"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"mysql [information_schema]>select * from information_schema.workload_groups where name='g1';\n+-------+------+-----------+--------------+--------------------------+-----------------+----------------+---------------+----------------+-----------------+----------------------------+----------------------------+----------------------+-----------------------+------+-----------------------+------------------------------+\n| ID    | NAME | CPU_SHARE | MEMORY_LIMIT | ENABLE_MEMORY_OVERCOMMIT | MAX_CONCURRENCY | MAX_QUEUE_SIZE | QUEUE_TIMEOUT | CPU_HARD_LIMIT | SCAN_THREAD_NUM | MAX_REMOTE_SCAN_THREAD_NUM | MIN_REMOTE_SCAN_THREAD_NUM | MEMORY_LOW_WATERMARK | MEMORY_HIGH_WATERMARK | TAG  | READ_BYTES_PER_SECOND | REMOTE_READ_BYTES_PER_SECOND |\n+-------+------+-----------+--------------+--------------------------+-----------------+----------------+---------------+----------------+-----------------+----------------------------+----------------------------+----------------------+-----------------------+------+-----------------------+------------------------------+\n| 14009 | g1   |      1024 | -1           | true                     |      2147483647 |              0 |             0 | -1             |              -1 |                         -1 |                         -1 | 50%                  | 80%                   |      |                    -1 |                           -1 |\n+-------+------+-----------+--------------+--------------------------+-----------------+----------------+---------------+----------------+-----------------+----------------------------+----------------------------+----------------------+-----------------------+------+-----------------------+------------------------------+\n1 row in set (0.05 sec)\n"})}),"\n",(0,o.jsx)(n.h2,{id:"alter-workload-group",children:"Alter Workload Group"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"mysql [information_schema]>alter workload group g1 properties('cpu_share'='2048');\nQuery OK, 0 rows affected (0.00 sec\n\nmysql [information_schema]>select cpu_share from information_schema.workload_groups where name='g1';\n+-----------+\n| cpu_share |\n+-----------+\n|      2048 |\n+-----------+\n1 row in set (0.02 sec)\n\n"})}),"\n",(0,o.jsxs)(n.p,{children:["More details can be found in ",(0,o.jsx)(n.a,{href:"../../sql-manual/sql-statements/cluster-management/compute-management/ALTER-WORKLOAD-GROUP",children:"ALTER-WORKLOAD-GROUP"})]}),"\n",(0,o.jsx)(n.h2,{id:"drop-workload-group",children:"Drop Workload Group"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"mysql [information_schema]>drop workload group g1;\nQuery OK, 0 rows affected (0.01 sec)\n"})}),"\n",(0,o.jsxs)(n.p,{children:["More details can be found in",(0,o.jsx)(n.a,{href:"../../sql-manual/sql-statements/cluster-management/compute-management/DROP-WORKLOAD-GROUP",children:"DROP-WORKLOAD-GROUP"})]}),"\n",(0,o.jsx)(n.h2,{id:"testing",children:"Testing"}),"\n",(0,o.jsx)(n.h3,{id:"memory-hard-limit",children:"Memory hard limit"}),"\n",(0,o.jsx)(n.p,{children:"Adhoc-type queries typically have unpredictable SQL inputs and uncertain memory usage, which poses the risk of a few queries consuming a large amount of memory.\nThese types of workloads can be allocated to a separate group, and by using the Workload Group's memory hard limit feature, it helps prevent sudden large queries from consuming all memory, which could cause other queries to run out of available memory or result in OOM (Out of Memory) errors.\nWhen the memory usage of this Workload Group exceeds the configured hard limit, the system will kill queries to release memory, preventing the process from running out of memory."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Testing environment"})}),"\n",(0,o.jsx)(n.p,{children:"1 FE, 1 BE, with BE configured to 96 cores and 375GB of memory."}),"\n",(0,o.jsx)(n.p,{children:"The test dataset is clickbench, and the testing method involves using JMeter to run query Q29 with three concurrent executions."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Test without enabling memory hard limit for Workload Group"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Check the memory usage of the process. The fourth column in the ps command output represents the physical memory usage of the process, in kilobytes (KB). It shows that under the current test load, the process uses approximately 7.7GB of memory."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"[ ~]$ ps -eo pid,comm,%mem,rss | grep 1407481\n1407481 doris_be         2.0 7896792\n[ ~]$ ps -eo pid,comm,%mem,rss | grep 1407481\n1407481 doris_be         2.0 7929692\n[ ~]$ ps -eo pid,comm,%mem,rss | grep 1407481\n1407481 doris_be         2.0 8101232\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Use Doris system tables to check the current memory usage of the Workload Group. The memory usage of the Workload Group is approximately 5.8GB."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"mysql [information_schema]>select MEMORY_USAGE_BYTES / 1024/ 1024 as wg_mem_used_mb from workload_group_resource_usage where workload_group_id=11201;\n+-------------------+\n| wg_mem_used_mb    |\n+-------------------+\n| 5797.524360656738 |\n+-------------------+\n1 row in set (0.01 sec)\n\nmysql [information_schema]>select MEMORY_USAGE_BYTES / 1024/ 1024 as wg_mem_used_mb from workload_group_resource_usage where workload_group_id=11201;\n+-------------------+\n| wg_mem_used_mb    |\n+-------------------+\n| 5840.246627807617 |\n+-------------------+\n1 row in set (0.02 sec)\n\nmysql [information_schema]>select MEMORY_USAGE_BYTES / 1024/ 1024 as wg_mem_used_mb from workload_group_resource_usage where workload_group_id=11201;\n+-------------------+\n| wg_mem_used_mb    |\n+-------------------+\n| 5878.394917488098 |\n+-------------------+\n1 row in set (0.02 sec)\n"})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Here, we can see that the process memory usage is typically much larger than the memory usage of a Workload Group, even if only one Workload Group is running. This is because the Workload Group only tracks the memory used by queries and loads The memory used by other components within the process, such as metadata and various caches, is not counted as part of the Workload Group's memory usage, nor is it managed by the Workload Group."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Test with the memory hard limit for Workload Group enabled"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Execute the SQL command to modify the memory configuration."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"alter workload group g2 properties('memory_limit'='0.5%');\nalter workload group g2 properties('enable_memory_overcommit'='false');\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Run the same test and check the memory usage in the system table; the memory usage is around 1.5G."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"mysql [information_schema]>select MEMORY_USAGE_BYTES / 1024/ 1024 as wg_mem_used_mb from workload_group_resource_usage where workload_group_id=11201;\n+--------------------+\n| wg_mem_used_mb     |\n+--------------------+\n| 1575.3877239227295 |\n+--------------------+\n1 row in set (0.02 sec)\n\nmysql [information_schema]>select MEMORY_USAGE_BYTES / 1024/ 1024 as wg_mem_used_mb from workload_group_resource_usage where workload_group_id=11201;\n+------------------+\n| wg_mem_used_mb   |\n+------------------+\n| 1668.77405834198 |\n+------------------+\n1 row in set (0.01 sec)\n\nmysql [information_schema]>select MEMORY_USAGE_BYTES / 1024/ 1024 as wg_mem_used_mb from workload_group_resource_usage where workload_group_id=11201;\n+--------------------+\n| wg_mem_used_mb     |\n+--------------------+\n| 499.96760272979736 |\n+--------------------+\n1 row in set (0.01 sec)\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Use the ps command to check the memory usage of the process; the memory usage is around 3.8G."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"[ ~]$ ps -eo pid,comm,%mem,rss | grep 1407481\n1407481 doris_be         1.0 4071364\n[ ~]$ ps -eo pid,comm,%mem,rss | grep 1407481\n1407481 doris_be         1.0 4059012\n[ ~]$ ps -eo pid,comm,%mem,rss | grep 1407481\n1407481 doris_be         1.0 4057068\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"At the same time, the client will observe a significant number of query failures caused by insufficient memory."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:'1724074250162,14126,1c_sql,HY000 1105,"java.sql.SQLException: errCode = 2, detailMessage = (127.0.0.1)[MEM_LIMIT_EXCEEDED]GC wg for hard limit, wg id:11201, name:g2, used:1.71 GB, limit:1.69 GB, backend:10.16.10.8. cancel top memory used tracker <Query#Id=4a0689936c444ac8-a0d01a50b944f6e7> consumption 1.71 GB. details:process memory used 3.01 GB exceed soft limit 304.41 GB or sys available memory 101.16 GB less than warning water mark 12.80 GB., Execute again after enough memory, details see be.INFO.",\u5E76\u53D1 1-3,text,false,,444,0,3,3,null,0,0,0\n'})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"From the error message, it can be observed that the Workload Group used 1.7G of memory, but the Workload Group's limit is 1.69G. The calculation is as follows:1.69G = Physical machine memory (375G) * mem_limit (value from be.conf, default is 0.9) * 0.5% (Workload Group's configuration).\nThis means the memory percentage configured in the Workload Group is calculated based on the memory available to the BE process."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Recommendations"})}),"\n",(0,o.jsx)(n.p,{children:"As demonstrated in the tests above, memory hard limits can control the memory usage of a Workload Group but do so by terminating queries to release memory. This approach can lead to a poor user experience and, in extreme cases, may cause all queries to fail."}),"\n",(0,o.jsx)(n.p,{children:"Therefore, in production environments, it is recommended to use memory hard limits in conjunction with query queuing functionality. This ensures controlled memory usage while maintaining query success rates."}),"\n",(0,o.jsx)(n.h3,{id:"cpu-hard-limit",children:"CPU hard limit"}),"\n",(0,o.jsx)(n.p,{children:"Doris workloads can generally be categorized into three types:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Core Report Queries: These are typically used by company executives to view reports. While the load may not be very high, the availability requirements are strict. These queries can be assigned to a group with a higher-priority soft limit, ensuring they receive more CPU resources when resources are insufficient."}),"\n",(0,o.jsx)(n.li,{children:"Adhoc queries are typically exploratory and analytical in nature, with random SQL and unpredictable resource consumption. Their priority is usually low. Therefore, CPU hard limits can be used to manage these queries, configuring lower values to prevent excessive CPU resource usage that could reduce cluster availability."}),"\n",(0,o.jsx)(n.li,{children:"ETL queries typically have fixed SQL and stable resource consumption, although there may occasionally be spikes in resource usage due to increased upstream data. Therefore, CPU hard limits can be configured to manage these queries."}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Different workloads have varying CPU consumption, and users have different latency requirements. When the BE CPU is fully utilized, availability decreases, and response times increase. For example, an Adhoc analysis query may fully utilize the CPU of the entire cluster, causing core report queries to experience higher latency, which impacts SLA. Therefore, a CPU isolation mechanism is needed to separate different workloads and ensure cluster availability and SLA."}),"\n",(0,o.jsx)(n.p,{children:"Workload Group supports both CPU soft limits and hard limits. It is currently recommended to configure Workload Groups with hard limits in production environments. This is because CPU soft limits typically only show priority effects when the CPU is fully utilized. However, when the CPU is fully used, internal Doris components (such as the RPC component) and the operating system\u2019s available CPU are reduced, leading to a significant drop in overall cluster availability. Therefore, in production environments, it is essential to avoid CPU resource exhaustion, and the same logic applies to other resources such as memory."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Test environment"})}),"\n",(0,o.jsx)(n.p,{children:"1 FE, 1 BE, 96-core machine.\nThe dataset is clickbench, and the test SQL is q29."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Tesing"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Using JMeter to initiate 3 concurrent queries, the CPU usage of the BE process is pushed to a relatively high usage rate. The test machine has 96 cores, and using the top command, we can see that the BE process's CPU usage is 7600%, which means the process is currently using 76 cores."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"use workload group cpu",src:r(53982).Z+"",width:"962",height:"146"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Modify the CPU hard limit of the currently used Workload Group to 10%."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"alter workload group g2 properties('max_cpu_percent'='10%');\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Re-run the load test for queries, and you can see that the current process can only use 9 to 10 cores, which is about 10% of the total cores."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"use workload group cpu",src:r(665930).Z+"",width:"1138",height:"180"})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"It is important to note that this test is best conducted using query workloads, as they are more likely to reflect the effect. If testing load, it may trigger Compaction, causing the actual observed values to be higher than the values configured in the Workload Group. Currently, Compaction workloads are not managed under the Workload Group."}),"\n",(0,o.jsxs)(n.ol,{start:"4",children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"In addition to using Linux system commands, you can also observe the current CPU usage of the group through Doris's system tables, where the CPU usage is around 10%."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"mysql [information_schema]>select CPU_USAGE_PERCENT from workload_group_resource_usage where WORKLOAD_GROUP_ID=11201;\n+-------------------+\n| CPU_USAGE_PERCENT |\n+-------------------+\n|              9.57 |\n+-------------------+\n1 row in set (0.02 sec)\n"})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"note"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"When configuring, it's better not to set the total CPU allocation of all groups to exactly 100%. This is mainly to ensure the availability of low-latency scenarios, as some resources need to be reserved for other components. However, for scenarios that are not very sensitive to latency and aim for maximum resource utilization, setting the total CPU allocation of all groups to 100% can be considered."}),"\n",(0,o.jsx)(n.li,{children:"Currently, the interval for synchronizing Workload Group metadata from FE to BE is 30 seconds. Therefore, changes to Workload Group settings may take up to 30 seconds to take effect."}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"limit-local-io",children:"Limit local IO"}),"\n",(0,o.jsx)(n.p,{children:"In OLAP systems, during ETL operations or large Adhoc queries, a significant amount of data needs to be read. To speed up the data analysis process, Doris uses multi-threaded parallel scanning across multiple disk files, which generates substantial disk IO that can impact other queries (such as report analysis).\nBy using Workload Groups, Doris can group offline ETL data processing and online report queries separately, limiting the offline data processing IO bandwidth. This helps reduce the impact of offline data processing on online report analysis."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Test environment"})}),"\n",(0,o.jsx)(n.p,{children:"1 FE, 1 BE, 96-core machine. Dataset: clickbench. Test query: q29."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Testing without enabling IO hard limits"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Clear Cache."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"// clear OS cache\nsync; echo 3 > /proc/sys/vm/drop_caches\n\n// disable BE page cache\ndisable_storage_page_cache = true\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Perform a full table scan on the clickbench table, and execute a single concurrent query."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"set dry_run_query = true;\nselect * from hits.hits;\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Check the maximum throughput of the current Group as 3GB per second through Doris's system table."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"mysql [information_schema]>select LOCAL_SCAN_BYTES_PER_SECOND / 1024 / 1024 as mb_per_sec from workload_group_resource_usage where WORKLOAD_GROUP_ID=11201;\n+--------------------+\n| mb_per_sec         |\n+--------------------+\n| 1146.6208400726318 |\n+--------------------+\n1 row in set (0.03 sec)\n\nmysql [information_schema]>select LOCAL_SCAN_BYTES_PER_SECOND / 1024 / 1024 as mb_per_sec from workload_group_resource_usage where WORKLOAD_GROUP_ID=11201;\n+--------------------+\n| mb_per_sec         |\n+--------------------+\n| 3496.2762966156006 |\n+--------------------+\n1 row in set (0.04 sec)\n\nmysql [information_schema]>select LOCAL_SCAN_BYTES_PER_SECOND / 1024 / 1024 as mb_per_sec from workload_group_resource_usage where WORKLOAD_GROUP_ID=11201;\n+--------------------+\n| mb_per_sec         |\n+--------------------+\n| 2192.7690029144287 |\n+--------------------+\n1 row in set (0.02 sec)\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Use the pidstat command to check the process IO. The first column is the process ID, and the second column is the read IO throughput (in kb/s). It can be seen that when IO is not restricted, the maximum throughput is 2GB per second."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"use workload group io",src:r(715719).Z+"",width:"814",height:"1080"})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Test after enabling IO hard limit"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Clear cache."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"// Clear OS cache.\nsync; echo 3 > /proc/sys/vm/drop_caches\n\n// disable BE page cache\ndisable_storage_page_cache = true\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Modify the Workload Group configuration to limit the maximum throughput to 100M per second."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"alter workload group g2 properties('read_bytes_per_second'='104857600');\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Use Doris system tables to check that the maximum IO throughput of the Workload Group is 98M per second."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"mysql [information_schema]>select LOCAL_SCAN_BYTES_PER_SECOND / 1024 / 1024 as mb_per_sec from workload_group_resource_usage where WORKLOAD_GROUP_ID=11201;\n+--------------------+\n| mb_per_sec         |\n+--------------------+\n| 97.94296646118164  |\n+--------------------+\n1 row in set (0.03 sec)\n\nmysql [information_schema]>select LOCAL_SCAN_BYTES_PER_SECOND / 1024 / 1024 as mb_per_sec from workload_group_resource_usage where WORKLOAD_GROUP_ID=11201;\n+--------------------+\n| mb_per_sec         |\n+--------------------+\n| 98.37584781646729  |\n+--------------------+\n1 row in set (0.04 sec)\n\nmysql [information_schema]>select LOCAL_SCAN_BYTES_PER_SECOND / 1024 / 1024 as mb_per_sec from workload_group_resource_usage where WORKLOAD_GROUP_ID=11201;\n+--------------------+\n| mb_per_sec         |\n+--------------------+\n| 98.06641292572021  |\n+--------------------+\n1 row in set (0.02 sec)\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Use the pid tool to check that the maximum IO throughput of the process is 131M per second."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"use workload group io",src:r(579239).Z+"",width:"808",height:"676"})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Note"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"The LOCAL_SCAN_BYTES_PER_SECOND field in the system table represents the summary value of the current Workload Group's statistics at the process level. For example, if 12 file paths are configured, LOCAL_SCAN_BYTES_PER_SECOND is the maximum IO value of these 12 file paths. If you wish to view the IO throughput for each file path separately, you can check the detailed values in Grafana."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Due to the presence of the operating system and Doris's Page Cache, the IO observed through Linux's IO monitoring scripts is typically smaller than the IO seen in the system table."}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"limit-remote-io",children:"Limit remote IO"}),"\n",(0,o.jsx)(n.p,{children:"BrokerLoad and S3Load are commonly used methods for large-scale data load. Users can first upload data to HDFS or S3, and then use BrokerLoad and S3Load to load data in parallel. To speed up the load process, Doris uses multi-threading to pull data from HDFS/S3, which can generate significant pressure on HDFS/S3, potentially making other jobs running on HDFS/S3 unstable."}),"\n",(0,o.jsx)(n.p,{children:"To mitigate the impact on other workloads, the Workload Group's remote IO limit feature can be used to restrict the bandwidth used during the load process from HDFS/S3. This helps reduce the impact on other business operations."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Test environment"})}),"\n",(0,o.jsx)(n.p,{children:"1 FE and 1 BE are deployed on the same machine, configured with 16 cores and 64GB of memory. The test data is the clickbench dataset, and before testing, we need to upload the dataset to S3. Considering the upload time, we will only upload 10 million rows of data, and then use the TVF function to query the data from S3."}),"\n",(0,o.jsx)(n.p,{children:"After the upload is successful, you can use the command to view the schema information."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'```sql\nDESC FUNCTION s3 (\n    "URI" = "https://bucketname/1kw.tsv",\n    "s3.access_key"= "ak",\n    "s3.secret_key" = "sk",\n    "format" = "csv",\n    "use_path_style"="true"\n);\n```\n'})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Test without restricting remote read IO"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Initiate a single-threaded test to perform a full table scan on the clickbench table."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:'// Set the operation to only scan the data without returning results.\nset dry_run_query = true;\n\nSELECT * FROM s3(\n    "URI" = "https://bucketname/1kw.tsv",\n    "s3.access_key"= "ak",\n    "s3.secret_key" = "sk",\n    "format" = "csv",\n    "use_path_style"="true"\n);\n'})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Use the system table to check the current remote IO throughput. It shows that the remote IO throughput for this query is 837 MB per second. Note that the actual IO throughput here is highly dependent on the environment. If the machine hosting the BE has limited bandwidth to the external storage, the actual throughput may be lower."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"MySQL [(none)]> select cast(REMOTE_SCAN_BYTES_PER_SECOND/1024/1024 as int) as read_mb from information_schema.workload_group_resource_usage;\n+---------+\n| read_mb |\n+---------+\n|     837 |\n+---------+\n1 row in set (0.104 sec)\n\nMySQL [(none)]> select cast(REMOTE_SCAN_BYTES_PER_SECOND/1024/1024 as int) as read_mb from information_schema.workload_group_resource_usage;\n+---------+\n| read_mb |\n+---------+\n|     867 |\n+---------+\n1 row in set (0.070 sec)\n\nMySQL [(none)]> select cast(REMOTE_SCAN_BYTES_PER_SECOND/1024/1024 as int) as read_mb from information_schema.workload_group_resource_usage;\n+---------+\n| read_mb |\n+---------+\n|     867 |\n+---------+\n1 row in set (0.186 sec)\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Use the sar command (sar -n DEV 1 3600) to monitor the machine's network bandwidth. It shows that the maximum network bandwidth at the machine level is 1033 MB per second.\nThe first column of the output represents the number of bytes received per second by a specific network interface on the machine, in KB per second."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"use workload group rio",src:r(716653).Z+"",width:"960",height:"436"})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Test limiting remote read IO"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Modify the Workload Group configuration to limit remote read IO throughput to 100M per second."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"alter workload group normal properties('remote_read_bytes_per_second'='104857600');\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Initiate a single concurrent full table scan query."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:'set dry_run_query = true;\n\nSELECT * FROM s3(\n    "URI" = "https://bucketname/1kw.tsv",\n    "s3.access_key"= "ak",\n    "s3.secret_key" = "sk",\n    "format" = "csv",\n    "use_path_style"="true"\n);\n'})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Use the system table to check the current remote read IO throughput. At this time, the IO throughput is around 100M, with some fluctuations. These fluctuations are influenced by the current algorithm design, typically peaking briefly without persisting for long periods, which is considered normal."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:"MySQL [(none)]> select cast(REMOTE_SCAN_BYTES_PER_SECOND/1024/1024 as int) as read_mb from information_schema.workload_group_resource_usage;\n+---------+\n| read_mb |\n+---------+\n|      56 |\n+---------+\n1 row in set (0.010 sec)\n\nMySQL [(none)]> select cast(REMOTE_SCAN_BYTES_PER_SECOND/1024/1024 as int) as read_mb from information_schema.workload_group_resource_usage;\n+---------+\n| read_mb |\n+---------+\n|     131 |\n+---------+\n1 row in set (0.009 sec)\n\nMySQL [(none)]> select cast(REMOTE_SCAN_BYTES_PER_SECOND/1024/1024 as int) as read_mb from information_schema.workload_group_resource_usage;\n+---------+\n| read_mb |\n+---------+\n|     111 |\n+---------+\n1 row in set (0.009 sec)\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Use the sar command (sar -n DEV 1 3600) to monitor the current network card's received traffic. The first column represents the amount of data received per second. The maximum value observed is now 207M per second, indicating that the read IO limit is effective. However, since the sar command reflects machine-level traffic, the observed value is slightly higher than what Doris reports."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"use workload group rio",src:r(674967).Z+"",width:"864",height:"472"})}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"frequently-asked-questions",children:"Frequently Asked Questions"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Why is the CPU hard limit configuration not taking effect?"}),"\n"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["This is usually caused by the following reasons:\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Environment initialization failed. You need to check the two configuration files under the Doris CGroup path.\nHere, we take the CGroup V1 version as an example. If the user has specified the Doris CGroup path as ",(0,o.jsx)(n.code,{children:"/sys/fs/cgroup/cpu/doris/"}),",\nyou should first check if the content of ",(0,o.jsx)(n.code,{children:"/sys/fs/cgroup/cpu/doris/query/1/tasks"}),' contains the thread IDs corresponding to the Workload Group.\nThe "1" in the path represents the Workload Group ID, which can be obtained by running the command ',(0,o.jsx)(n.code,{children:"top -H -b -n 1 -p pid"})," to find the thread IDs of the Workload Group.\nAfter confirming, ensure that the thread IDs of the Workload Group are written into the tasks file.\nThen, check if the value of ",(0,o.jsx)(n.code,{children:"/sys/fs/cgroup/cpu/doris/query/1/cpu.cfs_quota_us"})," is -1. If it is -1, it means the CPU hard limit configuration has not taken effect."]}),"\n",(0,o.jsxs)(n.li,{children:["The CPU usage of the Doris BE process is higher than the CPU hard limit configured for the Workload Group.\nThis is expected because the CPU managed by the Workload Group is primarily for query threads and memtable flush threads for Load.\nHowever, the BE process typically has other components consuming CPU as well, such as Compaction.\nTherefore, the CPU usage of the process is generally higher than the configured limit for the Workload Group.\nYou can create a test Workload Group that only stresses the query load and then check the CPU usage of the\nWorkload Group through the system table ",(0,o.jsx)(n.code,{children:"information_schema.workload_group_resource_usage"}),".\nThis table only records the CPU usage of the Workload Group and has been supported since version 2.1.6."]}),"\n",(0,o.jsxs)(n.li,{children:["Some users have configured the ",(0,o.jsx)(n.code,{children:"cpu_resource_limit"}),".First, execute ",(0,o.jsx)(n.code,{children:"show property for jack like 'cpu_resource_limit'"}),"\nto check whether this parameter is set in the properties of the user jack.\nThen, execute ",(0,o.jsx)(n.code,{children:"show variables like 'cpu_resource_limit'"})," to verify whether this parameter is set in the session variables.\nThe default value of this parameter is -1, which indicates that it is not set.\nAfter configuring this parameter, queries are handled by an independent thread pool that\nis not managed by the Workload Group. Directly modifying this parameter may affect the stability of the production environment.\nIt is recommended to gradually migrate the query loads that are configured with this parameter to be managed by the Workload Group.\nThe current alternative to this parameter is the session variable ",(0,o.jsx)(n.code,{children:"num_scanner_threads"}),". The main process is as follows:\nFirst, divide the users who have configured ",(0,o.jsx)(n.code,{children:"cpu_resource_limit"})," into several batches. When migrating the first batch of users,\nmodify the session variable ",(0,o.jsx)(n.code,{children:"num_scanner_threads"})," for these users to 1. Then, assign a Workload Group to these users. After that,\nchange ",(0,o.jsx)(n.code,{children:"cpu_resource_limit"})," to -1 and observe the cluster's stability over a period of time. If the cluster remains stable, continue migrating the next batch of users."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.ol,{start:"2",children:["\n",(0,o.jsx)(n.li,{children:"Why is the default number of Workload Groups limited to 15?"}),"\n"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Workload Groups are primarily used for dividing resources on a single machine.\nIf too many Workload Groups are created on one machine, each Workload Group will only receive a very small portion of the resources.\nIf the user indeed requires creating this many Workload Groups,\nyou can consider dividing the cluster into multiple groups of BEs and then creating different Workload Groups for each group of BEs.\nYou can also temporarily bypass this limit by modifying the FE configuration ",(0,o.jsx)(n.code,{children:"workload_group_max_num"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(n.ol,{start:"3",children:["\n",(0,o.jsx)(n.li,{children:'Why does the error "Resource temporarily unavailable" occur after configuring many Workload Groups?'}),"\n"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Each Workload Group corresponds to an independent thread pool.\nCreating too many Workload Groups may cause the BE process to attempt to start too many threads,\nexceeding the maximum number of threads allowed for a process by the operating system.\nTo resolve this issue, you can modify the system environment configuration to allow the BE process to create more threads."}),"\n"]})]})}function h(e={}){let{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},53982:function(e,n,r){r.d(n,{Z:function(){return s}});let s=r.p+"assets/images/use_wg_cpu_1-6211d7170720ad508590d94cf72724e3.png"},665930:function(e,n,r){r.d(n,{Z:function(){return s}});let s=r.p+"assets/images/use_wg_cpu_2-03419ba3e02b1980179a1af557d41d1c.png"},715719:function(e,n,r){r.d(n,{Z:function(){return s}});let s=r.p+"assets/images/use_wg_io_1-15b5d3e97f7ccf7f914eef0e6bf55cd4.png"},579239:function(e,n,r){r.d(n,{Z:function(){return s}});let s=r.p+"assets/images/use_wg_io_2-2202fea206c596a3879c6660ada71037.png"},716653:function(e,n,r){r.d(n,{Z:function(){return s}});let s=r.p+"assets/images/use_wg_rio_1-e3ae321d5e709bb0ba21b9572d2bce1f.png"},674967:function(e,n,r){r.d(n,{Z:function(){return s}});let s=r.p+"assets/images/use_wg_rio_2-7511c9afedf43b931909b18e529f00ea.png"},356631:function(e,n,r){r.d(n,{Z:function(){return s}});let s=r.p+"assets/images/workload_group_arch-8a340fcf78d446415148216722775065.png"},250065:function(e,n,r){r.d(n,{Z:function(){return a},a:function(){return i}});var s=r(667294);let o={},t=s.createContext(o);function i(e){let n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);