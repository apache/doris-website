"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["638540"],{798500:function(e,n,t){t.r(n),t.d(n,{default:()=>x,frontMatter:()=>i,metadata:()=>s,assets:()=>l,toc:()=>h,contentTitle:()=>c});var s=JSON.parse('{"id":"admin-manual/maint-monitor/metrics","title":"Monitor Metrics","description":"Doris FE process and BE processes provide complete monitoring metrics. Monitoring metrics can be divided into two categories:","source":"@site/versioned_docs/version-3.x/admin-manual/maint-monitor/metrics.md","sourceDirName":"admin-manual/maint-monitor","slug":"/admin-manual/maint-monitor/metrics","permalink":"/docs/3.x/admin-manual/maint-monitor/metrics","draft":false,"unlisted":false,"tags":[],"version":"3.x","lastUpdatedAt":1770477659000,"frontMatter":{"title":"Monitor Metrics","language":"en","description":"Doris FE process and BE processes provide complete monitoring metrics. Monitoring metrics can be divided into two categories:"},"sidebar":"docs","previous":{"title":"BE Log Management","permalink":"/docs/3.x/admin-manual/log-management/be-log"},"next":{"title":"Monitoring and alarming","permalink":"/docs/3.x/admin-manual/maint-monitor/monitor-alert"}}'),d=t("785893"),r=t("250065");let i={title:"Monitor Metrics",language:"en",description:"Doris FE process and BE processes provide complete monitoring metrics. Monitoring metrics can be divided into two categories:"},c="Monitor Metrics",l={},h=[{value:"Monitoring levels and best practices",id:"monitoring-levels-and-best-practices",level:2},{value:"FE Monitoring Metrics",id:"fe-monitoring-metrics",level:2},{value:"Process monitoring",id:"process-monitoring",level:3},{value:"<strong>JVM</strong> <strong>metrics</strong>",id:"jvm-metrics",level:3}];function o(e){let n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,r.a)(),...e.components};return(0,d.jsxs)(d.Fragment,{children:[(0,d.jsx)(n.header,{children:(0,d.jsx)(n.h1,{id:"monitor-metrics",children:"Monitor Metrics"})}),"\n",(0,d.jsx)(n.p,{children:"Doris FE process and BE processes provide complete monitoring metrics. Monitoring metrics can be divided into two categories:"}),"\n",(0,d.jsxs)(n.ol,{children:["\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.strong,{children:"Process monitoring"}),": mainly displays some monitoring values of the Doris process itself ."]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.strong,{children:"Node monitoring"}),": mainly displays the monitoring of the node machine itself where the Doris process is located, such as CPU , memory, IO , network , etc."]}),"\n"]}),"\n",(0,d.jsx)(n.p,{children:"You can obtain the current monitoring by accessing the http port of the FE or BE node . like :"}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{children:"curl http://fe_host:http_port/metrics\ncurl http://be_host:webserver_port/metrics\n"})}),"\n",(0,d.jsx)(n.p,{children:"Monitoring metrics are generated in a Prometheus compatible format, for eg:"}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{children:'doris_fe_cache_added{type="partition"} 0\ndoris_fe_cache_added{type="sql"} 0\ndoris_fe_cache_hit{type="partition"} 0\ndoris_fe_cache_hit{type="sql"} 0\ndoris_fe_connection_total 2\n'})}),"\n",(0,d.jsxs)(n.p,{children:["Monitoring metrics in Json format can be fetched using ",(0,d.jsx)(n.code,{children:"type"})," parameter in rest interface, for eg:"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{children:"curl http://fe_host:http_port/metrics?type=json\ncurl http://be_host:webserver_port/metrics?type=json\n"})}),"\n",(0,d.jsx)(n.h2,{id:"monitoring-levels-and-best-practices",children:"Monitoring levels and best practices"}),"\n",(0,d.jsx)(n.p,{children:(0,d.jsx)(n.strong,{children:"The last column in the table marks the importance level of the monitoring items. P0 means the most important, the larger the value , the lower the importance."})}),"\n",(0,d.jsx)(n.p,{children:"The vast majority of monitoring metric types are Counter . That is the cumulative value. You can obtain effective information by collecting monitoring values at intervals (such as every 15 seconds) and calculating the slope per unit time ."}),"\n",(0,d.jsxs)(n.p,{children:["The query error rate can be obtained by calculating the slope of ",(0,d.jsx)(n.code,{children:"doris_fe_query_err"}),", presented as (error per second)."]}),"\n",(0,d.jsx)(n.h2,{id:"fe-monitoring-metrics",children:"FE Monitoring Metrics"}),"\n",(0,d.jsx)(n.h3,{id:"process-monitoring",children:"Process monitoring"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,d.jsxs)(n.table,{children:[(0,d.jsx)(n.thead,{children:(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"name"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Label"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"unit"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Description"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Implication"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Grade"})})]})}),(0,d.jsxs)(n.tbody,{children:[(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_cache_added"}),(0,d.jsx)(n.td,{children:'{type="partition"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Cumulative value of the number of new Partition Cache"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type=" sql "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Cumulative value of the number of new SQL Cache"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_cache_hit"}),(0,d.jsx)(n.td,{children:'{type="partition"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Count of partition cache hits"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type=" sql "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Count of SQL Cache hits"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_connection_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Current number of FE MySQL port connections"}),(0,d.jsx)(n.td,{children:"Used to monitor the number of query connections. If  the number of connections exceeds the limit, new connections will not be  accessible ."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_counter_hit_sql_block_rule"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Number of queries blocked by SQL BLOCK RULE"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_edit_log_clean"}),(0,d.jsx)(n.td,{children:'{type="failed"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"to clear historical metadata logs"}),(0,d.jsx)(n.td,{children:"It should not fail. If it fails, manual intervention is required."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="success"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of times the historical metadata log was successfully cleared"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_edit_log"}),(0,d.jsx)(n.td,{children:'{type="  accumulated_bytes "}'}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"value of metadata log write amount"}),(0,d.jsx)(n.td,{children:"The write rate can be obtained by calculating the slope to observe  whether there is a delay in metadata writing."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type=" current_bytes  "}'}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"Metadata log current value"}),(0,d.jsx)(n.td,{children:"Used to monitor editlog size. If  the size exceeds the limit, manual intervention is required"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="read"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Count of metadata log reads"}),(0,d.jsx)(n.td,{children:"Observe whether the metadata reading frequency is normal through the  slope"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="write"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Count of metadata log writes"}),(0,d.jsx)(n.td,{children:"Observe whether the metadata writing frequency is normal through the  slope"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="current"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Current number of metadata logs"}),(0,d.jsx)(n.td,{children:"Used to monitor editlog quantity.  If the quantity exceeds the limit, manual intervention is required"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_editlog_write_latency_ms"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"millisecond"}),(0,d.jsx)(n.td,{children:'metadata log write latency . For  example, {quantile="0.75"}  indicates the 75th percentile write latency .'}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_image_clean"}),(0,d.jsx)(n.td,{children:'{type="failed"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"to clean historical metadata image  files"}),(0,d.jsx)(n.td,{children:"It should not fail. If it fails, manual intervention is required."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="success"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of times successful cleaning  of historical metadata image files"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_image_push"}),(0,d.jsx)(n.td,{children:'{type="failed"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of failures in pushing metadata image files to other FE nodes"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="success"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"metadata image files to other FE nodes"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_image_write"}),(0,d.jsx)(n.td,{children:'{type="failed"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Number of failures to  generate metadata image files"}),(0,d.jsx)(n.td,{children:"It should not fail. If it fails, manual intervention is required."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="success"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"the metadata image file was successfully  generated"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_job"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'Current count of different job types and different job statuses. For example, {job="load",  type="INSERT", state="LOADING"} represents an import job of type INSERT and the number of jobs in the LOADING state .'}),(0,d.jsx)(n.td,{children:"observe the number of different types of jobs in the cluster as needed"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_max_journal_id"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The maximum metadata log ID of the current FE node . If it is Master FE  , it is the maximum ID currently written , if it  is a non- Master FE , represents the maximum ID of the metadata log currently being played  back"}),(0,d.jsx)(n.td,{children:"Used to observe whether the ID gap between multiple FEs is too large. If it is too large, it indicates a problem with metadata  synchronization."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_max_tablet_compaction_score"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The largest compaction  score value among all BE nodes ."}),(0,d.jsx)(n.td,{children:"This value can be used to observe the maximum compaction score of the current cluster to determine whether it is too high. If it is too  high, query or write delays may occur."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_qps"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num/Sec"}),(0,d.jsx)(n.td,{children:"Current number of FE queries per second ( only query requests are counted )"}),(0,d.jsx)(n.td,{children:"QPS"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_query_err"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"value of error query"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_query_err_rate"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num/Sec"}),(0,d.jsx)(n.td,{children:"Error queries per second"}),(0,d.jsx)(n.td,{children:"Observe whether query errors occur in the cluster"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_query_latency_ms"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"millisecond"}),(0,d.jsx)(n.td,{children:'Percentile statistics of query request latency. For example, {quantile="0.75"}  indicates the query delay at the 75th percentile'}),(0,d.jsx)(n.td,{children:"Detailed observation of query latency in each quantile"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_query_latency_ms_db"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"millisecond"}),(0,d.jsx)(n.td,{children:'Percentile statistics of query request delay of each DB . For example, {quantile="0.75  ",db ="test"} indicates  the query delay of the  75th percentile of DB test'}),(0,d.jsx)(n.td,{children:"Observe the query latency of each DB in detail"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_query_olap_table"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"the statistics of the number of requests for the internal table ( OlapTable )"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_query_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"all query requests"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_report_queue_size"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The queue length of  various periodic reporting tasks of BE on the FE side"}),(0,d.jsx)(n.td,{children:"This value reflects the blocking degree of the reporting task on the Master FE node. The larger the value, the lower the processing capacity of the FE ."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_request_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"All operation requests received through the MySQL port (including  queries and other statements )"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_routine_load_error_rows"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Count the total number of error rows for all Routine Load jobs in the cluster"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_routine_load_receive_bytes"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"the amount of data received by all Routine Load jobs in the cluster"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_routine_load_rows"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Count the number of data rows received by all Routine Load jobs in the cluster"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_routine_load_get_meta_latency"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"millisecond"}),(0,d.jsx)(n.td,{children:"Total latency for retrieving metadata for all Routine Load Jobs across the cluster"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_routine_load_get_meta_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Total number of metadata retrieval operations for all Routine Load Jobs across the cluster"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_routine_load_get_meta_fail_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Total number of failed metadata retrieval operations for all Routine Load Jobs across the cluster"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_routine_load_task_execute_time"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"millisecond"}),(0,d.jsx)(n.td,{children:"Total execution time for all Routine Load Tasks across the cluster"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_routine_load_task_execute_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Total number of executed Routine Load Tasks across the cluster"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_routine_load_lag"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"millisecond"}),(0,d.jsx)(n.td,{children:"Total consumption lag for all Routine Load Jobs across the cluster"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_routine_load_progress"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"millisecond"}),(0,d.jsx)(n.td,{children:"Total consumption progress for all Routine Load Jobs across the cluster"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_routine_load_abort_task_num"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Total number of failed Routine Load Tasks across the cluster"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_rps"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"current number of FE requests per second (including queries and other types of statements )"}),(0,d.jsx)(n.td,{children:"Work with QPS to view the amount of requests processed by the cluster ."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_scheduled_tablet_num"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"tablets being scheduled by the Master FE node .  Includes replicas being repaired and replicas being balanced"}),(0,d.jsx)(n.td,{children:"tablets being migrated . If there is a value for a long time, it means the cluster is unstable."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_tablet_max_compaction_score"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'The compaction core reported by each BE node . For  example, { backend="172.21.0.1:9556"}  represents the reported value of BE "172.21.0.1:9556"'}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_tablet_num"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'current total number of tablets on each BE node . For  example, {backend="172.21.0.1:9556"}  indicates the current number  of tablets of the BE  "172.21.0.1:9556"'}),(0,d.jsx)(n.td,{children:"You can check whether the tablet distribution  is uniform and whether the absolute value is reasonable"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_tablet_status_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Statistics Master FE  node The cumulative value of the number of tablets scheduled  by the tablet scheduler ."}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="added"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'Statistics Master FE  node The cumulative value of the number of tablets scheduled  by the tablet scheduler . "added" indicates the number of tablets that have been scheduled'}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type=" in_sched  "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Same as above. Indicates the number of tablets that are scheduled repeatedly"}),(0,d.jsx)(n.td,{children:"If this value increases quickly, it means that a tablet has been  in an unhealthy state for a long time , causing it to be scheduled repeatedly by the scheduler."}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type=" not_ready  "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Same as above. Indicates the number of tablets that have not yet met the scheduling trigger conditions ."}),(0,d.jsx)(n.td,{children:"If this value increases quickly, it means that a large number of tablets are in an unhealthy state but cannot be scheduled."}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="total"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Same as above. Represents the cumulative number of tablets that have been  checked (but not necessarily scheduled) ."}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="unhealthy"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Same as above. Indicates the cumulative number of unhealthy tablets that have been  checked ."}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_thread_pool"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'Count the number of working threads and queuing status of various  thread pools . "active_thread_num" Indicates the number of tasks being  executed . "pool_size" Indicates the total number of threads in  the thread pool . "task_in_queue" Indicates the number of tasks being queued'}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name="agent-task-pool"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Master FE is used to send Agent Task to BE 's thread pool"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name="connect-scheduler-check-timer"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"pool for checking if MySQL idle connection has timed out"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name="connect-scheduler-pool"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"pool for receiving MySQL connection requests"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name=" mysql - nio  -pool"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"NIO MySQL Server thread pool for processing tasks"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name="export-exporting-job-pool"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"pool for export jobs in exporting state"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name="export-pending-job-pool"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"pool for export jobs in pending state"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name="heartbeat- mgr  -pool"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Master FE is used to process the thread pool of each node's heartbeat"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name="loading-load-task-scheduler"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Master FE is used to schedule Broker In Load job, loading Task scheduling thread pool"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name="pending-load-task-scheduler"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Master FE is used to schedule Broker Load job , pending Task scheduling thread pool"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name="schema-change-pool"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"pool used by Master FE  to schedule schema change jobs"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name="thrift-server-pool"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"worker thread pool of ThriftServer on the FE side . correspond fe.conf middle rpc_port . Used to interact with BE ."}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_txn_counter"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"value of the number of imported transactions in  each status"}),(0,d.jsx)(n.td,{children:"You can observe the execution of imported  transactions ."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="begin"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Number of transactions committed"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="failed"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Number of failed transactions"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="reject"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"rejected transactions . ( If the number of  currently running transactions is greater than the threshold, new  transactions will be rejected )"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type=" succes  "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"number of successful transactions"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_txn_status"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'Count the number of import transactions currently in various states.  For example, {type="committed"}  indicates the number of transactions in the committed state.'}),(0,d.jsx)(n.td,{children:"You can observe the number of imported transactions  in each state to determine whether there is accumulation."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_query_instance_num"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'Specifies the  fragment that the user is currently requesting Number of instances . For example, {user=" test_u "} represents  the user test_u The number of instances  currently being requested'}),(0,d.jsx)(n.td,{children:"This value can be used to observe whether the specified user takes up  too many query resources ."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_query_instance_begin"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'Specify the fragment where the  user request starts Number of instances . For example, {user=" test_u "} represents  the user test_u Number of instances  to start requesting'}),(0,d.jsx)(n.td,{children:"This value can be used to observe whether a given user has submitted  too many queries."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_query_rpc_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'of RPCs sent to the specified BE . For example, { be="192.168.10.1"}  indicates the number of RPCs sent to BE with IP address 192.168.10.1'}),(0,d.jsx)(n.td,{children:"This value can be used to observe whether too many RPCs are submitted to a certain BE ."}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_query_rpc_failed"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'RPC failures sent to the specified BE . For example, { be="192.168.10.1"} indicates the number of RPC failures sent to BE with IP address 192.168.10.1'}),(0,d.jsx)(n.td,{children:"This value can be used to observe whether a certain BE has RPC problems."}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_query_rpc_size"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'Specify the RPC data  size of BE . For  example, { be="192.168.10.1"}  indicates the number of RPC data bytes sent to BE with IP address 192.168.10.1'}),(0,d.jsx)(n.td,{children:"This value can be used to observe whether an excessively large RPC is submitted to a BE ."}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_txn_exec_latency_ms"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"millisecond"}),(0,d.jsx)(n.td,{children:'Percentile statistics of transaction execution time. For example, {quantile="0.75"}  indicates the 75th percentile transaction execution time'}),(0,d.jsx)(n.td,{children:"Observe the execution time of each digit transaction in detail"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_txn_publish_latency_ms"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"millisecond"}),(0,d.jsx)(n.td,{children:'Percentile statistics of transaction  publish time. For example, {quantile="0.75"}  indicates that the 75th percentile transaction publish time is'}),(0,d.jsx)(n.td,{children:"of the publishing time of each quantile transaction"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_txn_num"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'Specifies the number of transactions being performed by the DB . For example, { db ="test"} indicates the number of transactions currently being executed by DB test .'}),(0,d.jsx)(n.td,{children:"This value can be used to observe whether a certain DB has submitted a large number of transactions ."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_publish_txn_num"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'Specify the number of transactions being published by the DB . For example, { db ="test"}  indicates the number of  transactions currently being published by DB test .'}),(0,d.jsx)(n.td,{children:"This value can be used to observe the number of publish transactions  of a certain DB ."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_txn_replica_num"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'Specifies the number of replicas opened by the transaction being executed by the DB . For example, { db  ="test"} indicates the number of copies opened by the transaction currently being executed by DB test .'}),(0,d.jsx)(n.td,{children:"This value can be used to observe whether a certain DB has too many copies opened, which may affect the  execution of other transactions."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_thrift_rpc_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'RPC requests received by each method of the FE thrift interface . For example, {method="report"}  indicates the number of RPC requests received by the report method.'}),(0,d.jsx)(n.td,{children:"This value can observe a certain thrift rpc method payload"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_thrift_rpc_latency_ms"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"millisecond"}),(0,d.jsx)(n.td,{children:'The RPC requests received by each method of the FE thrift interface take time. For example, {method="report"}  indicates that the RPC request received by the report method takes  time.'}),(0,d.jsx)(n.td,{children:"This value can observe a certain thrift rpc method payload"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_external_schema_cache"}),(0,d.jsx)(n.td,{children:'{ catalog  ="hive"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"SpecifyExternal Catalog _ The number of corresponding schema  caches"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_fe_hive_meta_cache"}),(0,d.jsx)(n.td,{children:'{ catalog  ="hive"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type=" partition_value  "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Specify External Hive Metastore  Catalog The number of corresponding partition  value caches"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="partition"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Specify External Hive Metastore  Catalog The number of corresponding partition  caches"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="file"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Specify External Hive Metastore  Catalog The number of corresponding file  caches"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]})]})]}),"\n",(0,d.jsxs)(n.h3,{id:"jvm-metrics",children:[(0,d.jsx)(n.strong,{children:"JVM"})," ",(0,d.jsx)(n.strong,{children:"metrics"})]}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,d.jsxs)(n.table,{children:[(0,d.jsx)(n.thead,{children:(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"name"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Label"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"unit"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Description"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Impact"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Grade"})})]})}),(0,d.jsxs)(n.tbody,{children:[(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:(0,d.jsx)(n.code,{children:"jvm_heap_size_bytes"})}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"JVM memory metrics. The tags include max, used, committed , corresponding to the maximum value, used and requested memory  respectively."}),(0,d.jsx)(n.td,{children:"Observe JVM memory usage"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:(0,d.jsx)(n.code,{children:"jvm_non_heap_size_bytes"})}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"JVM off-heap memory statistics"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:(0,d.jsx)(n.code,{children:"<GarbageCollector>"})}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"GC metrics ."}),(0,d.jsx)(n.td,{children:"GarbageCollector refers to a specific garbage collector"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="count"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Cumulative value of GC times"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="time"}'}),(0,d.jsx)(n.td,{children:"millisecond"}),(0,d.jsx)(n.td,{children:"Cumulative value of GC time consumption"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:(0,d.jsx)(n.code,{children:"jvm_old_size_bytes"})}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"JVM old generation memory statistics"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:(0,d.jsx)(n.code,{children:"jvm_thread"})}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"JVM thread count statistics"}),(0,d.jsx)(n.td,{children:"Observe whether the number of JVM threads is reasonable"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:(0,d.jsx)(n.code,{children:"jvm_young_size_bytes"})}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"JVM new generation memory statistics"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"P0"})]})]})]}),"\n",(0,d.jsxs)(n.p,{children:[(0,d.jsx)(n.strong,{children:"Machine"})," ",(0,d.jsx)(n.strong,{children:"metrics"})]}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,d.jsxs)(n.table,{children:[(0,d.jsx)(n.thead,{children:(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"name"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Label"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"unit"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Description"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Impact"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Grade"})})]})}),(0,d.jsxs)(n.tbody,{children:[(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"system_meminfo"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"FE node machines. Collected from /proc/meminfo  . include buffers , cached , memory_available , memory_free  , memory_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"system_snmp"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"FE node machines. Collected from /proc/net/  snmp ."}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name=" tcp_in_errs  "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"tcp packet reception errors"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name=" tcp_in_segs  "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"tcp packets sent"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name=" tcp_out_segs  "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"tcp packets sent"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name=" tcp_retrans_segs  "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Number of tcp packet retransmissions"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]})]})]}),"\n",(0,d.jsxs)(n.p,{children:[(0,d.jsx)(n.strong,{children:"BE"})," ",(0,d.jsx)(n.strong,{children:"metrics metrics"})]}),"\n",(0,d.jsx)(n.p,{children:(0,d.jsx)(n.strong,{children:"Process metrics"})}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,d.jsxs)(n.table,{children:[(0,d.jsx)(n.thead,{children:(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"name"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Label"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"unit"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Description"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Impact"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"grade"})})]})}),(0,d.jsxs)(n.tbody,{children:[(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_active_scan_context_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"the number of scanners currently opened directly from the outside"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_add_batch_task_queue_size"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"When recording import, the queue size of the thread pool that receives the batch"}),(0,d.jsx)(n.td,{children:"If it is greater than 0 , it means there is a backlog at the receiving end of the import task."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"agent_task_queue_size"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'Display the length of each Agent Task processing queue, such as {type="CREATE_TABLE"} Indicates the length of the CREATE_TABLE task queue'}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_brpc_endpoint_stub_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Created _ The number of  brpc stubs used for interaction between BEs"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_brpc_function_endpoint_stub_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Created _ The number of brpc stubs used to interact with Remote RPC"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_cache_capacity"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Record the capacity of the specified LRU Cache"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_cache_usage"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Record the usage of the specified LRU Cache"}),(0,d.jsx)(n.td,{children:"Used to observe memory usage"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_cache_usage_ratio"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Record the usage of the specified LRU Cache"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_cache_lookup_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Record the number of times the specified LRU Cache is searched"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_cache_hit_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Record the number of hits in the  specified LRU Cache"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_cache_hit_ratio"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Record the hit rate of the specified LRU Cache"}),(0,d.jsx)(n.td,{children:"Used to observe whether the cache is effective"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name=" DataPageCache  "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"DataPageCache Data Page for caching data"}),(0,d.jsx)(n.td,{children:"Data Cache , directly affects query efficiency"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name="  IndexPageCache "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"IndexPageCache Index Page for caching data"}),(0,d.jsx)(n.td,{children:"Index Cache , directly affects query efficiency"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name="  LastestSuccessChannelCache "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"LastestSuccessChannelCache  Used to cache import receivers LoadChannel"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{name=" SegmentCache  "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"SegmentCache Used to cache turned on Segment , such as  index information"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_chunk_pool_local_core_alloc_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"ChunkAllocator , the number of times memory is allocated from  the memory queue of the bound core"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_chunk_pool_other_core_alloc_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"ChunkAllocator , the number of times memory is allocated from the memory queue of other cores"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_chunk_pool_reserved_bytes"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"ChunkAllocator The amount of memory reserved in"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_chunk_pool_system_alloc_cost_ns"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"nanosecond"}),(0,d.jsx)(n.td,{children:"SystemAllocator The  cumulative value of time spent applying for memory"}),(0,d.jsx)(n.td,{children:"The slope can be used to observe the time taken for memory allocation."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_chunk_pool_system_alloc_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"SystemAllocator Number of times to apply for memory"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_chunk_pool_system_free_cost_ns"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"nanosecond"}),(0,d.jsx)(n.td,{children:"SystemAllocator Cumulative  value of time taken to release memory"}),(0,d.jsx)(n.td,{children:"The slope can be used to observe the time it takes to release memory."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_chunk_pool_system_free_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"SystemAllocator The number of times memory is released"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_compaction_bytes_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"value of the amount of data processed by compaction"}),(0,d.jsx)(n.td,{children:"What is recorded is the input in the compaction task rowset The disk size . It can be observed through the slope rate of compaction"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="base"}'}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"Accumulated data volume of Base Compaction"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="cumulative"}'}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"The cumulative data volume of Cumulative Compaction"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_compaction_deltas_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"processed by compaction  rowset The cumulative value of the number"}),(0,d.jsx)(n.td,{children:"What is recorded is the input in the compaction task rowset of number"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="base"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Processed by Base  Compaction rowset Cumulative number"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="cumulative"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Processed by Cumulative  Compaction rowset Cumulative number"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_disks_compaction_num"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'compaction tasks being  executed on the specified data directory . like {path="/path1/"} means /path1 The number of tasks being executed on the  directory'}),(0,d.jsx)(n.td,{children:"Used to observe whether the number of compaction tasks on  each disk is reasonable."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_disks_compaction_score"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'Specifies the number of compaction tokens being executed on  the data directory. like {path="/path1/"} means /path1 Number of tokens being executed on the  directory'}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_compaction_used_permits"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of tokens used by the Compaction task"}),(0,d.jsx)(n.td,{children:"Used to reflect the resource consumption of Compaction"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_compaction_waitting_permits"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Compaction tokens awaiting"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_data_stream_receiver_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Number of data receiving terminals Receiver"}),(0,d.jsx)(n.td,{children:"FIXME : This indicator is missing for the vectorization engine"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_disks_avail_capacity"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:'Specify the remaining space on the disk where the specified data  directory is located. like {path="/path1/"} express /path1 The remaining space on the disk where the directory is located'}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_disks_local_used_capacity"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"the specified data directory is located"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_disks_remote_used_capacity"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"the specified data directory is located"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_disks_state"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Boolean"}),(0,d.jsx)(n.td,{children:"Specifies the disk status of the data directory . 1 means normal. 0 means abnormal"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_disks_total_capacity"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"capacity of the disk where the specified data directory is located"}),(0,d.jsx)(n.td,{children:"Cooperate doris_be_disks_avail_capacity Calculate disk usage"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_engine_requests_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"value of various task execution  statuses on BE"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{status=" failed  ",type ="xxx"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"value of the number of failures for tasks of type xxx"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{status=" total  ",type ="xxx"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The cumulative value of the total number of tasks of type xxx ."}),(0,d.jsx)(n.td,{children:"Can monitor the number of failures of various  tasks on demand"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{status=" skip  ",type =" report_all_tablets "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"value of the number of times xxx type tasks have been skipped"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_fragment_endpoint_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"same"}),(0,d.jsx)(n.td,{children:"FIXME: Same as doris_be_data_stream_receiver_count number. And the vectorization engine is missing"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_fragment_request_duration_us"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"microseconds"}),(0,d.jsx)(n.td,{children:"All fragment intance The cumulative execution time of"}),(0,d.jsx)(n.td,{children:"the execution time of instance through slope"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_fragment_requests_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The cumulative number of executed fragment instances"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_load_channel_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of load  channels currently open"}),(0,d.jsx)(n.td,{children:"The larger the value , the more import tasks are currently being executed."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_local_bytes_read_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"Depend on LocalFileReader Number of bytes read"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_local_bytes_written_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"Depend on LocalFileWriter Number of bytes written"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_local_file_reader_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"opened LocalFileReader Cumulative count of"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_local_file_open_reading"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"currently open LocalFileReader number"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_local_file_writer_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"opened LocalFileWriter cumulative count ."}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_mem_consumption"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:'Specifies the current memory overhead of the module . For example, {type="compaction"}  represents the current total memory overhead of the compaction module .'}),(0,d.jsx)(n.td,{children:"Values taken from the same type MemTracker . FIXME"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_memory_allocated_bytes"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"BE process physical memory size, taken from /proc/self/status/ VmRSS"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_memory_jemalloc"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"Jemalloc stats, taken from je_mallctl ."}),(0,d.jsxs)(n.td,{children:[(0,d.jsx)(n.a,{href:"https://jemalloc.net/jemalloc.3.html",children:"Meaning"}),"reference : ",(0,d.jsx)(n.a,{href:"https://jemalloc.net/jemalloc.3.html",children:"https://jemalloc.net/jemalloc.3.html"})]}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_memory_pool_bytes_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"all MemPool The size of memory currently occupied. Statistical value, does not represent actual memory usage ."}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_memtable_flush_duration_us"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"microseconds"}),(0,d.jsx)(n.td,{children:"value of the time taken to write memtable to disk"}),(0,d.jsx)(n.td,{children:"Write latency can be observed via slope"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_memtable_flush_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"number of memtable writes to disk"}),(0,d.jsx)(n.td,{children:"The slope can be used to calculate the frequency of writing to a file"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_meta_request_duration"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"microseconds"}),(0,d.jsx)(n.td,{children:"access RocksDB The cumulative time consumption of meta in"}),(0,d.jsx)(n.td,{children:"BE metadata read and write latency through  slope"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="read"}'}),(0,d.jsx)(n.td,{children:"microseconds"}),(0,d.jsx)(n.td,{children:"Reading time"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="write"}'}),(0,d.jsx)(n.td,{children:"microseconds"}),(0,d.jsx)(n.td,{children:"Writing time"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_meta_request_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"access RocksDB The cumulative number of meta in"}),(0,d.jsx)(n.td,{children:"BE metadata access frequency by slope"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="read"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Read times"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:'{type="write"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Number of writes"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_fragment_instance_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of fragment  instances currently received"}),(0,d.jsx)(n.td,{children:"Observe whether instance accumulation occurs"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_process_fd_num_limit_hard"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"BE process. pass /proc/ pid /limits collection"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_process_fd_num_limit_soft"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"BE process. pass /proc/ pid /limits collection"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_process_fd_num_used"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of file handles used by the BE process. pass /proc/ pid /limits collection"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_process_thread_num"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"BE process threads. pass /proc/  pid /task collection"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_query_cache_memory_total_byte"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"Number of bytes occupied by Query Cache"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_query_cache_partition_total_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"current number of Partition Cache caches"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_query_cache_sql_total_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Current number of SQL Cache caches"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_query_scan_bytes"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"Read the cumulative value of the data amount. Here we only count reads Olap The amount of data in the table"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_query_scan_bytes_per_second"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Bytes / second"}),(0,d.jsx)(n.td,{children:"according to doris_be_query_scan_bytes Calculated read rate"}),(0,d.jsx)(n.td,{children:"Observe query rate"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_query_scan_rows"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Read the cumulative value of the number of rows. Here we only count  reads Olap The amount of data in the table. and is RawRowsRead (Some data rows may be skipped by the index and not actually read, but  will still be recorded in this value )"}),(0,d.jsx)(n.td,{children:"Query rate by slope observation"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_result_block_queue_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of fragment  instances in the  current query result cache"}),(0,d.jsx)(n.td,{children:"This queue is only used when being read directly by an external  system. For example, Spark on  Doris queries data through external scan."}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_result_buffer_block_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of queries in the current query result cache"}),(0,d.jsx)(n.td,{children:"This value reflects how many query results are currently waiting for FE consumption  in BE ."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_routine_load_task_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of routine  load tasks currently being executed"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_rowset_count_generated_and_in_use"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"New and in use since the last  startup The number of rowset  ids ."}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_s3_bytes_read_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"S3FileReader The cumulative number of opens"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_s3_file_open_reading"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"currently open S3FileReader number"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_s3_bytes_read_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"S3FileReader Read the cumulative value of bytes"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_scanner_thread_pool_queue_size"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"used for OlapScanner The current queued number of thread pools"}),(0,d.jsx)(n.td,{children:"it is greater than zero , it means that Scanner starts to accumulate."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_segment_read"}),(0,d.jsx)(n.td,{children:'{type="  segment_read_total "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Cumulative value of the number of segments read"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_segment_read"}),(0,d.jsx)(n.td,{children:'{type=" segment_row_total  "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"value of the number of rows in the segment read"}),(0,d.jsx)(n.td,{children:"This value also includes the number of rows filtered by the index.  Equivalent to the number of segments read * the total number of rows in each segment"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_send_batch_thread_pool_queue_size"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of queues in the thread pool used to send data packets when  importing"}),(0,d.jsx)(n.td,{children:"it is greater than 0 , it means there is accumulation"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_send_batch_thread_pool_thread_num"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of threads in the thread pool  used to send packets when importing"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_small_file_cache_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"currently cached by BE"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_streaming_load_current_processing"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Number of stream  load tasks currently running"}),(0,d.jsx)(n.td,{children:"Contains only tasks sent by the curl command"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_streaming_load_duration_ms"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"millisecond"}),(0,d.jsx)(n.td,{children:"The cumulative value of  the execution time of all stream load tasks"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_streaming_load_requests_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"value of the number of stream load tasks"}),(0,d.jsx)(n.td,{children:"Observable task submission frequency via slope"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_stream_load_pipe_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"current stream load data pipelines"}),(0,d.jsx)(n.td,{children:"Including stream  load and routine load tasks"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_stream_load"}),(0,d.jsx)(n.td,{children:'{type=" load_rows  "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"number of rows finally imported by stream load"}),(0,d.jsx)(n.td,{children:"Including stream  load and routine load tasks"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_stream_load"}),(0,d.jsx)(n.td,{children:'{type=" receive_bytes  "}'}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"value of the number of bytes  received by stream load"}),(0,d.jsx)(n.td,{children:"Including stream  load data received from http , and routine load from kafka read data"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_tablet_base_max_compaction_score"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The current largest Base Compaction Score"}),(0,d.jsx)(n.td,{children:"This value changes in real time, and peak data may be lost. The higher  the value, the more serious the compaction accumulation is ."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_tablet_cumulative_max_compaction_score"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Same as above. Current largest Cumulative Compaction Score"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_tablet_version_num_distribution"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The histogram of the number of tablet versions ."}),(0,d.jsx)(n.td,{children:"Distribution used to reflect the number of tablet versions"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_thrift_connections_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'thrift connections created . like {name="heartbeat"} Indicates the cumulative number of connections to the heartbeat  service'}),(0,d.jsx)(n.td,{children:"This value is the connection of thrift server with BE as the server."}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_thrift_current_connections"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'current number of thrift connections. like {name="heartbeat"} Indicates the current number  of connections to the heartbeat service .'}),(0,d.jsx)(n.td,{children:"Same as above"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_thrift_opened_clients"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'thrift clients currently open . like {name="frontend"} Indicates the number of clients accessing the FE service'}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_thrift_used_clients"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'thrift clients currently in use . like {name="frontend"} Indicates the number of clients being used to access the FE service'}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_timeout_canceled_fragment_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Cumulative value of the number of fragment instances  canceled due to timeout"}),(0,d.jsx)(n.td,{children:"This value may be recorded repeatedly. For example, some fragment instances are canceled multiple times"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_stream_load_txn_request"}),(0,d.jsx)(n.td,{children:'{type="begin"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"value of the number of transactions  started by stream load"}),(0,d.jsx)(n.td,{children:"Including stream  load and routine load tasks"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_stream_load_txn_request"}),(0,d.jsx)(n.td,{children:'{type="commit"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"value of the number of transactions successfully  executed by stream load"}),(0,d.jsx)(n.td,{children:"Same as above"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_stream_load_txn_request"}),(0,d.jsx)(n.td,{children:'{type="rollback"}'}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"value of the number of transactions that failed to  execute stream load"}),(0,d.jsx)(n.td,{children:"Same as above"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_unused_rowsets_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of currently abandoned rowsets"}),(0,d.jsx)(n.td,{children:"These rowsets will be deleted regularly under normal  circumstances."}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_upload_fail_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"cumulative value of rowset failed to be uploaded to remote storage"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_upload_rowset_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"cumulative number of rowsets successfully uploaded to remote storage"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_upload_total_byte"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"value of rowset data successfully uploaded to remote storage"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_load_bytes"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"Cumulative quantity sent through tablet sink"}),(0,d.jsx)(n.td,{children:"Observable amount of imported data"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_load_rows"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Cumulative number of rows sent through tablet sink"}),(0,d.jsx)(n.td,{children:"Observable amount of imported data"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"fragment_thread_pool_queue_size"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"current query execution thread pool waiting queue"}),(0,d.jsx)(n.td,{children:"If it is greater than zero, the query  thread has been exhausted and queries will pile up."}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_all_rowsets_num"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"All currently rowset number of"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_all_segments_num"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of all current segments"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_heavy_work_max_threads"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"brpc Number of heavy thread pool threads"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"p0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_light_work_max_threads"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"brpc Number of light thread pool threads"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"p0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_heavy_work_pool_queue_size"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"brpc The maximum length of  the heavy thread pool queue will block the submission  of work if it exceeds it ."}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"p0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_light_work_pool_queue_size"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"brpc The maximum length of  the light thread pool queue . If it exceeds the maximum  length, the submission of work will be blocked."}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"p0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_heavy_work_active_threads"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"brpc Number of active threads in heavy thread pool"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"p0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_light_work_active_threads"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"brpc Number of active threads in light thread pool"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"p0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"routine_load_get_msg_latency"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"millisecond"}),(0,d.jsx)(n.td,{children:"Latency for retrieving Kafka messages for Routine Load"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"routine_load_get_msg_count"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Number of Kafka messages retrieved by Routine Load"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"routine_load_consume_bytes"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"Amount of Kafka data consumed by Routine Load"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"routine_load_consume_rows"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Number of Kafka messages consumed by Routine Load"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]})]})]}),"\n",(0,d.jsxs)(n.p,{children:[(0,d.jsx)(n.strong,{children:"Machine"})," ",(0,d.jsx)(n.strong,{children:"metrics"})]}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,d.jsxs)(n.table,{children:[(0,d.jsx)(n.thead,{children:(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"name"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Label"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"unit"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Description"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Impact"})}),(0,d.jsx)(n.th,{children:(0,d.jsx)(n.strong,{children:"Grade"})})]})}),(0,d.jsxs)(n.tbody,{children:[(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_cpu"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'CPU related metrics metrics, from /proc/stat collection. Each value of each logical core will be collected  separately . like {device="cpu0  ",mode ="nice"} Indicates the nice value of cpu0'}),(0,d.jsx)(n.td,{children:"CPU usage can be calculated"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_disk_bytes_read"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:'The cumulative value of disk reads. from /proc/ diskstats collection. The values of each  disk will be collected separately . like {device=" vdd "} express vvd disk value'}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_disk_bytes_written"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"The cumulative value of disk writes. The collection method is the same  as above"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_disk_io_time_ms"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"The collection method is the same as above"}),(0,d.jsx)(n.td,{children:"IO Util can be calculated"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_disk_io_time_weighted"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"The collection method is the same as above"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_disk_reads_completed"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"The collection method is the same as above"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_disk_read_time_ms"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"The collection method is the same as above"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_disk_writes_completed"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"The collection method is the same as above"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_disk_write_time_ms"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"The collection method is the same as above"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_fd_num_limit"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"System file handle limit upper limit. from /proc/sys/fs/file-nr collection"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_fd_num_used"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of file handles used by the system . from /proc/sys/fs/file-nr collection"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_file_created_total"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"Cumulative number of local  file creation times"}),(0,d.jsx)(n.td,{children:"all calls local_file_writer And finally close the file count"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_load_average"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:'Machine Load Avg Metric metrics. For example, {mode="15_minutes"} is 15 minutes Load Avg'}),(0,d.jsx)(n.td,{children:"Observe the overall machine load"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_max_disk_io_util_percent"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"percentage"}),(0,d.jsx)(n.td,{children:"value of the disk with the largest IO UTIL  among all disks"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_max_network_receive_bytes_rate"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Bytes / second"}),(0,d.jsx)(n.td,{children:"The maximum receive rate calculated among all network cards"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_max_network_send_bytes_rate"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Bytes / second"}),(0,d.jsx)(n.td,{children:"The calculated maximum sending rate among all network cards"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_memory_pgpgin"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"The amount of data written by the system  from disk to memory page"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_memory_pgpgout"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"The amount of data written to disk by  system memory pages"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_memory_pswpin"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"The number of times the system swapped from disk to memory"}),(0,d.jsx)(n.td,{children:"Normally, swap should be turned off, so this value should be 0"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_memory_pswpout"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"The number of times the system swapped from memory to disk"}),(0,d.jsx)(n.td,{children:"Normally, swap should be turned off, so this value should be 0"}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_network_receive_bytes"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"each network card are accumulated. Collected  from /proc/net/dev"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_network_receive_packets"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"each network card is accumulated. Collected  from /proc/net/dev"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_network_send_bytes"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"byte"}),(0,d.jsx)(n.td,{children:"each network card . Collected from /proc/net/dev"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_network_send_packets"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The total number of packets sent by each network card is accumulated. Collected from /proc/net/dev"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_proc"}),(0,d.jsx)(n.td,{children:'{mode=" ctxt_switch  "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"CPU context switches . Collected from /proc/stat"}),(0,d.jsx)(n.td,{children:"Observe whether there are abnormal context switches"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_proc"}),(0,d.jsx)(n.td,{children:'{mode="interrupt"}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"CPU interrupts . Collected from /proc/stat"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_proc"}),(0,d.jsx)(n.td,{children:'{mode=" procs_blocked  "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of processes currently blocked in the system (such as  waiting for IO ). Collected from /proc/stat"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_proc"}),(0,d.jsx)(n.td,{children:'{mode=" procs_running  "}'}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"The number of processes currently executing on the system . Collected  from /proc/stat"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_snmp_tcp_in_errs"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"tcp packet reception errors. Collected from /proc/net/ snmp"}),(0,d.jsx)(n.td,{children:"Observable network errors such as  retransmission, packet loss, etc. Need and other snmp metrics used together  with"}),(0,d.jsx)(n.td,{children:"P0"})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_snmp_tcp_in_segs"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"tcp packets sent . Collected from /proc/net/ snmp"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_snmp_tcp_out_segs"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"tcp packets sent. Collected from /proc/net/ snmp"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]}),(0,d.jsxs)(n.tr,{children:[(0,d.jsx)(n.td,{children:"doris_be_snmp_tcp_retrans_segs"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{children:"Num"}),(0,d.jsx)(n.td,{children:"TCP packet retransmissions . Collected from /proc/net/ snmp"}),(0,d.jsx)(n.td,{}),(0,d.jsx)(n.td,{})]})]})]})]})}function x(e={}){let{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,d.jsx)(n,{...e,children:(0,d.jsx)(o,{...e})}):o(e)}},250065:function(e,n,t){t.d(n,{Z:function(){return c},a:function(){return i}});var s=t(667294);let d={},r=s.createContext(d);function i(e){let n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(d):e.components||d:i(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);