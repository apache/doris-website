"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["506868"],{903457:function(e,t,n){n.r(t),n.d(t,{default:()=>h,frontMatter:()=>c,metadata:()=>a,assets:()=>l,toc:()=>o,contentTitle:()=>r});var a=JSON.parse('{"id":"compute-storage-decoupled/file-cache/file-cache","title":"File Cache","description":"In a decoupled architecture, data is stored in remote storage. The Doris database accelerates data access by utilizing a cache on local disks and employs an advanced multi-queue LRU (Least Recently Used) strategy to efficiently manage cache space. This strategy particularly optimizes the access paths for indexes and metadata, aiming to maximize the caching of frequently accessed user data. For multi-compute group (Compute Group) scenarios, Doris also provides a cache warming feature to quickly load specific data (such as tables or partitions) into the cache when a new compute group is established, thereby enhancing query performance.","source":"@site/docs/compute-storage-decoupled/file-cache/file-cache.md","sourceDirName":"compute-storage-decoupled/file-cache","slug":"/compute-storage-decoupled/file-cache/","permalink":"/docs/dev/compute-storage-decoupled/file-cache/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"File Cache","language":"en"},"sidebar":"docs","previous":{"title":"Managing Compute Groups","permalink":"/docs/dev/compute-storage-decoupled/managing-compute-cluster"},"next":{"title":"File Cache Internals","permalink":"/docs/dev/compute-storage-decoupled/file-cache/file-cache-internals"}}'),i=n("785893"),s=n("250065");let c={title:"File Cache",language:"en"},r=void 0,l={},o=[{value:"Role of Cache",id:"role-of-cache",level:2},{value:"Cache Configuration",id:"cache-configuration",level:2},{value:"Cache Warm Up",id:"cache-warm-up",level:2},{value:"Cache Cleanup",id:"cache-cleanup",level:2},{value:"Cache Observation",id:"cache-observation",level:2},{value:"Hotspot Information",id:"hotspot-information",level:3},{value:"Viewing the Most Frequently Accessed Tables Across All Compute Groups",id:"viewing-the-most-frequently-accessed-tables-across-all-compute-groups",level:4},{value:"Viewing the Most Frequently Accessed Tables Under a Specific Compute Group",id:"viewing-the-most-frequently-accessed-tables-under-a-specific-compute-group",level:4},{value:"Viewing the Most Frequently Accessed Partitions for a Specific Compute Group and Table",id:"viewing-the-most-frequently-accessed-partitions-for-a-specific-compute-group-and-table",level:4},{value:"Cache Space and Hit Rate",id:"cache-space-and-hit-rate",level:3},{value:"SQL Profile",id:"sql-profile",level:3},{value:"TTL Usage",id:"ttl-usage",level:2},{value:"Practical Case",id:"practical-case",level:2}];function d(e){let t={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.p,{children:"In a decoupled architecture, data is stored in remote storage. The Doris database accelerates data access by utilizing a cache on local disks and employs an advanced multi-queue LRU (Least Recently Used) strategy to efficiently manage cache space. This strategy particularly optimizes the access paths for indexes and metadata, aiming to maximize the caching of frequently accessed user data. For multi-compute group (Compute Group) scenarios, Doris also provides a cache warming feature to quickly load specific data (such as tables or partitions) into the cache when a new compute group is established, thereby enhancing query performance."}),"\n",(0,i.jsx)(t.h2,{id:"role-of-cache",children:"Role of Cache"}),"\n",(0,i.jsx)(t.p,{children:"In a decoupled architecture, data is typically stored in remote storage systems, such as object storage S3, HDFS, etc. In this scenario, the Doris database can leverage local disk space as a cache to store some data locally, thereby reducing the frequency of access to remote storage,improving data access efficiency, and lowering operating costs."}),"\n",(0,i.jsx)(t.p,{children:"Remote storage (such as object storage) usually has higher access latency and may be subject to constraints of QPS (queries per second) and bandwidth limits. For example, QPS limits on object storage can cause bottlenecks during high-concurrency queries, while network bandwidth limits can affect data transfer speeds. By using local file caching, Doris can store hot data on local disks, thereby significantly reducing query latency and enhancing query performance."}),"\n",(0,i.jsx)(t.p,{children:"On the other hand, object storage services typically charge based on the number of requests and the amount of data transferred. Frequent access and large volumes of data downloads can increase query costs. Through caching mechanisms, the number of accesses and the amount of data transferred to object storage can be reduced, thereby lowering costs."}),"\n",(0,i.jsx)(t.p,{children:"Doris's file cache typically caches the following two types of files in a decoupled architecture:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"Segment data files: The basic unit of data storage in Doris's internal tables. Caching these files can accelerate data read operations and enhance query performance."}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"Inverted index files: Used to accelerate filtering operations in queries.By caching these files, data that meets query conditions can be located more quickly, further improving query efficiency and supporting complex query scenarios."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"cache-configuration",children:"Cache Configuration"}),"\n",(0,i.jsx)(t.p,{children:"Doris provides a range of configuration options to help users manage file caching flexibly. These configuration options include enabling/disabling caching, setting cache paths and sizes, configuring cache block sizes,enabling/disabling automatic cleanup,and pre-eviction mechanisms, among others. The detailed configuration instructions are as follows:"}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsx)(t.li,{children:"Enabling File Cache"}),"\n"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-plaintext",children:'enable_file_cache Default: "false"\n'})}),"\n",(0,i.jsxs)(t.p,{children:["Parameter Description: This configuration item controls whether the file cache function is enabled. If set to",(0,i.jsx)(t.code,{children:"true"}),", file caching is enabled; if set to",(0,i.jsx)(t.code,{children:"false"}),", file caching is disabled."]}),"\n",(0,i.jsxs)(t.ol,{start:"2",children:["\n",(0,i.jsx)(t.li,{children:"Configuring File Cache Paths and Sizes"}),"\n"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-plaintext",children:"file_cache_path Default: storage directory under the BE deployment path\n"})}),"\n",(0,i.jsx)(t.p,{children:"Parameter Description: This configuration item specifies the path and size of the file cache. The format is a JSON array, with each element being a JSON object containing the following fields:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"path"}),": The path where cache files are stored."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"total_size"}),": The total size of the cache under this path (in bytes)."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"ttl_percent"}),": The proportion of the TTL queue(as a percentage)."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"normal_percent"}),": The proportion of the Normal queue(as a percentage)."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"disposable_percent"}),": The proportion of the Disposable queue (as a percentage)."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"index_percent"}),": The proportion of the Index queue (as a percentage)."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"storage"}),": The type of cache storage,which can be",(0,i.jsx)(t.code,{children:"disk"}),"or",(0,i.jsx)(t.code,{children:"memory"}),". The default value is",(0,i.jsx)(t.code,{children:"disk"}),"."]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"Example:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Single-path configuration:"}),"\n"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-json",children:'[{"path":"/path/to/file_cache","total_size":21474836480}]\n'})}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Multi-path configuration:"}),"\n"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-json",children:'[{"path":"/path/to/file_cache","total_size":21474836480},{"path":"/path/to/file_cache2","total_size":21474836480}]\n'})}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Memory storage configuration:"}),"\n"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-json",children:'[{"path": "xxx", "total_size":53687091200, "storage": "memory"}]\n'})}),"\n",(0,i.jsxs)(t.ol,{start:"3",children:["\n",(0,i.jsx)(t.li,{children:"Automatic Cache Cleanup"}),"\n"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-plaintext",children:'clear_file_cache Default: "false"\n'})}),"\n",(0,i.jsxs)(t.p,{children:["Parameter Description: This configuration item controls whether to automatically clear cached data when BE restarts. If set to",(0,i.jsx)(t.code,{children:"true"}),", the cache will be automatically cleared each time BE restarts; if set to",(0,i.jsx)(t.code,{children:"false"}),", the cache will not be automatically cleared."]}),"\n",(0,i.jsxs)(t.ol,{start:"4",children:["\n",(0,i.jsx)(t.li,{children:"Pre-eviction Mechanism"}),"\n"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-plaintext",children:'enable_evict_file_cache_in_advance Default: "true"\n'})}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["Parameter Description: This configuration item controls whether the pre-eviction mechanism is enabled. If set to",(0,i.jsx)(t.code,{children:"true"}),", when the cache space reaches a certain threshold, the system will proactively perform pre-eviction to free up space for future queries; if set to",(0,i.jsx)(t.code,{children:"false"}),", pre-eviction will not be performed."]}),"\n"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-plaintext",children:'file_cache_enter_need_evict_cache_in_advance_percent Default: "88"\n'})}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Parameter Description: This configuration item sets the threshold percentage for triggering pre-eviction. When the cache space/inode count reaches this percentage, the system begins pre-eviction."}),"\n"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-plaintext",children:'file_cache_exit_need_evict_cache_in_advance_percent Default: "85"\n'})}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Parameter Description: This configuration item sets the threshold percentage for stopping pre-eviction. When the cache space drops to this percentage,the system stops pre-eviction."}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"cache-warm-up",children:"Cache Warm Up"}),"\n",(0,i.jsx)(t.p,{children:"Doris provides a cache warming feature that allows users to actively pull data from remote storage into the local cache. This feature supports the following three modes:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Inter-Compute Group Warming"}),": Warm the cache data of Compute Group A to Compute Group B. Doris periodically collects hotspot information of tables/partitions accessed in each compute group over a period and selectively warms certain tables/partitions based on this information."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Table Data Warming"}),": Specify to warm the data of Table A to the new compute group."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Partition Data Warming"}),": Specify to warm the data of partition ",(0,i.jsx)(t.code,{children:"p1"})," of Table A to the new compute group."]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["For specific usage, please refer to the",(0,i.jsx)(t.a,{href:"#",children:"WARM-UP SQL documentation"}),"."]}),"\n",(0,i.jsx)(t.h2,{id:"cache-cleanup",children:"Cache Cleanup"}),"\n",(0,i.jsx)(t.p,{children:"Doris provides both synchronous and asynchronous cleanup methods:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["Synchronous Cleanup:The command is",(0,i.jsx)(t.code,{children:"curl 'http://BE_IP:WEB_PORT/api/file_cache?op=clear&sync=true'"}),". When the command returns, it indicates that the cleanup is complete.When Doris needs to clear the cache immediately, it will synchronously delete the cache files in the local file system directory and clean up the management metadata in memory. This method can quickly free up space but may have a certain impact on the efficiency of ongoing queries and even system stability. It is usually used for quick testing."]}),"\n",(0,i.jsxs)(t.li,{children:["Asynchronous Cleanup: The command is",(0,i.jsx)(t.code,{children:"curl 'http://BE_IP:WEB_PORT/api/file_cache?op=clear&sync=false'"}),". The command returns immediately,and the cleanup steps are executed asynchronously. During asynchronous cleanup, Doris traverses the management metadata in memory and deletes the corresponding cache files one by one. If it finds that some cache files are being used by queries, Doris will delay the deletion of these files until they are no longer in use. This method can reduce the impact on ongoing queries but usually takes longer to completely clean up the cache compared to synchronous cleanup."]}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"cache-observation",children:"Cache Observation"}),"\n",(0,i.jsx)(t.h3,{id:"hotspot-information",children:"Hotspot Information"}),"\n",(0,i.jsx)(t.p,{children:"Doris collects cache hotspot information for each compute group every 10 minutes and stores it in an internal system table. You can view this hotspot information using query statements. Users can better plan their cache usage based on this information."}),"\n",(0,i.jsx)(t.admonition,{title:"Note",type:"info",children:(0,i.jsxs)(t.p,{children:["Before version 3.0.4, the ",(0,i.jsx)(t.code,{children:"SHOW CACHE HOTSPOT"})," statement could be used to query cache hotspot information statistics. Starting from version 3.0.4, the ",(0,i.jsx)(t.code,{children:"SHOW CACHE HOTSPOT"})," statement is no longer supported for querying cache hotspot information statistics. Please directly query the system table ",(0,i.jsx)(t.code,{children:"__internal_schema.cloud_cache_hotspot"}),"."]})}),"\n",(0,i.jsx)(t.p,{children:"Users typically focus on cache usage information at two levels: compute groups and database tables. The following provides some commonly used query statements and examples."}),"\n",(0,i.jsx)(t.h4,{id:"viewing-the-most-frequently-accessed-tables-across-all-compute-groups",children:"Viewing the Most Frequently Accessed Tables Across All Compute Groups"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-sql",children:'-- Equivalent to SHOW CACHE HOTSPOT "/" before version 3.0.4\nWITH t1 AS (\n  SELECT\n    cluster_id,\n    cluster_name,\n    table_id,\n    table_name,\n    insert_day,\n    SUM(query_per_day) AS query_per_day_total,\n    SUM(query_per_week) AS query_per_week_total\n  FROM __internal_schema.cloud_cache_hotspot\n  GROUP BY cluster_id, cluster_name, table_id, table_name, insert_day\n)\nSELECT\n  cluster_id AS ComputeGroupId,\n  cluster_name AS ComputeGroupName,\n  table_id AS TableId,\n  table_name AS TableName\nFROM (\n  SELECT\n    ROW_NUMBER() OVER (\n      PARTITION BY cluster_id\n      ORDER BY insert_day DESC, query_per_day_total DESC, query_per_week_total DESC\n    ) AS dr2,\n    *\n  FROM t1\n) t2\nWHERE dr2 = 1;\n'})}),"\n",(0,i.jsx)(t.h4,{id:"viewing-the-most-frequently-accessed-tables-under-a-specific-compute-group",children:"Viewing the Most Frequently Accessed Tables Under a Specific Compute Group"}),"\n",(0,i.jsxs)(t.p,{children:["Viewing the most frequently accessed tables under compute group ",(0,i.jsx)(t.code,{children:"compute_group_name0"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:["Note: Replace the condition ",(0,i.jsx)(t.code,{children:'cluster_name = "compute_group_name0"'})," with the actual compute group name."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-sql",children:'-- Equivalent to SHOW CACHE HOTSPOT \'/compute_group_name0\' before version 3.0.4\nWITH t1 AS (\n  SELECT\n    cluster_id,\n    cluster_name,\n    table_id,\n    table_name,\n    insert_day,\n    SUM(query_per_day) AS query_per_day_total,\n    SUM(query_per_week) AS query_per_week_total\n  FROM __internal_schema.cloud_cache_hotspot\n  WHERE cluster_name = "compute_group_name0" -- Replace with the actual compute group name, e.g., "default_compute_group"\n  GROUP BY cluster_id, cluster_name, table_id, table_name, insert_day\n)\nSELECT\n  cluster_id AS ComputeGroupId,\n  cluster_name AS ComputeGroupName,\n  table_id AS TableId,\n  table_name AS TableName\nFROM (\n  SELECT\n    ROW_NUMBER() OVER (\n      PARTITION BY cluster_id\n      ORDER BY insert_day DESC, query_per_day_total DESC, query_per_week_total DESC\n    ) AS dr2,\n    *\n  FROM t1\n) t2\nWHERE dr2 = 1;\n'})}),"\n",(0,i.jsx)(t.h4,{id:"viewing-the-most-frequently-accessed-partitions-for-a-specific-compute-group-and-table",children:"Viewing the Most Frequently Accessed Partitions for a Specific Compute Group and Table"}),"\n",(0,i.jsxs)(t.p,{children:["Viewing the most frequently accessed partitions for table ",(0,i.jsx)(t.code,{children:"regression_test_cloud_load_copy_into_tpch_sf1_p1.customer"})," under compute group ",(0,i.jsx)(t.code,{children:"compute_group_name0"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:["Note: Replace the conditions ",(0,i.jsx)(t.code,{children:'cluster_name = "compute_group_name0"'})," and ",(0,i.jsx)(t.code,{children:'table_name = "regression_test_cloud_load_copy_into_tpch_sf1_p1.customer"'})," with the actual compute group name and database table name."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-sql",children:'-- Equivalent to SHOW CACHE HOTSPOT \'/compute_group_name0/regression_test_cloud_load_copy_into_tpch_sf1_p1.customer\' before version 3.0.4\nSELECT\n  partition_id AS PartitionId,\n  partition_name AS PartitionName\nFROM __internal_schema.cloud_cache_hotspot\nWHERE\n  cluster_name = "compute_group_name0" -- Replace with the actual compute group name, e.g., "default_compute_group"\n  AND table_name = "regression_test_cloud_load_copy_into_tpch_sf1_p1.customer" -- Replace with the actual database table name, e.g., "db1.t1"\nGROUP BY\n  cluster_id,\n  cluster_name,\n  table_id,\n  table_name,\n  partition_id,\n  partition_name;\n'})}),"\n",(0,i.jsx)(t.h3,{id:"cache-space-and-hit-rate",children:"Cache Space and Hit Rate"}),"\n",(0,i.jsxs)(t.p,{children:["Doris BE nodes can obtain cache statistics by using ",(0,i.jsx)(t.code,{children:"curl {be_ip}:{brpc_port}/vars"})," (where brpc_port defaults to 8060), and the names of the metrics start with the disk path."]}),"\n",(0,i.jsxs)(t.p,{children:['In the above example, the metric prefix for File Cache is the path, for example, the prefix "',(0,i.jsx)(t.em,{children:"mnt_disk1_gavinchou_debug_doris_cloud_be0_storage_file_cache"}),'" indicates "/mnt/disk1/gavinchou/debug/doris-cloud/be0_storage_file_cache/"\nThe part after the prefix is the statistical metric, for example, "file_cache_cache_size" indicates that the current size of the File Cache at this path is 26111 bytes.']}),"\n",(0,i.jsx)(t.p,{children:"The following table lists the meanings of all metrics (all size units are in bytes):"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:"Metric Name (excluding path prefix)"}),(0,i.jsx)(t.th,{children:"Meaning"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_cache_size"}),(0,i.jsx)(t.td,{children:"Current total size of the File Cache"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_disposable_queue_cache_size"}),(0,i.jsx)(t.td,{children:"Current size of the disposable queue"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_disposable_queue_element_count"}),(0,i.jsx)(t.td,{children:"Current number of elements in the disposable queue"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_disposable_queue_evict_size"}),(0,i.jsx)(t.td,{children:"Total amount of data evicted from the disposable queue since startup"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_index_queue_cache_size"}),(0,i.jsx)(t.td,{children:"Current size of the index queue"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_index_queue_element_count"}),(0,i.jsx)(t.td,{children:"Current number of elements in the index queue"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_index_queue_evict_size"}),(0,i.jsx)(t.td,{children:"Total amount of data evicted from the index queue since startup"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_normal_queue_cache_size"}),(0,i.jsx)(t.td,{children:"Current size of the normal queue"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_normal_queue_element_count"}),(0,i.jsx)(t.td,{children:"Current number of elements in the normal queue"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_normal_queue_evict_size"}),(0,i.jsx)(t.td,{children:"Total amount of data evicted from the normal queue since startup"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_total_evict_size"}),(0,i.jsx)(t.td,{children:"Total amount of data evicted from the entire File Cache since startup"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_ttl_cache_evict_size"}),(0,i.jsx)(t.td,{children:"Total amount of data evicted from the TTL queue since startup"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_ttl_cache_lru_queue_element_count"}),(0,i.jsx)(t.td,{children:"Current number of elements in the TTL queue"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_ttl_cache_size"}),(0,i.jsx)(t.td,{children:"Current size of the TTL queue"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_evict_by_heat_[A]_to_[B]"}),(0,i.jsx)(t.td,{children:"Data from cache type A evicted due to cache type B (time-based expiration)"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_evict_by_size_[A]_to_[B]"}),(0,i.jsx)(t.td,{children:"Data from cache type A evicted due to cache type B (space-based expiration)"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"file_cache_evict_by_self_lru_[A]"}),(0,i.jsx)(t.td,{children:"Data from cache type A evicted by its own LRU policy for new data"})]})]})]}),"\n",(0,i.jsx)(t.h3,{id:"sql-profile",children:"SQL Profile"}),"\n",(0,i.jsx)(t.p,{children:"Cache-related metrics in the SQL profile are found under SegmentIterator, including:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:"Metric Name"}),(0,i.jsx)(t.th,{children:"Meaning"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"BytesScannedFromCache"}),(0,i.jsx)(t.td,{children:"Amount of data read from the File Cache"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"BytesScannedFromRemote"}),(0,i.jsx)(t.td,{children:"Amount of data read from remote storage"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"BytesWriteIntoCache"}),(0,i.jsx)(t.td,{children:"Amount of data written into the File Cache"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"LocalIOUseTimer"}),(0,i.jsx)(t.td,{children:"Time taken to read from the File Cache"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"NumLocalIOTotal"}),(0,i.jsx)(t.td,{children:"Number of times the File Cache was read"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"NumRemoteIOTotal"}),(0,i.jsx)(t.td,{children:"Number of times remote storage was read"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"NumSkipCacheIOTotal"}),(0,i.jsx)(t.td,{children:"Number of times data read from remote storage did not enter the File Cache"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"RemoteIOUseTimer"}),(0,i.jsx)(t.td,{children:"Time taken to read from remote storage"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"WriteCacheIOUseTimer"}),(0,i.jsx)(t.td,{children:"Time taken to write to the File Cache"})]})]})]}),"\n",(0,i.jsxs)(t.p,{children:["You can view query performance analysis through ",(0,i.jsx)(t.a,{href:"../../query-acceleration/performance-tuning-overview/analysis-tools#doris-profile",children:"Query Performance Analysis"}),"."]}),"\n",(0,i.jsx)(t.h2,{id:"ttl-usage",children:"TTL Usage"}),"\n",(0,i.jsx)(t.p,{children:"When creating a table, set the corresponding PROPERTY to use the TTL strategy for caching that table's data."}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"file_cache_ttl_seconds"}),": The expected time for newly imported data to remain in the cache, in seconds."]}),"\n"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-shell",children:'CREATE TABLE IF NOT EXISTS customer (\n  C_CUSTKEY     INTEGER NOT NULL,\n  C_NAME        VARCHAR(25) NOT NULL,\n  C_ADDRESS     VARCHAR(40) NOT NULL,\n  C_NATIONKEY   INTEGER NOT NULL,\n  C_PHONE       CHAR(15) NOT NULL,\n  C_ACCTBAL     DECIMAL(15,2)   NOT NULL,\n  C_MKTSEGMENT  CHAR(10) NOT NULL,\n  C_COMMENT     VARCHAR(117) NOT NULL\n)\nDUPLICATE KEY(C_CUSTKEY, C_NAME)\nDISTRIBUTED BY HASH(C_CUSTKEY) BUCKETS 32\nPROPERTIES(\n    "file_cache_ttl_seconds"="300"\n)\n'})}),"\n",(0,i.jsx)(t.p,{children:"In the above table, all newly imported data will be retained in the cache for 300 seconds. The system currently supports modifying the TTL time of the table, and users can extend or shorten the TTL time based on actual needs."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-SQL",children:'ALTER TABLE customer set ("file_cache_ttl_seconds"="3000");\n'})}),"\n",(0,i.jsxs)(t.admonition,{title:"Note",type:"info",children:[(0,i.jsx)(t.p,{children:"The modified TTL value will not take effect immediately and will have a certain delay."}),(0,i.jsx)(t.p,{children:"If no TTL is set when creating the table, users can also modify the table's TTL attribute by executing the ALTER statement."})]}),"\n",(0,i.jsx)(t.h2,{id:"practical-case",children:"Practical Case"}),"\n",(0,i.jsxs)(t.p,{children:["A user has a series of data tables with a total data volume exceeding 3TB, while the available cache capacity is only 1.2TB. Among them, there are two tables with high access frequency: one is a dimension table of size 200MB (",(0,i.jsx)(t.code,{children:"dimension_table"}),"), and the other is a fact table of size 100GB (",(0,i.jsx)(t.code,{children:"fact_table"}),"), which has new data imported daily and requires T+1 query operations. Additionally, other large tables have low access frequency."]}),"\n",(0,i.jsx)(t.p,{children:"Under the LRU caching strategy, if large table data is queried, it may replace the small table data that needs to remain in the cache, causing performance fluctuations. To solve this problem, the user adopts a TTL caching strategy, setting the TTL times for the two tables to 1 year and 1 day, respectively."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-shell",children:'ALTER TABLE dimension_table set ("file_cache_ttl_seconds"="31536000");\n\nALTER TABLE fact_table set ("file_cache_ttl_seconds"="86400");\n'})}),"\n",(0,i.jsx)(t.p,{children:"For the dimension table, due to its smaller size and less variability, the user sets a TTL time of 1 year to ensure that its data can be accessed quickly within a year; for the fact table, the user needs to perform a table backup daily and then conduct a full import, so the TTL time is set to 1 day."})]})}function h(e={}){let{wrapper:t}={...(0,s.a)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},250065:function(e,t,n){n.d(t,{Z:function(){return r},a:function(){return c}});var a=n(667294);let i={},s=a.createContext(i);function c(e){let t=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:c(e.components),a.createElement(s.Provider,{value:t},e.children)}}}]);