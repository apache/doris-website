"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["600585"],{705225:function(e,t,n){n.r(t),n.d(t,{default:()=>d,frontMatter:()=>s,metadata:()=>o,assets:()=>a,toc:()=>l,contentTitle:()=>c});var o=JSON.parse('{"id":"lakehouse/best-practices/tpch","title":"Generating TPC-H on Hive/Iceberg","description":"Doris supports using the Trino Connector compatible framework to quickly build TPCH test sets with the TPCH Connector.","source":"@site/versioned_docs/version-2.1/lakehouse/best-practices/tpch.md","sourceDirName":"lakehouse/best-practices","slug":"/lakehouse/best-practices/tpch","permalink":"/docs/2.1/lakehouse/best-practices/tpch","draft":false,"unlisted":false,"tags":[],"version":"2.1","lastUpdatedAt":1770477659000,"frontMatter":{"title":"Generating TPC-H on Hive/Iceberg","language":"en","description":"Doris supports using the Trino Connector compatible framework to quickly build TPCH test sets with the TPCH Connector."},"sidebar":"docs","previous":{"title":"From MaxCompute to Doris","permalink":"/docs/2.1/lakehouse/best-practices/doris-maxcompute"},"next":{"title":"Generating TPC-DS on Hive/Iceberg","permalink":"/docs/2.1/lakehouse/best-practices/tpcds"}}'),r=n("785893"),i=n("250065");let s={title:"Generating TPC-H on Hive/Iceberg",language:"en",description:"Doris supports using the Trino Connector compatible framework to quickly build TPCH test sets with the TPCH Connector."},c=void 0,a={},l=[{value:"Compile TPCH Connector",id:"compile-tpch-connector",level:2},{value:"Deploy TPCH Connector",id:"deploy-tpch-connector",level:2},{value:"Create TPCH Catalog",id:"create-tpch-catalog",level:2},{value:"Use TPCH Catalog",id:"use-tpch-catalog",level:2},{value:"Build TPCH Test Dataset",id:"build-tpch-test-dataset",level:2}];function h(e){let t={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h2:"h2",p:"p",pre:"pre",...(0,i.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(t.p,{children:["Doris supports using the ",(0,r.jsx)(t.a,{href:"https://doris.apache.org/community/how-to-contribute/trino-connector-developer-guide",children:"Trino Connector"})," compatible framework to quickly build TPCH test sets with the ",(0,r.jsx)(t.a,{href:"https://trino.io/docs/current/connector/tpch.html",children:"TPCH Connector"}),"."]}),"\n",(0,r.jsx)(t.p,{children:"By combining the data write-back function of Hive/Iceberg tables, you can quickly build TPCH test datasets for Doris, Hive, and Iceberg tables through Doris."}),"\n",(0,r.jsx)(t.p,{children:"This document mainly introduces how to deploy and use the TPCH Connector to build test datasets."}),"\n",(0,r.jsx)(t.admonition,{type:"tip",children:(0,r.jsx)(t.p,{children:"This feature is supported starting from Doris version 3.0.0."})}),"\n",(0,r.jsx)(t.h2,{id:"compile-tpch-connector",children:"Compile TPCH Connector"}),"\n",(0,r.jsxs)(t.blockquote,{children:["\n",(0,r.jsx)(t.p,{children:"Requires JDK version 17."}),"\n"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-shell",children:"git clone https://github.com/trinodb/trino.git\ngit checkout 435\ncd trino/plugin/trino-tpch\nmvn clean install -DskipTest\n"})}),"\n",(0,r.jsxs)(t.p,{children:["After compilation, you will get the ",(0,r.jsx)(t.code,{children:"trino-tpch-435/"})," directory under ",(0,r.jsx)(t.code,{children:"trino/plugin/trino-tpch/target/"}),"."]}),"\n",(0,r.jsxs)(t.p,{children:["You can also directly download the precompiled ",(0,r.jsx)(t.a,{href:"https://github.com/morningman/trino-connectors/releases/download/trino-connectors/trino-tpch-435.tar.gz",children:"trino-tpch-435.tar.gz"})," and extract it."]}),"\n",(0,r.jsx)(t.h2,{id:"deploy-tpch-connector",children:"Deploy TPCH Connector"}),"\n",(0,r.jsxs)(t.p,{children:["Place the ",(0,r.jsx)(t.code,{children:"trino-tpch-435/"})," directory into the ",(0,r.jsx)(t.code,{children:"connectors/"})," directory of all FE and BE deployment paths. (If not present, you can create it manually)."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-text",children:"\u251C\u2500\u2500 bin\n\u251C\u2500\u2500 conf\n\u251C\u2500\u2500 connectors\n\u2502\xa0\xa0 \u251C\u2500\u2500 trino-tpch-435\n...\n"})}),"\n",(0,r.jsx)(t.p,{children:"After deployment, it is recommended to restart the FE and BE nodes to ensure the Connector can be loaded correctly."}),"\n",(0,r.jsx)(t.h2,{id:"create-tpch-catalog",children:"Create TPCH Catalog"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-sql",children:'CREATE CATALOG `tpch` PROPERTIES (\n    "type" = "trino-connector",\n    "trino.connector.name" = "tpch",\n    "trino.tpch.column-naming" = "STANDARD",\n    "trino.tpch.splits-per-node" = "32"\n);\n'})}),"\n",(0,r.jsxs)(t.p,{children:["The ",(0,r.jsx)(t.code,{children:"tpch.splits-per-node"})," is the concurrency number, which is recommended to be set to 2 times the number of cores per BE machine to achieve optimal concurrency. This improves data generation efficiency."]}),"\n",(0,r.jsxs)(t.p,{children:["When ",(0,r.jsx)(t.code,{children:'"tpch.column-naming" = "STANDARD"'}),", the column names in the TPCH table will start with the table name abbreviation, such as ",(0,r.jsx)(t.code,{children:"l_orderkey"}),", otherwise, it is ",(0,r.jsx)(t.code,{children:"orderkey"}),"."]}),"\n",(0,r.jsx)(t.h2,{id:"use-tpch-catalog",children:"Use TPCH Catalog"}),"\n",(0,r.jsxs)(t.p,{children:["The TPCH Catalog has pre-configured TPCH datasets of different Scale Factors, which can be viewed using the ",(0,r.jsx)(t.code,{children:"SHOW DATABASES"})," and ",(0,r.jsx)(t.code,{children:"SHOW TABLES"})," commands."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-sql",children:"mysql> SWITCH tpch;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SHOW DATABASES;\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| sf1                |\n| sf100              |\n| sf1000             |\n| sf10000            |\n| sf100000           |\n| sf300              |\n| sf3000             |\n| sf30000            |\n| tiny               |\n+--------------------+\n\nmysql> USE sf1;\nmysql> SHOW TABLES;\n+---------------+\n| Tables_in_sf1 |\n+---------------+\n| customer      |\n| lineitem      |\n| nation        |\n| orders        |\n| part          |\n| partsupp      |\n| region        |\n| supplier      |\n+---------------+\n"})}),"\n",(0,r.jsx)(t.p,{children:"You can directly query these tables using the SELECT statement."}),"\n",(0,r.jsx)(t.admonition,{type:"tip",children:(0,r.jsxs)(t.p,{children:["The data in these pre-configured datasets is not actually stored but is generated in real-time during queries. Therefore, these pre-configured datasets are not suitable for direct Benchmark testing. They are suitable for writing datasets into other target tables (such as Doris internal tables, Hive, Iceberg, and all other data sources that Doris supports writing to) through ",(0,r.jsx)(t.code,{children:"INSERT INTO SELECT"}),", and then performing performance testing on the target tables."]})}),"\n",(0,r.jsx)(t.h2,{id:"build-tpch-test-dataset",children:"Build TPCH Test Dataset"}),"\n",(0,r.jsx)(t.p,{children:"The following example quickly builds a TPCH test dataset on Hive using the CTAS statement:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-sql",children:'CREATE TABLE hive.tpch100.customer PROPERTIES("file_format" = "parquet") AS SELECT * FROM tpch.sf100.customer  ;\nCREATE TABLE hive.tpch100.lineitem PROPERTIES("file_format" = "parquet") AS SELECT * FROM tpch.sf100.lineitem  ;\nCREATE TABLE hive.tpch100.nation   PROPERTIES("file_format" = "parquet") AS SELECT * FROM tpch.sf100.nation    ;\nCREATE TABLE hive.tpch100.orders   PROPERTIES("file_format" = "parquet") AS SELECT * FROM tpch.sf100.orders    ;\nCREATE TABLE hive.tpch100.part     PROPERTIES("file_format" = "parquet") AS SELECT * FROM tpch.sf100.part      ;\nCREATE TABLE hive.tpch100.partsupp PROPERTIES("file_format" = "parquet") AS SELECT * FROM tpch.sf100.partsupp  ;\nCREATE TABLE hive.tpch100.region   PROPERTIES("file_format" = "parquet") AS SELECT * FROM tpch.sf100.region    ;\nCREATE TABLE hive.tpch100.supplier PROPERTIES("file_format" = "parquet") AS SELECT * FROM tpch.sf100.supplier  ;\n'})}),"\n",(0,r.jsx)(t.admonition,{type:"tip",children:(0,r.jsx)(t.p,{children:"In a Doris cluster with 3 16C BE nodes, creating a TPCH 1000 Hive dataset takes about 25 minutes, and TPCH 10000 takes about 4 to 5 hours."})})]})}function d(e={}){let{wrapper:t}={...(0,i.a)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},250065:function(e,t,n){n.d(t,{Z:function(){return c},a:function(){return s}});var o=n(667294);let r={},i=o.createContext(r);function s(e){let t=o.useContext(i);return o.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function c(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),o.createElement(i.Provider,{value:t},e.children)}}}]);