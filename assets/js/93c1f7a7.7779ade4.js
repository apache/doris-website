"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["39601"],{163519:function(e,n,i){i.r(n),i.d(n,{default:()=>m,frontMatter:()=>c,metadata:()=>t,assets:()=>s,toc:()=>l,contentTitle:()=>r});var t=JSON.parse('{"id":"admin-manual/trouble-shooting/compaction","title":"Compaction","description":"Doris writes data through a structure similar to LSM-Tree,","source":"@site/versioned_docs/version-4.x/admin-manual/trouble-shooting/compaction.md","sourceDirName":"admin-manual/trouble-shooting","slug":"/admin-manual/trouble-shooting/compaction","permalink":"/docs/4.x/admin-manual/trouble-shooting/compaction","draft":false,"unlisted":false,"tags":[],"version":"4.x","lastUpdatedAt":1770477659000,"frontMatter":{"title":"Compaction","language":"en","description":"Doris writes data through a structure similar to LSM-Tree,"},"sidebar":"docs","previous":{"title":"Memory Control Strategy","permalink":"/docs/4.x/admin-manual/trouble-shooting/memory-management/memory-feature/memory-control-strategy"},"next":{"title":"Compaction Principles","permalink":"/docs/4.x/admin-manual/trouble-shooting/compaction-principles"}}'),o=i("785893"),a=i("250065");let c={title:"Compaction",language:"en",description:"Doris writes data through a structure similar to LSM-Tree,"},r="Compaction",s={},l=[{value:"Vertical compaction",id:"vertical-compaction",level:2},{value:"Segment compaction",id:"segment-compaction",level:2},{value:"Single replica compaction",id:"single-replica-compaction",level:2},{value:"Compaction strategy",id:"compaction-strategy",level:2},{value:"Size-based compaction strategy",id:"size-based-compaction-strategy",level:3},{value:"Time series compaction strategy",id:"time-series-compaction-strategy",level:3},{value:"Compaction concurrency control",id:"compaction-concurrency-control",level:2}];function d(e){let n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"compaction",children:"Compaction"})}),"\n",(0,o.jsx)(n.p,{children:"Doris writes data through a structure similar to LSM-Tree, and continuously merges small files into large ordered files through compaction in the background. Compaction handles operations such as deletion and updating."}),"\n",(0,o.jsx)(n.p,{children:"Appropriately adjusting the compaction strategy can greatly improve load and query efficiency. Doris provides the following compaction strategies for tuning:"}),"\n",(0,o.jsx)(n.h2,{id:"vertical-compaction",children:"Vertical compaction"}),"\n",(0,o.jsx)(n.p,{children:"Vertical compaction is a new compaction algorithm implemented in Doris 1.2.2, which is used to optimize compaction execution efficiency and resource overhead in large-scale and wide table scenarios. It can effectively reduce the memory overhead of compaction and improve the execution speed of compaction. The test results show that the memory consumption by vertical compaction is only 1/10 of the original compaction algorithm, and the compaction rate is increased by 15%."}),"\n",(0,o.jsx)(n.p,{children:"In vertical compaction, merging by row is changed to merging by column group. The granularity of each merge is changed to column group, which reduces the amount of data involved in single compaction and reduces the memory usage during compaction."}),"\n",(0,o.jsx)(n.p,{children:"BE configuration:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"enable_vertical_compaction = true"})," will turn on vertical compaction"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"vertical_compaction_num_columns_per_group = 5"})," The number of columns contained in each column group, by testing, the efficiency and memory usage of a group of 5 columns by default is more friendly"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"vertical_compaction_max_segment_size"})," is used to configure the size of the disk file after vertical compaction, the default value is 268435456 (bytes)"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"segment-compaction",children:"Segment compaction"}),"\n",(0,o.jsx)(n.p,{children:"Segment compaction mainly deals with the large-scale data load. Segment compaction operates during the load process and compact segments inside the job, which is different from normal compaction and vertical compaction. This mechanism can effectively reduce the number of generated segments and avoid the -238 (OLAP_ERR_TOO_MANY_SEGMENTS) errors."}),"\n",(0,o.jsx)(n.p,{children:"The following features are provided by segment compaction:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"reduce the number of segments generated by load"}),"\n",(0,o.jsx)(n.li,{children:"the compacting process is parallel to the load process, which will not increase the load time"}),"\n",(0,o.jsx)(n.li,{children:"memory consumption and computing resources will increase during loading, but the increase is relatively low because it is evenly distributed throughout the long load process."}),"\n",(0,o.jsx)(n.li,{children:"data after segment compaction will have resource and performance advantages in subsequent queries and normal compaction."}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"BE configuration:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"enable_segcompaction=true"})," turn it on."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"segcompaction_batch_size"})," is used to configure the interval for merging. The default value 10 means that every 10 segment files will trigger a segment compaction. It is recommended to set between 10 - 30. The larger value will increase the memory usage of segment compaction."]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Situations where segment compaction is recommended:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Loading large amounts of data fails at OLAP_ ERR_ TOO_ MANY_ SEGMENTS (errcode - 238) error. Then it is recommended to turn on segment compaction to reduce the quantity of segments during the load process."}),"\n",(0,o.jsx)(n.li,{children:"Too many small files are generated during the load process: although the amount of loading data is reasonable, the generation of a large number of small segment files may also fail the load job because of low cardinality or memory constraints that trigger memtable to be flushed in advance. Then it is recommended to turn on this function."}),"\n",(0,o.jsx)(n.li,{children:"Query immediately after loading. When the load is just finished and the standard compaction has not finished, large number of segment files will affect the efficiency of subsequent queries. If the user needs to query immediately after loading, it is recommended to turn on this function."}),"\n",(0,o.jsx)(n.li,{children:"The pressure of normal compaction is high after loading: segment compaction evenly puts part of the pressure of normal compaction on the loading process. At this time, it is recommended to enable this function."}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Situations where segment compaction is not recommended:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"When the load operation itself has exhausted memory resources, it is not recommended to use the segment compaction to avoid further increasing memory pressure and causing the load job to fail."}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["Refer to this ",(0,o.jsx)(n.a,{href:"https://github.com/apache/doris/pull/12866",children:"link"})," for more information about implementation and test results."]}),"\n",(0,o.jsx)(n.h2,{id:"single-replica-compaction",children:"Single replica compaction"}),"\n",(0,o.jsx)(n.p,{children:"By default, compaction for multiple replicas is performed independently, with each replica consuming CPU and IO resources. When single replica compaction is enabled, only one replica performs the compaction. Afterward, the other replicas pull the compacted files from this replica, resulting in CPU resources being consumed only once, saving N - 1 times CPU usage (where N is the number of replicas)."}),"\n",(0,o.jsxs)(n.p,{children:["Single replica compaction is specified in the table's PROPERTIES via the parameter ",(0,o.jsx)(n.code,{children:"enable_single_replica_compaction"}),", which is false by default (disabled). To enable it, set the parameter to true."]}),"\n",(0,o.jsx)(n.p,{children:"This parameter can be specified when creating the table or modified later using:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sql",children:'ALTER TABLE table_name SET("enable_single_replica_compaction" = "true");\n'})}),"\n",(0,o.jsx)(n.h2,{id:"compaction-strategy",children:"Compaction strategy"}),"\n",(0,o.jsxs)(n.p,{children:["The compaction strategy determines when and which small files are merged into larger files. Doris currently offers two compaction strategies, specified by the ",(0,o.jsx)(n.code,{children:"compaction_policy"})," parameter in the table properties."]}),"\n",(0,o.jsx)(n.h3,{id:"size-based-compaction-strategy",children:"Size-based compaction strategy"}),"\n",(0,o.jsx)(n.p,{children:"The size-based compaction strategy is the default strategy and is suitable for most scenarios."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'"compaction_policy" = "size_based"\n'})}),"\n",(0,o.jsx)(n.h3,{id:"time-series-compaction-strategy",children:"Time series compaction strategy"}),"\n",(0,o.jsx)(n.p,{children:"The time series compaction strategy is optimized for scenarios like logs and time-series data. It leverages the time locality of time-series data, merging small files written in adjacent times into larger files. Each file participates in compaction only once, reducing write amplification from repeated compaction."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'"compaction_policy" = "time_series"\n'})}),"\n",(0,o.jsx)(n.p,{children:"The time series compaction strategy is triggered when any of the following conditions are met:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["The size of unmerged files exceeds ",(0,o.jsx)(n.code,{children:"time_series_compaction_goal_size_mbytes"})," (default 1 GB)."]}),"\n",(0,o.jsxs)(n.li,{children:["The number of unmerged files exceeds ",(0,o.jsx)(n.code,{children:"time_series_compaction_file_count_threshold"})," (default 2000)."]}),"\n",(0,o.jsxs)(n.li,{children:["The time since the last compaction exceeds ",(0,o.jsx)(n.code,{children:"time_series_compaction_time_threshold_seconds"})," (default 1 hour)."]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"These parameters are set in the table's PROPERTIES and can be specified when creating the table or modified later using:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'ALTER TABLE table_name SET("name" = "value");\n'})}),"\n",(0,o.jsx)(n.h2,{id:"compaction-concurrency-control",children:"Compaction concurrency control"}),"\n",(0,o.jsx)(n.p,{children:"Compaction runs in the background and consumes CPU and IO resources. The resource consumption can be controlled by adjusting the number of concurrent compaction threads."}),"\n",(0,o.jsx)(n.p,{children:"The number of concurrent compaction threads is configured in the BE configuration file, including the following parameters:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"max_base_compaction_threads"}),": Number of base compaction threads, default is 4."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"max_cumu_compaction_threads"}),": Number of cumulative compaction threads, default is -1, which mean that 1 thread per disk."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"max_single_replica_compaction_threads"}),": Number of threads for fetching data files during single replica compaction, default is 10."]}),"\n"]})]})}function m(e={}){let{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},250065:function(e,n,i){i.d(n,{Z:function(){return r},a:function(){return c}});var t=i(667294);let o={},a=t.createContext(o);function c(e){let n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:c(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);