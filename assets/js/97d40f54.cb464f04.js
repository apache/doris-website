"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["566025"],{728555:function(e,n,t){t.r(n),t.d(n,{assets:function(){return l},contentTitle:function(){return r},default:function(){return h},frontMatter:function(){return s},metadata:function(){return o},toc:function(){return c}});var o=t(550269),a=t(785893),i=t(250065);let s={title:"Auto synchronization of an entire MySQL database for data analysis",description:"Flink-Doris-Connector 1.4.0 allows users to ingest a whole database (MySQL or Oracle) that contains thousands of tables into Apache Doris, in one step.",date:"2023-08-16",author:"velodb.io \xb7 VeloDB Engineering Team",tags:["Tech Sharing"],externalLink:"https://www.velodb.io/blog/135",image:"/images/auto-synchronize.png"},r=void 0,l={authorsImageUrls:[void 0]},c=[{value:"Quick Start",id:"quick-start",level:2},{value:"How to Use It",id:"how-to-use-it",level:2},{value:"How It Performs",id:"how-it-performs",level:2},{value:"How It Benefits Data Engineers",id:"how-it-benefits-data-engineers",level:2},{value:"Other Features",id:"other-features",level:2},{value:"Example Usage",id:"example-usage",level:2}];function d(e){let n={a:"a",code:"code",h2:"h2",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(n.p,{children:["Flink-Doris-Connector 1.4.0 allows users to ingest a whole database (",(0,a.jsx)(n.strong,{children:"MySQL"})," or ",(0,a.jsx)(n.strong,{children:"Oracle"}),") that contains thousands of tables into ",(0,a.jsx)(n.a,{href:"https://doris.apache.org/zh-CN/",children:"Apache Doris"}),", a real-time analytic database, ",(0,a.jsx)(n.strong,{children:"in one step"}),"."]}),"\n",(0,a.jsx)(n.p,{children:"With built-in Flink CDC, the Connector can directly synchronize the table schema and data from the upstream source to Apache Doris, which means users no longer have to write a DataStream program or pre-create mapping tables in Doris."}),"\n",(0,a.jsx)(n.p,{children:"When a Flink job starts, the Connector automatically checks for data equivalence between the source database and Apache Doris. If the data source contains tables which do not exist in Doris, the Connector will automatically create those same tables in Doris, and utilizes the side outputs of Flink to facilitate the ingestion of multiple tables at once; if there is a schema change in the source, it will automatically obtain the DDL statement and make the same schema change in Doris."}),"\n",(0,a.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,a.jsxs)(n.p,{children:["Download Flink Doris Connector: ",(0,a.jsx)(n.a,{href:"https://doris.apache.org/download/",children:"https://doris.apache.org/download/"})]}),"\n",(0,a.jsx)(n.h2,{id:"how-to-use-it",children:"How to Use It"}),"\n",(0,a.jsxs)(n.p,{children:["For example, to ingest a whole MySQL database ",(0,a.jsx)(n.code,{children:"mysql_db"})," into Doris (the MySQL table names start with ",(0,a.jsx)(n.code,{children:"tbl"})," or ",(0,a.jsx)(n.code,{children:"test"}),"), simply execute the following command (no need to create the tables in Doris in advance):"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-Shell",children:'<FLINK_HOME>/bin/flink run \\\n    -Dexecution.checkpointing.interval=10s \\\n    -Dparallelism.default=1 \\\n    -c org.apache.doris.flink.tools.cdc.CdcTools \\\n    lib/flink-doris-connector-1.16-1.4.0.jar \\\n    mysql-sync-database \\\n    --database test_db \\\n    --mysql-conf hostname=127.0.0.1 \\\n    --mysql-conf username=root \\\n    --mysql-conf password=123456 \\\n    --mysql-conf database-name=mysql_db \\\n    --including-tables "tbl|test.*" \\\n    --sink-conf fenodes=127.0.0.1:8030 \\\n    --sink-conf username=root \\\n    --sink-conf password=123456 \\\n    --sink-conf jdbc-url=jdbc:mysql://127.0.0.1:9030 \\\n    --sink-conf sink.label-prefix=label1 \\\n    --table-conf replication_num=1 \n'})}),"\n",(0,a.jsxs)(n.p,{children:["To ingest an Oracle database: please refer to the ",(0,a.jsx)(n.a,{href:"https://github.com/apache/doris-flink-connector/pull/156",children:"example code"}),"."]}),"\n",(0,a.jsx)(n.h2,{id:"how-it-performs",children:"How It Performs"}),"\n",(0,a.jsx)(n.p,{children:"When it comes to synchronizing a whole database (containing hundreds or even thousands of tables, active or inactive), most users want it to be done within seconds. So we tested the Connector to see if it came up to scratch:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"1000 MySQL tables, each having 100 fields. All tables were active (which meant they were continuously updated and each data writing involved over a hundred rows)"}),"\n",(0,a.jsx)(n.li,{children:"Flink job checkpoint: 10s"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Under pressure test, the system showed high stability, with key metrics as follows:"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Flink-Doris-Connector",src:t(889767).Z+"",width:"1280",height:"243"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Flink-CDC",src:t(290369).Z+"",width:"1280",height:"487"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Doris-Cluster-Compaction-Score",src:t(407831).Z+"",width:"1280",height:"306"})}),"\n",(0,a.jsx)(n.p,{children:"According to feedback from early adopters, the Connector has also delivered high performance and system stability in 10,000-table database synchronization in their production environment. This proves that the combination of Apache Doris and Flink CDC is capable of large-scale data synchronization with high efficiency and reliability."}),"\n",(0,a.jsx)(n.h2,{id:"how-it-benefits-data-engineers",children:"How It Benefits Data Engineers"}),"\n",(0,a.jsx)(n.p,{children:"Engineers no longer have to worry about table creation or table schema maintenance, saving them days of tedious and error-prone work. Previously in Flink CDC, you need to create a Flink job for each table and build a log parsing link at the source end, but now with whole-database ingestion, resource consumption in the source database is largely reduced. It is also a unified solution for incremental update and full update."}),"\n",(0,a.jsx)(n.h2,{id:"other-features",children:"Other Features"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"1. Joining dimension table and fact table"})}),"\n",(0,a.jsxs)(n.p,{children:["The common practice is to put dimension tables in Doris and run join queries via the real-time stream of Flink. Based on the ",(0,a.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/dev/datastream/operators/asyncio/",children:"Async I/O of Flink"}),", Flink-Doris-Connector 1.4.0 implements asynchronous Lookup Join, so the Flink real-time stream won't be blocked due to queries. Also, the Connector allows you to combine multiple queries into one big query, and send it to Doris at once for processing. This improves the efficiency and throughput of such join queries."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"2. Thrift"})," ",(0,a.jsx)(n.strong,{children:"SDK"})]}),"\n",(0,a.jsx)(n.p,{children:"We introduced Thrift-Service SDK into the Connector so users no longer have to use Thrift plug-ins or configure a Thrift environment in compilation. This makes the compilation process much simpler."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"3. On-Demand Stream Load"})}),"\n",(0,a.jsx)(n.p,{children:"During data synchronization, when there is no new data ingestion, no Stream Load requests will be issued. This avoids unnecessary consumption of cluster resources."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"4. Polling of Backend Nodes"})}),"\n",(0,a.jsx)(n.p,{children:"For data ingestion, Doris calls a frontend node to obtain a list of the backend nodes, and randomly chooses one to launch an ingestion request. That backend node will be the Coordinator. Flink-Doris-Connector 1.4.0 allows users to enable the polling mechanism, which is to have a different backend node to be the Coordinator at each Flink checkpoint to avoid too much pressure on a single backend node for a long time."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"5. Support for More Data Types"})}),"\n",(0,a.jsx)(n.p,{children:"In addition to the common data types, Flink-Doris-Connector 1.4.0 supports DecimalV3/DateV2/DateTimev2/Array/JSON in Doris."}),"\n",(0,a.jsx)(n.h2,{id:"example-usage",children:"Example Usage"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Read from Apache Doris:"})}),"\n",(0,a.jsx)(n.p,{children:"You can read data from Doris via DataStream or FlinkSQL (bounded stream). Predicate pushdown is supported."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-Java",children:"CREATE TABLE flink_doris_source (\n    name STRING,\n    age INT,\n    score DECIMAL(5,2)\n    ) \n    WITH (\n      'connector' = 'doris',\n      'fenodes' = '127.0.0.1:8030',\n      'table.identifier' = 'database.table',\n      'username' = 'root',\n      'password' = 'password',\n      'doris.filter.query' = 'age=18'\n);\n\nSELECT * FROM flink_doris_source;\n"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Join dimension table and fact table"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-Java",children:"CREATE TABLE fact_table (\n  `id` BIGINT,\n  `name` STRING,\n  `city` STRING,\n  `process_time` as proctime()\n) WITH (\n  'connector' = 'kafka',\n  ...\n);\n\ncreate table dim_city(\n  `city` STRING,\n  `level` INT ,\n  `province` STRING,\n  `country` STRING\n) WITH (\n  'connector' = 'doris',\n  'fenodes' = '127.0.0.1:8030',\n  'jdbc-url' = 'jdbc:mysql://127.0.0.1:9030',\n  'lookup.jdbc.async' = 'true',\n  'table.identifier' = 'dim.dim_city',\n  'username' = 'root',\n  'password' = ''\n);\n\nSELECT a.id, a.name, a.city, c.province, c.country,c.level \nFROM fact_table a\nLEFT JOIN dim_city FOR SYSTEM_TIME AS OF a.process_time AS c\nON a.city = c.city\n"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Write to Apache Doris"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-Java",children:"CREATE TABLE doris_sink (\n    name STRING,\n    age INT,\n    score DECIMAL(5,2)\n    ) \n    WITH (\n      'connector' = 'doris',\n      'fenodes' = '127.0.0.1:8030',\n      'table.identifier' = 'database.table',\n      'username' = 'root',\n      'password' = '',\n      'sink.label-prefix' = 'doris_label',\n      //json write in\n      'sink.properties.format' = 'json',\n      'sink.properties.read_json_by_line' = 'true'\n);\n"})}),"\n",(0,a.jsxs)(n.p,{children:["If you've got any questions, find Apache Doris developers on ",(0,a.jsx)(n.a,{href:"https://doris.apache.org/slack",children:"Slack"}),"."]})]})}function h(e={}){let{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},889767:function(e,n,t){t.d(n,{Z:function(){return o}});let o=t.p+"assets/images/FDC_1-ce2b3c35d3126c743a9b9df1105dd1ce.png"},290369:function(e,n,t){t.d(n,{Z:function(){return o}});let o=t.p+"assets/images/FDC_2-18b4e1b3346d90e6430b992d74e9a64f.png"},407831:function(e,n,t){t.d(n,{Z:function(){return o}});let o=t.p+"assets/images/FDC_3-5e973914e448c11df5e3e408823f2ded.png"},250065:function(e,n,t){t.d(n,{Z:function(){return r},a:function(){return s}});var o=t(667294);let a={},i=o.createContext(a);function s(e){let n=o.useContext(i);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),o.createElement(i.Provider,{value:n},e.children)}},550269:function(e){e.exports=JSON.parse('{"permalink":"/blog/Auto-Synchronization-of-an-Entire-MySQL-Database-for-Data-Analysis","source":"@site/blog/Auto-Synchronization-of-an-Entire-MySQL-Database-for-Data-Analysis.md","title":"Auto synchronization of an entire MySQL database for data analysis","description":"Flink-Doris-Connector 1.4.0 allows users to ingest a whole database (MySQL or Oracle) that contains thousands of tables into Apache Doris, in one step.","date":"2023-08-16T00:00:00.000Z","tags":[{"inline":true,"label":"Tech Sharing","permalink":"/blog/tags/tech-sharing"}],"hasTruncateMarker":false,"authors":[{"name":"velodb.io \xb7 VeloDB Engineering Team","key":null,"page":null}],"frontMatter":{"title":"Auto synchronization of an entire MySQL database for data analysis","description":"Flink-Doris-Connector 1.4.0 allows users to ingest a whole database (MySQL or Oracle) that contains thousands of tables into Apache Doris, in one step.","date":"2023-08-16","author":"velodb.io \xb7 VeloDB Engineering Team","tags":["Tech Sharing"],"externalLink":"https://www.velodb.io/blog/135","image":"/images/auto-synchronize.png"},"unlisted":false,"prevItem":{"title":"Choosing an OLAP engine for financial risk management: what to consider?","permalink":"/blog/Choosing-an-OLAP-Engine-for-Financial-Risk-Management-What-to-Consider"},"nextItem":{"title":"New milestone: Apache Doris 2.0.0 just released","permalink":"/blog/release-note-2.0.0"}}')}}]);