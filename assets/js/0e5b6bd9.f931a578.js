"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["161710"],{978186:function(n,e,l){l.r(e),l.d(e,{default:()=>h,frontMatter:()=>t,metadata:()=>a,assets:()=>o,toc:()=>d,contentTitle:()=>r});var a=JSON.parse('{"id":"data-operate/import/load-data-convert","title":"Transforming Data During Load","description":"Doris provides powerful data transformation capabilities during data loading, which can simplify data processing workflows and reduce dependency on additional ETL tools. It mainly supports four types of transformations:","source":"@site/docs/data-operate/import/load-data-convert.md","sourceDirName":"data-operate/import","slug":"/data-operate/import/load-data-convert","permalink":"/docs/dev/data-operate/import/load-data-convert","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Transforming Data During Load","language":"en"},"sidebar":"docs","previous":{"title":"Handling Data Issues","permalink":"/docs/dev/data-operate/import/handling-messy-data"},"next":{"title":"Load High Availability","permalink":"/docs/dev/data-operate/import/load-high-availability"}}'),s=l("785893"),i=l("250065");let t={title:"Transforming Data During Load",language:"en"},r=void 0,o={},d=[{value:"Load Syntax",id:"load-syntax",level:2},{value:"Stream Load",id:"stream-load",level:3},{value:"Broker Load",id:"broker-load",level:3},{value:"Routine Load",id:"routine-load",level:3},{value:"Insert Into",id:"insert-into",level:3},{value:"Column Mapping",id:"column-mapping",level:2},{value:"Implementation Principle",id:"implementation-principle",level:3},{value:"Load CSV Format Data",id:"load-csv-format-data",level:4},{value:"Load JSON Format Data with Specified jsonpaths",id:"load-json-format-data-with-specified-jsonpaths",level:4},{value:"Load JSON Format Data without Specified jsonpaths",id:"load-json-format-data-without-specified-jsonpaths",level:4},{value:"Load JSON Data with Specified jsonpaths",id:"load-json-data-with-specified-jsonpaths",level:3},{value:"Create Target Table",id:"create-target-table",level:5},{value:"Load Data",id:"load-data",level:5},{value:"Query Results",id:"query-results",level:5},{value:"Load JSON Data without Specified jsonpaths",id:"load-json-data-without-specified-jsonpaths",level:3},{value:"Create Target Table",id:"create-target-table-1",level:5},{value:"Load Data",id:"load-data-1",level:5},{value:"Query Results",id:"query-results-1",level:5},{value:"Adjusting Column Order",id:"adjusting-column-order",level:3},{value:"Creating the Target Table",id:"creating-the-target-table",level:4},{value:"Loading Data",id:"loading-data",level:4},{value:"Query Results",id:"query-results-2",level:4},{value:"Source File Columns Exceed Table Columns",id:"source-file-columns-exceed-table-columns",level:3},{value:"Creating the Target Table",id:"creating-the-target-table-1",level:4},{value:"Loading Data",id:"loading-data-1",level:4},{value:"Query Results",id:"query-results-3",level:4},{value:"Source File Columns Less Than Table Columns",id:"source-file-columns-less-than-table-columns",level:3},{value:"Creating the Target Table",id:"creating-the-target-table-2",level:4},{value:"Loading Data",id:"loading-data-2",level:4},{value:"Query Results",id:"query-results-4",level:4},{value:"Column Transformation",id:"column-transformation",level:2},{value:"Transforming Source File Column Values Before Loading",id:"transforming-source-file-column-values-before-loading",level:3},{value:"Creating the Target Table",id:"creating-the-target-table-3",level:4},{value:"Loading Data",id:"loading-data-3",level:4},{value:"Query Results",id:"query-results-5",level:4},{value:"Using Case When Function for Conditional Column Transformation",id:"using-case-when-function-for-conditional-column-transformation",level:3},{value:"Creating the Target Table",id:"creating-the-target-table-4",level:4},{value:"Loading Data",id:"loading-data-4",level:4},{value:"Query Results",id:"query-results-6",level:4},{value:"Handling NULL Values in Source Files",id:"handling-null-values-in-source-files",level:3},{value:"Creating the Target Table",id:"creating-the-target-table-5",level:4},{value:"Loading Data",id:"loading-data-5",level:4},{value:"Query Results",id:"query-results-7",level:4},{value:"Pre-filtering",id:"pre-filtering",level:2},{value:"Example 1: Using Numeric Conditions for Pre-filtering",id:"example-1-using-numeric-conditions-for-pre-filtering",level:3},{value:"Creating the Target Table",id:"creating-the-target-table-6",level:4},{value:"Loading Data",id:"loading-data-6",level:4},{value:"Query Results",id:"query-results-8",level:4},{value:"Example 2: Using Intermediate Columns to Filter Invalid Data",id:"example-2-using-intermediate-columns-to-filter-invalid-data",level:3},{value:"Table Creation",id:"table-creation",level:4},{value:"Load Statements",id:"load-statements",level:4},{value:"Load Results",id:"load-results",level:4},{value:"Post-filtering",id:"post-filtering",level:2},{value:"Filtering Without Column Mapping and Transformation",id:"filtering-without-column-mapping-and-transformation",level:3},{value:"Creating the Target Table",id:"creating-the-target-table-7",level:4},{value:"Loading Data",id:"loading-data-7",level:4},{value:"Query Results",id:"query-results-9",level:4},{value:"Filtering Transformed Data",id:"filtering-transformed-data",level:3},{value:"Creating the Target Table",id:"creating-the-target-table-8",level:4},{value:"Loading Data",id:"loading-data-8",level:4},{value:"Query Results",id:"query-results-10",level:4},{value:"Multiple Conditions Filtering",id:"multiple-conditions-filtering",level:3},{value:"Creating the Target Table",id:"creating-the-target-table-9",level:4},{value:"Loading Data",id:"loading-data-9",level:4},{value:"Query Results",id:"query-results-11",level:4}];function c(n){let e={blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",h4:"h4",h5:"h5",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.a)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.p,{children:"Doris provides powerful data transformation capabilities during data loading, which can simplify data processing workflows and reduce dependency on additional ETL tools. It mainly supports four types of transformations:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Column Mapping"}),": Map source data columns to different columns in the target table."]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Column Transformation"}),": Transform source data in real-time using functions and expressions."]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Pre-filtering"}),": Filter out unwanted raw data before column mapping and transformation."]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Post-filtering"}),": Filter the final results after column mapping and transformation."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Through these built-in data transformation functions, you can improve loading efficiency and ensure consistency in data processing logic."}),"\n",(0,s.jsx)(e.h2,{id:"load-syntax",children:"Load Syntax"}),"\n",(0,s.jsx)(e.h3,{id:"stream-load",children:"Stream Load"}),"\n",(0,s.jsx)(e.p,{children:"Configure data transformation by setting the following parameters in HTTP headers:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,s.jsxs)(e.table,{children:[(0,s.jsx)(e.thead,{children:(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.th,{children:"Parameter"}),(0,s.jsx)(e.th,{children:"Description"})]})}),(0,s.jsxs)(e.tbody,{children:[(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.code,{children:"columns"})}),(0,s.jsx)(e.td,{children:"Specify column mapping and transformation"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.code,{children:"where"})}),(0,s.jsx)(e.td,{children:"Specify post-filtering"})]})]})]}),"\n",(0,s.jsxs)(e.blockquote,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Note"}),": Stream Load does not support pre-filtering."]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Example:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-shell",children:'curl --location-trusted -u user:passwd \\\n    -H "columns: k1, k2, tmp_k3, k3 = tmp_k3 + 1" \\\n    -H "where: k1 > 1" \\\n    -T data.csv \\\n    http://<fe_ip>:<fe_http_port>/api/example_db/example_table/_stream_load\n'})}),"\n",(0,s.jsx)(e.h3,{id:"broker-load",children:"Broker Load"}),"\n",(0,s.jsx)(e.p,{children:"Implement data transformation in SQL statements using the following clauses:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,s.jsxs)(e.table,{children:[(0,s.jsx)(e.thead,{children:(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.th,{children:"Clause"}),(0,s.jsx)(e.th,{children:"Description"})]})}),(0,s.jsxs)(e.tbody,{children:[(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.code,{children:"column list"})}),(0,s.jsxs)(e.td,{children:["Specify column mapping, format: ",(0,s.jsx)(e.code,{children:"(k1, k2, tmp_k3)"})]})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.code,{children:"SET"})}),(0,s.jsx)(e.td,{children:"Specify column transformation"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.code,{children:"PRECEDING FILTER"})}),(0,s.jsx)(e.td,{children:"Specify pre-filtering"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.code,{children:"WHERE"})}),(0,s.jsx)(e.td,{children:"Specify post-filtering"})]})]})]}),"\n",(0,s.jsx)(e.p,{children:"Example:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'LOAD LABEL test_db.label1\n(\n    DATA INFILE("s3://bucket_name/data.csv")\n    INTO TABLE `test_tbl`\n    (k1, k2, tmp_k3)\n    PRECEDING FILTER k1 = 1\n    SET (\n        k3 = tmp_k3 + 1\n    )\n    WHERE k1 > 1\n)\nWITH S3 (...);\n'})}),"\n",(0,s.jsx)(e.h3,{id:"routine-load",children:"Routine Load"}),"\n",(0,s.jsx)(e.p,{children:"Implement data transformation in SQL statements using the following clauses:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,s.jsxs)(e.table,{children:[(0,s.jsx)(e.thead,{children:(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.th,{children:"Clause"}),(0,s.jsx)(e.th,{children:"Description"})]})}),(0,s.jsxs)(e.tbody,{children:[(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.code,{children:"COLUMNS"})}),(0,s.jsx)(e.td,{children:"Specify column mapping and transformation"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.code,{children:"PRECEDING FILTER"})}),(0,s.jsx)(e.td,{children:"Specify pre-filtering"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.code,{children:"WHERE"})}),(0,s.jsx)(e.td,{children:"Specify post-filtering"})]})]})]}),"\n",(0,s.jsx)(e.p,{children:"Example:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE ROUTINE LOAD test_db.label1 ON test_tbl\n    COLUMNS(k1, k2, tmp_k3, k3 = tmp_k3 + 1),\n    PRECEDING FILTER k1 = 1,\n    WHERE k1 > 1\n    ...\n"})}),"\n",(0,s.jsx)(e.h3,{id:"insert-into",children:"Insert Into"}),"\n",(0,s.jsxs)(e.p,{children:["Insert Into can directly perform data transformation in the ",(0,s.jsx)(e.code,{children:"SELECT"})," statement, using the ",(0,s.jsx)(e.code,{children:"WHERE"})," clause for data filtering."]}),"\n",(0,s.jsx)(e.h2,{id:"column-mapping",children:"Column Mapping"}),"\n",(0,s.jsx)(e.p,{children:"Column mapping is used to define the correspondence between source data columns and target table columns. It can handle the following scenarios:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"The order of source data columns and target table columns is inconsistent"}),"\n",(0,s.jsx)(e.li,{children:"The number of source data columns and target table columns is inconsistent"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"implementation-principle",children:"Implementation Principle"}),"\n",(0,s.jsx)(e.p,{children:"Column mapping implementation can be divided into two steps:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Step 1: Data Source Parsing"})," - Parse raw data into intermediate variables based on data format"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Step 2: Column Mapping and Assignment"})," - Map intermediate variables to target table fields by column name"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"The following are processing flows for three different data formats:"}),"\n",(0,s.jsx)(e.h4,{id:"load-csv-format-data",children:"Load CSV Format Data"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.img,{src:l(526083).Z+"",width:"1676",height:"1848"})}),"\n",(0,s.jsx)(e.h4,{id:"load-json-format-data-with-specified-jsonpaths",children:"Load JSON Format Data with Specified jsonpaths"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.img,{src:l(679134).Z+"",width:"1454",height:"1828"})}),"\n",(0,s.jsx)(e.h4,{id:"load-json-format-data-without-specified-jsonpaths",children:"Load JSON Format Data without Specified jsonpaths"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.img,{src:l(998599).Z+"",width:"1656",height:"1804"})}),"\n",(0,s.jsx)(e.h3,{id:"load-json-data-with-specified-jsonpaths",children:"Load JSON Data with Specified jsonpaths"}),"\n",(0,s.jsx)(e.p,{children:"Assume the following source data (column headers are for illustration only, no actual headers exist):"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:'{"k1":1,"k2":"100","k3":"beijing","k4":1.1}\n{"k1":2,"k2":"200","k3":"shanghai","k4":1.2}\n{"k1":3,"k2":"300","k3":"guangzhou","k4":1.3}\n{"k1":4,"k2":"\\\\N","k3":"chongqing","k4":1.4}\n'})}),"\n",(0,s.jsx)(e.h5,{id:"create-target-table",children:"Create Target Table"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE TABLE example_table\n(\n    col1 INT,\n    col2 STRING,\n    col3 INT,\n    col4 DOUBLE\n) ENGINE = OLAP\nDUPLICATE KEY(col1)\nDISTRIBUTED BY HASH(col1) BUCKETS 1;\n"})}),"\n",(0,s.jsx)(e.h5,{id:"load-data",children:"Load Data"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Stream Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'curl --location-trusted -u user:passwd \\\n    -H "columns:col1, col3, col2, col4" \\\n    -H "jsonpaths:[\\"$.k1\\", \\"$.k2\\", \\"$.k3\\", \\"$.k4\\"]" \\\n    -H "format:json" \\\n    -H "read_json_by_line:true" \\\n    -T data.json \\\n    -X PUT \\\n    http://<fe_ip>:<fe_http_port>/api/example_db/example_table/_stream_load\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Broker Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'LOAD LABEL example_db.label_broker\n(\n    DATA INFILE("s3://bucket_name/data.json")\n    INTO TABLE example_table\n    FORMAT AS "json"\n    (col1, col3, col2, col4)\n    PROPERTIES\n    (\n        "jsonpaths" = "[\\"$.k1\\", \\"$.k2\\", \\"$.k3\\", \\"$.k4\\"]"\n    )\n)\nWITH s3 (...);\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Routine Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'CREATE ROUTINE LOAD example_db.example_routine_load ON example_table\nCOLUMNS(col1, col3, col2, col4)\nPROPERTIES\n(\n    "format" = "json",\n    "jsonpaths" = "[\\"$.k1\\", \\"$.k2\\", \\"$.k3\\", \\"$.k4\\"]",\n    "read_json_by_line" = "true"\n)\nFROM KAFKA (...);\n'})}),"\n",(0,s.jsx)(e.h5,{id:"query-results",children:"Query Results"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"mysql> SELECT * FROM example_table;\n+------+-----------+------+------+\n| col1 | col2      | col3 | col4 |\n+------+-----------+------+------+\n|    1 | beijing   |  100 |  1.1 |\n|    2 | shanghai  |  200 |  1.2 |\n|    3 | guangzhou |  300 |  1.3 |\n|    4 | chongqing | NULL |  1.4 |\n+------+-----------+------+------+\n"})}),"\n",(0,s.jsx)(e.h3,{id:"load-json-data-without-specified-jsonpaths",children:"Load JSON Data without Specified jsonpaths"}),"\n",(0,s.jsx)(e.p,{children:"Assume the following source data (column headers are for illustration only, no actual headers exist):"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:'{"k1":1,"k2":"100","k3":"beijing","k4":1.1}\n{"k1":2,"k2":"200","k3":"shanghai","k4":1.2}\n{"k1":3,"k2":"300","k3":"guangzhou","k4":1.3}\n{"k1":4,"k2":"\\\\N","k3":"chongqing","k4":1.4}\n'})}),"\n",(0,s.jsx)(e.h5,{id:"create-target-table-1",children:"Create Target Table"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE TABLE example_table\n(\n    col1 INT,\n    col2 STRING,\n    col3 INT,\n    col4 DOUBLE\n) ENGINE = OLAP\nDUPLICATE KEY(col1)\nDISTRIBUTED BY HASH(col1) BUCKETS 1;\n"})}),"\n",(0,s.jsx)(e.h5,{id:"load-data-1",children:"Load Data"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Stream Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'curl --location-trusted -u user:passwd \\\n    -H "columns:k1, k3, k2, k4,col1 = k1, col2 = k3, col3 = k2, col4 = k4" \\\n    -H "format:json" \\\n    -H "read_json_by_line:true" \\\n    -T data.json \\\n    -X PUT \\\n    http://<fe_ip>:<fe_http_port>/api/example_db/example_table/_stream_load\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Broker Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'LOAD LABEL example_db.label_broker\n(\n    DATA INFILE("s3://bucket_name/data.json")\n    INTO TABLE example_table\n    FORMAT AS "json"\n    (k1, k3, k2, k4)\n    SET (\n        col1 = k1,\n        col2 = k3,\n        col3 = k2,\n        col4 = k4\n    )\n)\nWITH s3 (...);\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Routine Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'CREATE ROUTINE LOAD example_db.example_routine_load ON example_table\nCOLUMNS(k1, k3, k2, k4, col1 = k1, col2 = k3, col3 = k2, col4 = k4),\nPROPERTIES\n(\n    "format" = "json",\n    "read_json_by_line" = "true"\n)\nFROM KAFKA (...);\n'})}),"\n",(0,s.jsx)(e.h5,{id:"query-results-1",children:"Query Results"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"mysql> SELECT * FROM example_table;\n+------+-----------+------+------+\n| col1 | col2      | col3 | col4 |\n+------+-----------+------+------+\n|    1 | beijing   |  100 |  1.1 |\n|    2 | shanghai  |  200 |  1.2 |\n|    3 | guangzhou |  300 |  1.3 |\n|    4 | chongqing | NULL |  1.4 |\n+------+-----------+------+------+\n"})}),"\n",(0,s.jsx)(e.h3,{id:"adjusting-column-order",children:"Adjusting Column Order"}),"\n",(0,s.jsx)(e.p,{children:"Suppose we have the following source data (column names are for illustration purposes only, and there is no actual header):"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1,column2,column3,column4\n1,100,beijing,1.1\n2,200,shanghai,1.2\n3,300,guangzhou,1.3\n4,\\N,chongqing,1.4\n"})}),"\n",(0,s.jsx)(e.p,{children:"The target table has four columns: k1, k2, k3, and k4. We want to map the columns as follows:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1 -> k1\ncolumn2 -> k3\ncolumn3 -> k2\ncolumn4 -> k4\n"})}),"\n",(0,s.jsx)(e.h4,{id:"creating-the-target-table",children:"Creating the Target Table"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE TABLE example_table\n(\n    k1 INT,\n    k2 STRING,\n    k3 INT,\n    k4 DOUBLE\n) ENGINE = OLAP\nDUPLICATE KEY(k1)\nDISTRIBUTED BY HASH(k1) BUCKETS 1;\n"})}),"\n",(0,s.jsx)(e.h4,{id:"loading-data",children:"Loading Data"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Stream Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'curl --location-trusted -u user:passwd \\\n    -H "column_separator:," \\\n    -H "columns: k1,k3,k2,k4" \\\n    -T data.csv \\\n    -X PUT \\\n    http://<fe_ip>:<fe_http_port>/api/example_db/example_table/_stream_load\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Broker Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'LOAD LABEL example_db.label_broker\n(\n    DATA INFILE("s3://bucket_name/data.csv")\n    INTO TABLE example_table\n    COLUMNS TERMINATED BY ","\n    (k1, k3, k2, k4)\n)\nWITH s3 (...);\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Routine Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'CREATE ROUTINE LOAD example_db.example_routine_load ON example_table\nCOLUMNS(k1, k3, k2, k4),\nCOLUMNS TERMINATED BY ","\nFROM KAFKA (...);\n'})}),"\n",(0,s.jsx)(e.h4,{id:"query-results-2",children:"Query Results"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"mysql> select * from example_table;\n+------+-----------+------+------+\n| k1   | k2        | k3   | k4   |\n+------+-----------+------+------+\n|    2 | shanghai  |  200 |  1.2 |\n|    4 | chongqing | NULL |  1.4 |\n|    3 | guangzhou |  300 |  1.3 |\n|    1 | beijing   |  100 |  1.1 |\n+------+-----------+------+------+\n"})}),"\n",(0,s.jsx)(e.h3,{id:"source-file-columns-exceed-table-columns",children:"Source File Columns Exceed Table Columns"}),"\n",(0,s.jsx)(e.p,{children:"Suppose we have the following source data (column names are for illustration purposes only, and there is no actual header):"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1,column2,column3,column4\n1,100,beijing,1.1\n2,200,shanghai,1.2\n3,300,guangzhou,1.3\n4,\\N,chongqing,1.4\n"})}),"\n",(0,s.jsx)(e.p,{children:"The target table has three columns: k1, k2, and k3. We only need the first, second, and fourth columns from the source file, with the following mapping relationship:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1 -> k1\ncolumn2 -> k2\ncolumn4 -> k3\n"})}),"\n",(0,s.jsx)(e.p,{children:"To skip certain columns in the source file, you can use any column name that does not exist in the target table during column mapping. These column names can be customized and are not restricted. The data in these columns will be automatically ignored during loading."}),"\n",(0,s.jsx)(e.h4,{id:"creating-the-target-table-1",children:"Creating the Target Table"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE TABLE example_table\n(\n    k1 INT,\n    k2 STRING,\n    k3 DOUBLE\n) ENGINE = OLAP\nDUPLICATE KEY(k1)\nDISTRIBUTED BY HASH(k1) BUCKETS 1;\n"})}),"\n",(0,s.jsx)(e.h4,{id:"loading-data-1",children:"Loading Data"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Stream Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'curl --location-trusted -u usr:passwd \\\n    -H "column_separator:," \\\n    -H "columns: k1,k2,tmp_skip,k3" \\\n    -T data.csv \\\n    http://<fe_ip>:<fe_http_port>/api/example_db/example_table/_stream_load\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Broker Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'LOAD LABEL example_db.label_broker\n(\n    DATA INFILE("s3://bucket_name/data.csv")\n    INTO TABLE example_table\n    COLUMNS TERMINATED BY ","\n    (tmp_k1, tmp_k2, tmp_skip, tmp_k3)\n    SET (\n        k1 = tmp_k1,\n        k2 = tmp_k2,\n        k3 = tmp_k3\n    )\n)\nWITH s3 (...);\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Routine Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'CREATE ROUTINE LOAD example_db.example_routine_load ON example_table\nCOLUMNS(k1, k2, tmp_skip, k3),\nPROPERTIES\n(\n    "format" = "csv",\n    "column_separator" = ","\n)\nFROM KAFKA (...);\n'})}),"\n",(0,s.jsxs)(e.blockquote,{children:["\n",(0,s.jsxs)(e.p,{children:["Note: The ",(0,s.jsx)(e.code,{children:"tmp_skip"})," in the example can be replaced with any name, as long as it is not in the column definition of the target table."]}),"\n"]}),"\n",(0,s.jsx)(e.h4,{id:"query-results-3",children:"Query Results"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"mysql> select * from example_table;\n+------+------+------+\n| k1   | k2   | k3   |\n+------+------+------+\n|    1 | 100  |  1.1 |\n|    2 | 200  |  1.2 |\n|    3 | 300  |  1.3 |\n|    4 | NULL |  1.4 |\n+------+------+------+\n"})}),"\n",(0,s.jsx)(e.h3,{id:"source-file-columns-less-than-table-columns",children:"Source File Columns Less Than Table Columns"}),"\n",(0,s.jsx)(e.p,{children:"Suppose we have the following source data (column names are for illustration purposes only, and there is no actual header):"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1,column2,column3,column4\n1,100,beijing,1.1\n2,200,shanghai,1.2\n3,300,guangzhou,1.3\n4,\\N,chongqing,1.4\n"})}),"\n",(0,s.jsx)(e.p,{children:"The target table has five columns: k1, k2, k3, k4, and k5. We only need the first, second, third, and fourth columns from the source file, with the following mapping relationship:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1 -> k1\ncolumn2 -> k3\ncolumn3 -> k2\ncolumn4 -> k4\nk5 uses the default value\n"})}),"\n",(0,s.jsx)(e.h4,{id:"creating-the-target-table-2",children:"Creating the Target Table"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE TABLE example_table\n(\n    k1 INT,\n    k2 STRING,\n    k3 INT,\n    k4 DOUBLE,\n    k5 INT DEFAULT 2\n) ENGINE = OLAP\nDUPLICATE KEY(k1)\nDISTRIBUTED BY HASH(k1) BUCKETS 1;\n"})}),"\n",(0,s.jsx)(e.h4,{id:"loading-data-2",children:"Loading Data"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Stream Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'curl --location-trusted -u user:passwd \\\n    -H "column_separator:," \\\n    -H "columns: k1,k3,k2,k4" \\\n    -T data.csv \\\n    http://<fe_ip>:<fe_http_port>/api/example_db/example_table/_stream_load\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Broker Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'LOAD LABEL example_db.label_broker\n(\n    DATA INFILE("s3://bucket_name/data.csv")\n    INTO TABLE example_table\n    COLUMNS TERMINATED BY ","\n    (tmp_k1, tmp_k3, tmp_k2, tmp_k4)\n    SET (\n        k1 = tmp_k1,\n        k3 = tmp_k3,\n        k2 = tmp_k2,\n        k4 = tmp_k4\n    )\n)\nWITH s3 (...);\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Routine Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'CREATE ROUTINE LOAD example_db.example_routine_load ON example_table\nCOLUMNS(k1, k3, k2, k4),\nCOLUMNS TERMINATED BY ","\nFROM KAFKA (...);\n'})}),"\n",(0,s.jsx)(e.p,{children:"Note:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"If k5 has a default value, it will be filled with the default value"}),"\n",(0,s.jsx)(e.li,{children:"If k5 is a nullable column but has no default value, it will be filled with NULL"}),"\n",(0,s.jsx)(e.li,{children:"If k5 is a non-nullable column and has no default value, the load will fail"}),"\n"]}),"\n",(0,s.jsx)(e.h4,{id:"query-results-4",children:"Query Results"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"mysql> select * from example_table;\n+------+-----------+------+------+------+\n| k1   | k2        | k3   | k4   | k5   |\n+------+-----------+------+------+------+\n|    1 | beijing   |  100 |  1.1 |    2 |\n|    2 | shanghai  |  200 |  1.2 |    2 |\n|    3 | guangzhou |  300 |  1.3 |    2 |\n|    4 | chongqing | NULL |  1.4 |    2 |\n+------+-----------+------+------+------+\n"})}),"\n",(0,s.jsx)(e.h2,{id:"column-transformation",children:"Column Transformation"}),"\n",(0,s.jsx)(e.p,{children:"Column transformation allows users to transform column values in the source file, supporting the use of most built-in functions. Column transformation is usually defined together with column mapping, i.e., first map the columns and then transform them."}),"\n",(0,s.jsx)(e.h3,{id:"transforming-source-file-column-values-before-loading",children:"Transforming Source File Column Values Before Loading"}),"\n",(0,s.jsx)(e.p,{children:"Suppose we have the following source data (column names are for illustration purposes only, and there is no actual header):"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1,column2,column3,column4\n1,100,beijing,1.1\n2,200,shanghai,1.2\n3,300,guangzhou,1.3\n4,\\N,chongqing,1.4\n"})}),"\n",(0,s.jsx)(e.p,{children:"The target table has four columns: k1, k2, k3, and k4. We want to transform the column values as follows:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1 -> k1\ncolumn2 * 100 -> k3\ncolumn3 -> k2\ncolumn4 -> k4\n"})}),"\n",(0,s.jsx)(e.h4,{id:"creating-the-target-table-3",children:"Creating the Target Table"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE TABLE example_table\n(\n    k1 INT,\n    k2 STRING,\n    k3 INT,\n    k4 DOUBLE\n)\nENGINE = OLAP\nDUPLICATE KEY(k1)\nDISTRIBUTED BY HASH(k1) BUCKETS 1;\n"})}),"\n",(0,s.jsx)(e.h4,{id:"loading-data-3",children:"Loading Data"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Stream Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'curl --location-trusted -u user:passwd \\\n    -H "column_separator:," \\\n    -H "columns: k1, tmp_k3, k2, k4, k3 = tmp_k3 * 100" \\\n    -T data.csv \\\n    http://host:port/api/example_db/example_table/_stream_load\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Broker Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'LOAD LABEL example_db.label1\n(\n    DATA INFILE("s3://bucket_name/data.csv")\n    INTO TABLE example_table\n    COLUMNS TERMINATED BY ","\n    (k1, tmp_k3, k2, k4)\n    SET (\n        k3 = tmp_k3 * 100\n    )\n)\nWITH s3 (...);\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Routine Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'CREATE ROUTINE LOAD example_db.example_routine_load ON example_table\nCOLUMNS(k1, tmp_k3, k2, k4, k3 = tmp_k3 * 100),\nCOLUMNS TERMINATED BY ","\nFROM KAFKA (...);\n'})}),"\n",(0,s.jsx)(e.h4,{id:"query-results-5",children:"Query Results"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"mysql> select * from example_table;\n+------+------+-------+------+\n| k1   | k2   | k3    | k4   |\n+------+------+-------+------+\n|    1 | beijing   | 10000 |  1.1 |\n|    2 | shanghai  | 20000 |  1.2 |\n|    3 | guangzhou | 30000 |  1.3 |\n|    4 | chongqing |  NULL |  1.4 |\n+------+------+-------+------+\n"})}),"\n",(0,s.jsx)(e.h3,{id:"using-case-when-function-for-conditional-column-transformation",children:"Using Case When Function for Conditional Column Transformation"}),"\n",(0,s.jsx)(e.p,{children:"Suppose we have the following source data (column names are for illustration purposes only, and there is no actual header):"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1,column2,column3,column4\n1,100,beijing,1.1\n2,200,shanghai,1.2\n3,300,guangzhou,1.3\n4,\\N,chongqing,1.4\n"})}),"\n",(0,s.jsx)(e.p,{children:"The target table has four columns: k1, k2, k3, and k4. We want to transform the column values as follows:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1 -> k1\ncolumn2 -> k2\ncolumn3 -> k3 (transformed to area id)\ncolumn4 -> k4\n"})}),"\n",(0,s.jsx)(e.h4,{id:"creating-the-target-table-4",children:"Creating the Target Table"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE TABLE example_table\n(\n    k1 INT,\n    k2 INT,\n    k3 INT,\n    k4 DOUBLE\n)\nENGINE = OLAP\nDUPLICATE KEY(k1)\nDISTRIBUTED BY HASH(k1) BUCKETS 1;\n"})}),"\n",(0,s.jsx)(e.h4,{id:"loading-data-4",children:"Loading Data"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Stream Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"curl --location-trusted -u user:passwd \\\n    -H \"column_separator:,\" \\\n    -H \"columns: k1, k2, tmp_k3, k4, k3 = CASE tmp_k3 WHEN 'beijing' THEN 1 WHEN 'shanghai' THEN 2 WHEN 'guangzhou' THEN 3 WHEN 'chongqing' THEN 4 ELSE NULL END\" \\\n    -T data.csv \\\n    http://host:port/api/example_db/example_table/_stream_load\n"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Broker Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"LOAD LABEL example_db.label1\n(\n    DATA INFILE(\"s3://bucket_name/data.csv\")\n    INTO TABLE example_table\n    COLUMNS TERMINATED BY \",\"\n    (k1, k2, tmp_k3, k4)\n    SET (\n        k3 = CASE tmp_k3 WHEN 'beijing' THEN 1 WHEN 'shanghai' THEN 2 WHEN 'guangzhou' THEN 3 WHEN 'chongqing' THEN 4 ELSE NULL END\n    )\n)\nWITH s3 (...);\n"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Routine Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE ROUTINE LOAD example_db.example_routine_load ON example_table\nCOLUMNS(k1, k2, tmp_k3, k4, k3 = CASE tmp_k3 WHEN 'beijing' THEN 1 WHEN 'shanghai' THEN 2 WHEN 'guangzhou' THEN 3 WHEN 'chongqing' THEN 4 ELSE NULL END),\nCOLUMNS TERMINATED BY \",\"\nFROM KAFKA (...);\n"})}),"\n",(0,s.jsx)(e.h4,{id:"query-results-6",children:"Query Results"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"mysql> select * from example_table;\n+------+------+------+------+\n| k1   | k2   | k3   | k4   |\n+------+------+------+------+\n|    1 |  100 |    1 |  1.1 |\n|    2 |  200 |    2 |  1.2 |\n|    3 |  300 |    3 |  1.3 |\n|    4 | NULL |    4 |  1.4 |\n+------+------+------+------+\n"})}),"\n",(0,s.jsx)(e.h3,{id:"handling-null-values-in-source-files",children:"Handling NULL Values in Source Files"}),"\n",(0,s.jsx)(e.p,{children:"Suppose we have the following source data (column names are for illustration purposes only, and there is no actual header):"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1,column2,column3,column4\n1,100,beijing,1.1\n2,200,shanghai,1.2\n3,300,guangzhou,1.3\n4,\\N,chongqing,1.4\n"})}),"\n",(0,s.jsx)(e.p,{children:"The target table has four columns: k1, k2, k3, and k4. We want to transform the column values as follows:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1 -> k1 (transform NULL to 0)\ncolumn2 -> k2\ncolumn3 -> k3\ncolumn4 -> k4\n"})}),"\n",(0,s.jsx)(e.h4,{id:"creating-the-target-table-5",children:"Creating the Target Table"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE TABLE example_table\n(\n    k1 INT,\n    k2 INT,\n    k3 INT,\n    k4 DOUBLE\n)\nENGINE = OLAP\nDUPLICATE KEY(k1)\nDISTRIBUTED BY HASH(k1) BUCKETS 1;\n"})}),"\n",(0,s.jsx)(e.h4,{id:"loading-data-5",children:"Loading Data"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Stream Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"curl --location-trusted -u user:passwd \\\n    -H \"column_separator:,\" \\\n    -H \"columns: k1, tmp_k2, tmp_k3, k4, k2 = ifnull(tmp_k2, 0), k3 = CASE tmp_k3 WHEN 'beijing' THEN 1 WHEN 'shanghai' THEN 2 WHEN 'guangzhou' THEN 3 WHEN 'chongqing' THEN 4 ELSE NULL END\" \\\n    -T data.csv \\\n    http://host:port/api/example_db/example_table/_stream_load\n"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Broker Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"LOAD LABEL example_db.label1\n(\n    DATA INFILE(\"s3://bucket_name/data.csv\")\n    INTO TABLE example_table\n    COLUMNS TERMINATED BY \",\"\n    (k1, tmp_k2, tmp_k3, k4)\n    SET (\n        k2 = ifnull(tmp_k2, 0),\n        k3 = CASE tmp_k3 WHEN 'beijing' THEN 1 WHEN 'shanghai' THEN 2 WHEN 'guangzhou' THEN 3 WHEN 'chongqing' THEN 4 ELSE NULL END\n    )\n)\nWITH s3 (...);\n"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Routine Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE ROUTINE LOAD example_db.example_routine_load ON example_table\nCOLUMNS(k1, tmp_k2, tmp_k3, k4, k2 = ifnull(tmp_k2, 0), k3 = CASE tmp_k3 WHEN 'beijing' THEN 1 WHEN 'shanghai' THEN 2 WHEN 'guangzhou' THEN 3 WHEN 'chongqing' THEN 4 ELSE NULL END),\nCOLUMNS TERMINATED BY \",\"\nFROM KAFKA (...);\n"})}),"\n",(0,s.jsx)(e.h4,{id:"query-results-7",children:"Query Results"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"mysql> select * from example_table;\n+------+------+------+------+\n| k1   | k2   | k3   | k4   |\n+------+------+------+------+\n|    1 |  100 |    1 |  1.1 |\n|    2 |  200 |    2 |  1.2 |\n|    3 |  300 |    3 |  1.3 |\n|    4 |    0 |    4 |  1.4 |\n+------+------+------+------+\n"})}),"\n",(0,s.jsx)(e.h2,{id:"pre-filtering",children:"Pre-filtering"}),"\n",(0,s.jsx)(e.p,{children:"Pre-filtering is the process of filtering out unwanted raw data before column mapping and transformation. This feature is only supported in Broker Load and Routine Load."}),"\n",(0,s.jsx)(e.p,{children:"Pre-filtering has the following application scenarios:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Filtering before transformation"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Scenarios where filtering is needed before column mapping and transformation, allowing for the removal of unwanted data before processing."}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Filtering columns that do not exist in the table, only as filtering indicators"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"For example, source data contains multiple tables' data (or multiple tables' data is written to the same Kafka message queue). Each row of data has a column indicating which table the data belongs to. Users can use pre-filtering conditions to filter out the corresponding table data for loading."}),"\n",(0,s.jsx)(e.p,{children:"Pre-filtering has the following limitations:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Column filtering restrictions"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Pre-filtering can only filter independent simple columns in the column list and cannot filter columns with expressions. For example: when the column mapping is (a, tmp, b = tmp + 1), column b cannot be used as a filter condition."}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Data processing restrictions"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:["Pre-filtering occurs before data transformation, using raw data values for comparison, and raw data is treated as string type. For example: for data like ",(0,s.jsx)(e.code,{children:"\\N"}),", it will be compared directly as the ",(0,s.jsx)(e.code,{children:"\\N"})," string, rather than being converted to NULL before comparison."]}),"\n",(0,s.jsx)(e.h3,{id:"example-1-using-numeric-conditions-for-pre-filtering",children:"Example 1: Using Numeric Conditions for Pre-filtering"}),"\n",(0,s.jsx)(e.p,{children:"This example demonstrates how to filter source data using simple numeric comparison conditions. By setting the filter condition k1 > 1, we can filter out unwanted records before data transformation."}),"\n",(0,s.jsx)(e.p,{children:"Suppose we have the following source data (column names are for illustration purposes only, and there is no actual header):"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1,column2,column3,column4\n1,100,beijing,1.1\n2,200,shanghai,1.2\n3,300,guangzhou,1.3\n4,\\N,chongqing,1.4\n"})}),"\n",(0,s.jsx)(e.p,{children:"Pre-filtering condition:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"column1 > 1, i.e., only load data where column1 > 1, and filter out other data.\n"})}),"\n",(0,s.jsx)(e.h4,{id:"creating-the-target-table-6",children:"Creating the Target Table"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE TABLE example_table\n(\n    k1 INT,\n    k2 INT,\n    k3 STRING,\n    k4 DOUBLE\n)\nENGINE = OLAP\nDUPLICATE KEY(k1)\nDISTRIBUTED BY HASH(k1) BUCKETS 1;\n"})}),"\n",(0,s.jsx)(e.h4,{id:"loading-data-6",children:"Loading Data"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Broker Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'LOAD LABEL example_db.label1\n(\n    DATA INFILE("s3://bucket_name/data.csv")\n    INTO TABLE example_table\n    COLUMNS TERMINATED BY ","\n    (k1, k2, k3, k4)\n    PRECEDING FILTER k1 > 1\n)\nWITH s3 (...);\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Routine Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'CREATE ROUTINE LOAD example_db.example_routine_load ON example_table\nCOLUMNS(k1, k2, k3, k4),\nCOLUMNS TERMINATED BY ","\nPRECEDING FILTER k1 > 1\nFROM KAFKA (...)\n'})}),"\n",(0,s.jsx)(e.h4,{id:"query-results-8",children:"Query Results"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"mysql> select * from example_table;\n+------+------+-----------+------+\n| k1   | k2   | k3        | k4   |\n+------+------+-----------+------+\n|    2 |  200 | shanghai  |  1.2 |\n|    3 |  300 | guangzhou |  1.3 |\n|    4 | NULL | chongqing |  1.4 |\n+------+------+-----------+------+\n"})}),"\n",(0,s.jsx)(e.h3,{id:"example-2-using-intermediate-columns-to-filter-invalid-data",children:"Example 2: Using Intermediate Columns to Filter Invalid Data"}),"\n",(0,s.jsx)(e.p,{children:"This example demonstrates how to handle data import scenarios containing invalid data."}),"\n",(0,s.jsx)(e.p,{children:"Source data:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",metastring:"text",children:"1,1\n2,abc\n3,3\n"})}),"\n",(0,s.jsx)(e.h4,{id:"table-creation",children:"Table Creation"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE TABLE example_table\n(\n    k1 INT,\n    k2 INT NOT NULL\n)\nENGINE = OLAP\nDUPLICATE KEY(k1)\nDISTRIBUTED BY HASH(k1) BUCKETS 1;\n"})}),"\n",(0,s.jsxs)(e.p,{children:["For column k2, which is of type INT, ",(0,s.jsx)(e.code,{children:"abc"})," is invalid dirty data. To filter this data, we can introduce an intermediate column for filtering."]}),"\n",(0,s.jsx)(e.h4,{id:"load-statements",children:"Load Statements"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Broker Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'LOAD LABEL example_db.label1\n(\n    DATA INFILE("s3://bucket_name/data.csv")\n    INTO TABLE example_table\n    COLUMNS TERMINATED BY ","\n    (k1, tmp, k2 = tmp)\n    PRECEDING FILTER tmp != "abc"\n)\nWITH s3 (...);\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Routine Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'CREATE ROUTINE LOAD example_db.example_routine_load ON example_table\nCOLUMNS(k1, tmp, k2 = tmp),\nCOLUMNS TERMINATED BY ","\nPRECEDING FILTER tmp != "abc"\nFROM KAFKA (...);\n'})}),"\n",(0,s.jsx)(e.h4,{id:"load-results",children:"Load Results"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"mysql> select * from example_table;\n+------+----+\n| k1   | k2 |\n+------+----+\n|    1 |  1 |\n|    3 |  3 |\n+------+----+\n"})}),"\n",(0,s.jsx)(e.h2,{id:"post-filtering",children:"Post-filtering"}),"\n",(0,s.jsx)(e.p,{children:"Post-filtering is the process of filtering the final results after column mapping and transformation."}),"\n",(0,s.jsx)(e.h3,{id:"filtering-without-column-mapping-and-transformation",children:"Filtering Without Column Mapping and Transformation"}),"\n",(0,s.jsx)(e.p,{children:"Suppose we have the following source data (column names are for illustration purposes only, and there is no actual header):"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1,column2,column3,column4\n1,100,beijing,1.1\n2,200,shanghai,1.2\n3,300,guangzhou,1.3\n4,\\N,chongqing,1.4\n"})}),"\n",(0,s.jsx)(e.p,{children:"The target table has four columns: k1, k2, k3, and k4. We want to load only the data where the fourth column is greater than 1.2."}),"\n",(0,s.jsx)(e.h4,{id:"creating-the-target-table-7",children:"Creating the Target Table"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE TABLE example_table\n(\n    k1 INT,\n    k2 INT,\n    k3 STRING,\n    k4 DOUBLE\n)\nENGINE = OLAP\nDUPLICATE KEY(k1)\nDISTRIBUTED BY HASH(k1) BUCKETS 1;\n"})}),"\n",(0,s.jsx)(e.h4,{id:"loading-data-7",children:"Loading Data"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Stream Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'curl --location-trusted -u user:passwd \\\n    -H "column_separator:," \\\n    -H "columns: k1, k2, k3, k4" \\\n    -H "where: k4 > 1.2" \\\n    -T data.csv \\\n    http://host:port/api/example_db/example_table/_stream_load\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Broker Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'LOAD LABEL example_db.label1\n(\n    DATA INFILE("s3://bucket_name/data.csv")\n    INTO TABLE example_table\n    COLUMNS TERMINATED BY ","\n    (k1, k2, k3, k4)\n    where k4 > 1.2\n)\nWITH s3 (...);\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Routine Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'CREATE ROUTINE LOAD example_db.example_routine_load ON example_table\nCOLUMNS(k1, k2, k3, k4),\nCOLUMNS TERMINATED BY ","\nWHERE k4 > 1.2;\nFROM KAFKA (...)\n'})}),"\n",(0,s.jsx)(e.h4,{id:"query-results-9",children:"Query Results"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"mysql> select * from example_table;\n+------+------+-----------+------+\n| k1   | k2   | k3        | k4   |\n+------+------+-----------+------+\n|    3 |  300 | guangzhou |  1.3 |\n|    4 | NULL | chongqing |  1.4 |\n+------+------+-----------+------+\n"})}),"\n",(0,s.jsx)(e.h3,{id:"filtering-transformed-data",children:"Filtering Transformed Data"}),"\n",(0,s.jsx)(e.p,{children:"Suppose we have the following source data (column names are for illustration purposes only, and there is no actual header):"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1,column2,column3,column4\n1,100,beijing,1.1\n2,200,shanghai,1.2\n3,300,guangzhou,1.3\n4,\\N,chongqing,1.4\n"})}),"\n",(0,s.jsx)(e.p,{children:"The target table has four columns: k1, k2, k3, and k4. We want to transform the column values as follows:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1 -> k1\ncolumn2 -> k2\ncolumn3 -> k3 (transformed to area id)\ncolumn4 -> k4\n"})}),"\n",(0,s.jsx)(e.p,{children:"We want to filter out the data where the transformed k3 value is 3."}),"\n",(0,s.jsx)(e.h4,{id:"creating-the-target-table-8",children:"Creating the Target Table"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE TABLE example_table\n(\n    k1 INT,\n    k2 INT,\n    k3 INT,\n    k4 DOUBLE\n)\nENGINE = OLAP\nDUPLICATE KEY(k1)\nDISTRIBUTED BY HASH(k1) BUCKETS 1;\n"})}),"\n",(0,s.jsx)(e.h4,{id:"loading-data-8",children:"Loading Data"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Stream Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"curl --location-trusted -u user:passwd \\\n    -H \"column_separator:,\" \\\n    -H \"columns: k1, k2, tmp_k3, k4, k3 = case tmp_k3 when 'beijing' then 1 when 'shanghai' then 2 when 'guangzhou' then 3 when 'chongqing' then 4 else null end\" \\\n    -H \"where: k3 != 3\" \\\n    -T data.csv \\\n    http://host:port/api/example_db/example_table/_stream_load\n"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Broker Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"LOAD LABEL example_db.label1\n(\n    DATA INFILE(\"s3://bucket_name/data.csv\")\n    INTO TABLE example_table\n    COLUMNS TERMINATED BY \",\"\n    (k1, k2, tmp_k3, k4)\n    SET (\n        k3 = CASE tmp_k3 WHEN 'beijing' THEN 1 WHEN 'shanghai' THEN 2 WHEN 'guangzhou' THEN 3 WHEN 'chongqing' THEN 4 ELSE NULL END\n    )\n    WHERE k3 != 3\n)\nWITH s3 (...); \n"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Routine Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE ROUTINE LOAD example_db.example_routine_load ON example_table\nCOLUMNS(k1, k2, tmp_k3, k4),\nCOLUMNS TERMINATED BY \",\"\nSET (\n    k3 = CASE tmp_k3 WHEN 'beijing' THEN 1 WHEN 'shanghai' THEN 2 WHEN 'guangzhou' THEN 3 WHEN 'chongqing' THEN 4 ELSE NULL END\n)\nWHERE k3 != 3;\nFROM KAFKA (...)\n"})}),"\n",(0,s.jsx)(e.h4,{id:"query-results-10",children:"Query Results"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"mysql> select * from example_table;\n+------+------+------+------+\n| k1   | k2   | k3   | k4   |\n+------+------+------+------+\n|    1 |  100 |    1 |  1.1 |\n|    2 |  200 |    2 |  1.2 |\n|    4 | NULL |    4 |  1.4 |\n+------+------+------+------+\n"})}),"\n",(0,s.jsx)(e.h3,{id:"multiple-conditions-filtering",children:"Multiple Conditions Filtering"}),"\n",(0,s.jsx)(e.p,{children:"Suppose we have the following source data (column names are for illustration purposes only, and there is no actual header):"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-plain",children:"column1,column2,column3,column4\n1,100,beijing,1.1\n2,200,shanghai,1.2\n3,300,guangzhou,1.3\n4,\\N,chongqing,1.4\n"})}),"\n",(0,s.jsx)(e.p,{children:"The target table has four columns: k1, k2, k3, and k4. We want to filter out the data where k1 is NULL and k4 is less than 1.2."}),"\n",(0,s.jsx)(e.h4,{id:"creating-the-target-table-9",children:"Creating the Target Table"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:"CREATE TABLE example_table\n(\n    k1 INT,\n    k2 INT,\n    k3 STRING,\n    k4 DOUBLE\n)\nENGINE = OLAP\nDUPLICATE KEY(k1)\nDISTRIBUTED BY HASH(k1) BUCKETS 1;\n"})}),"\n",(0,s.jsx)(e.h4,{id:"loading-data-9",children:"Loading Data"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Stream Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'curl --location-trusted -u user:passwd \\\n    -H "column_separator:," \\\n    -H "columns: k1, k2, k3, k4" \\\n    -H "where: k1 is not null and k4 > 1.2" \\\n    -T data.csv \\\n    http://host:port/api/example_db/example_table/_stream_load\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Broker Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'LOAD LABEL example_db.label1\n(\n    DATA INFILE("s3://bucket_name/data.csv")\n    INTO TABLE example_table\n    COLUMNS TERMINATED BY ","\n    (k1, k2, k3, k4)\n    where k1 is not null and k4 > 1.2\n)\nWITH s3 (...);\n'})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Routine Load"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-sql",children:'CREATE ROUTINE LOAD example_db.example_routine_load ON example_table\nCOLUMNS(k1, k2, k3, k4),\nCOLUMNS TERMINATED BY ","\nWHERE k1 is not null and k4 > 1.2\nFROM KAFKA (...);\n'})}),"\n",(0,s.jsx)(e.h4,{id:"query-results-11",children:"Query Results"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"mysql> select * from example_table;\n+------+------+-----------+------+\n| k1   | k2   | k3        | k4   |\n+------+------+-----------+------+\n|    3 |  300 | guangzhou |  1.3 |\n|    4 | NULL | chongqing |  1.4 |\n+------+------+-----------+------+\n"})})]})}function h(n={}){let{wrapper:e}={...(0,i.a)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(c,{...n})}):c(n)}},526083:function(n,e,l){l.d(e,{Z:function(){return a}});let a=l.p+"assets/images/load-data-convert-csv-en-240a780c39bd04be64d4938f2a83ee43.png"},679134:function(n,e,l){l.d(e,{Z:function(){return a}});let a=l.p+"assets/images/load-data-convert-json1-en-bbc9562530e83faddc3b89a8a8f46f6d.png"},998599:function(n,e,l){l.d(e,{Z:function(){return a}});let a=l.p+"assets/images/load-data-convert-json2-en-fb63233122799e3d058e8eee946fa19f.png"},250065:function(n,e,l){l.d(e,{Z:function(){return r},a:function(){return t}});var a=l(667294);let s={},i=a.createContext(s);function t(n){let e=a.useContext(i);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:t(n.components),a.createElement(i.Provider,{value:e},n.children)}}}]);