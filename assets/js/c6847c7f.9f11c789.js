"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["724188"],{585756:function(e,n,s){s.r(n),s.d(n,{default:()=>h,frontMatter:()=>l,metadata:()=>t,assets:()=>c,toc:()=>o,contentTitle:()=>r});var t=JSON.parse('{"id":"lakehouse/file-analysis","title":"Analyze Files on S3/HDFS","description":"Through the Table Value Function feature, Doris can directly query and analyze files on object storage or HDFS as a Table. It also supports automatic column type inference.","source":"@site/versioned_docs/version-2.1/lakehouse/file-analysis.md","sourceDirName":"lakehouse","slug":"/lakehouse/file-analysis","permalink":"/docs/2.1/lakehouse/file-analysis","draft":false,"unlisted":false,"tags":[],"version":"2.1","frontMatter":{"title":"Analyze Files on S3/HDFS","language":"en"},"sidebar":"docs","previous":{"title":"Oceanbase JDBC Catalog","permalink":"/docs/2.1/lakehouse/catalogs/jdbc-oceanbase-catalog"},"next":{"title":"Hive Metastore","permalink":"/docs/2.1/lakehouse/metastores/hive-metastore"}}'),a=s("785893"),i=s("250065");let l={title:"Analyze Files on S3/HDFS",language:"en"},r=void 0,c={},o=[{value:"Basic Usage",id:"basic-usage",level:2},{value:"Query",id:"query",level:3},{value:"Automatic Inference of File Column Types",id:"automatic-inference-of-file-column-types",level:3},{value:"Applicable Scenarios",id:"applicable-scenarios",level:2},{value:"Query Analysis",id:"query-analysis",level:3},{value:"Data Import",id:"data-import",level:3},{value:"Notes",id:"notes",level:2}];function d(e){let n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.p,{children:"Through the Table Value Function feature, Doris can directly query and analyze files on object storage or HDFS as a Table. It also supports automatic column type inference."}),"\n",(0,a.jsx)(n.p,{children:"For more usage methods, refer to the Table Value Function documentation:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"/docs/2.1/sql-manual/sql-functions/table-valued-functions/s3",children:"S3"}),": Supports file analysis on S3-compatible object storage."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"/docs/2.1/sql-manual/sql-functions/table-valued-functions/hdfs",children:"HDFS"}),": Supports file analysis on HDFS."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"../sql-manual/sql-functions/table-valued-functions/file.md",children:"FILE"}),": Unified table function, which can support reading S3/HDFS/Local files at the same time. (Supported since version 3.1.0.)"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,a.jsx)(n.p,{children:"Here we illustrate how to analyze files on object storage using the S3 Table Value Function as an example."}),"\n",(0,a.jsx)(n.h3,{id:"query",children:"Query"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"SELECT * FROM S3 (\n    'uri' = 's3://bucket/path/to/tvf_test/test.parquet',\n    'format' = 'parquet',\n    's3.endpoint' = 'https://s3.us-east-1.amazonaws.com',\n    's3.region' = 'us-east-1',\n    's3.access_key' = 'ak',\n    's3.secret_key'='sk'\n)\n"})}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"S3(...)"}),' is a TVF (Table Value Function). A Table Value Function is essentially a table, so it can appear in any SQL statement where a "table" can appear.']}),"\n",(0,a.jsx)(n.p,{children:"The attributes of a TVF include the file path to be analyzed, file format, connection information of the object storage, etc. The file path (URI) can use wildcards to match multiple files. The following file paths are valid:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Match a specific file"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.code,{children:"s3://bucket/path/to/tvf_test/test.parquet"})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Match all files starting with ",(0,a.jsx)(n.code,{children:"test_"})]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.code,{children:"s3://bucket/path/to/tvf_test/test_*"})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Match all files with the ",(0,a.jsx)(n.code,{children:".parquet"})," suffix"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.code,{children:"s3://bucket/path/to/tvf_test/*.parquet"})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Match all files in the ",(0,a.jsx)(n.code,{children:"tvf_test"})," directory"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.code,{children:"s3://bucket/path/to/tvf_test/*"})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Match files with ",(0,a.jsx)(n.code,{children:"test"})," in the filename"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.code,{children:"s3://bucket/path/to/tvf_test/*test*"})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"automatic-inference-of-file-column-types",children:"Automatic Inference of File Column Types"}),"\n",(0,a.jsxs)(n.p,{children:["You can view the Schema of a TVF using the ",(0,a.jsx)(n.code,{children:"DESC FUNCTION"})," syntax:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:'DESC FUNCTION s3 (\n    "URI" = "s3://bucket/path/to/tvf_test/test.parquet",\n    "s3.access_key"= "ak",\n    "s3.secret_key" = "sk",\n    "format" = "parquet",\n    "use_path_style"="true"\n);\n+---------------+--------------+------+-------+---------+-------+\n| Field         | Type         | Null | Key   | Default | Extra |\n+---------------+--------------+------+-------+---------+-------+\n| p_partkey     | INT          | Yes  | false | NULL    | NONE  |\n| p_name        | TEXT         | Yes  | false | NULL    | NONE  |\n| p_mfgr        | TEXT         | Yes  | false | NULL    | NONE  |\n| p_brand       | TEXT         | Yes  | false | NULL    | NONE  |\n| p_type        | TEXT         | Yes  | false | NULL    | NONE  |\n| p_size        | INT          | Yes  | false | NULL    | NONE  |\n| p_container   | TEXT         | Yes  | false | NULL    | NONE  |\n| p_retailprice | DECIMAL(9,0) | Yes  | false | NULL    | NONE  |\n| p_comment     | TEXT         | Yes  | false | NULL    | NONE  |\n+---------------+--------------+------+-------+---------+-------+\n'})}),"\n",(0,a.jsx)(n.p,{children:"Doris infers the Schema based on the following rules:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"For Parquet and ORC formats, Doris obtains the Schema from the file metadata."}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"In the case of matching multiple files, the Schema of the first file is used as the TVF's Schema."}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["For CSV and JSON formats, Doris parses the ",(0,a.jsx)(n.strong,{children:"first line of data"})," to obtain the Schema based on fields, delimiters, etc."]}),"\n",(0,a.jsxs)(n.p,{children:["By default, all column types are ",(0,a.jsx)(n.code,{children:"string"}),". You can specify column names and types individually using the ",(0,a.jsx)(n.code,{children:"csv_schema"})," attribute. Doris will use the specified column types for file reading. The format is: ",(0,a.jsx)(n.code,{children:"name1:type1;name2:type2;..."}),". For example:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"S3 (\n    'uri' = 's3://bucket/path/to/tvf_test/test.parquet',\n    's3.endpoint' = 'https://s3.us-east-1.amazonaws.com',\n    's3.region' = 'us-east-1',\n    's3.access_key' = 'ak'\n    's3.secret_key'='sk',\n    'format' = 'csv',\n    'column_separator' = '|',\n    'csv_schema' = 'k1:int;k2:int;k3:int;k4:decimal(38,10)'\n)\n"})}),"\n",(0,a.jsx)(n.p,{children:"The currently supported column type names are as follows:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsx)(n.tr,{children:(0,a.jsx)(n.th,{children:"Column Type Name"})})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsx)(n.tr,{children:(0,a.jsx)(n.td,{children:"tinyint"})}),(0,a.jsx)(n.tr,{children:(0,a.jsx)(n.td,{children:"smallint"})}),(0,a.jsx)(n.tr,{children:(0,a.jsx)(n.td,{children:"int"})}),(0,a.jsx)(n.tr,{children:(0,a.jsx)(n.td,{children:"bigint"})}),(0,a.jsx)(n.tr,{children:(0,a.jsx)(n.td,{children:"largeint"})}),(0,a.jsx)(n.tr,{children:(0,a.jsx)(n.td,{children:"float"})}),(0,a.jsx)(n.tr,{children:(0,a.jsx)(n.td,{children:"double"})}),(0,a.jsx)(n.tr,{children:(0,a.jsx)(n.td,{children:"decimal(p,s)"})}),(0,a.jsx)(n.tr,{children:(0,a.jsx)(n.td,{children:"date"})}),(0,a.jsx)(n.tr,{children:(0,a.jsx)(n.td,{children:"datetime"})}),(0,a.jsx)(n.tr,{children:(0,a.jsx)(n.td,{children:"char"})}),(0,a.jsx)(n.tr,{children:(0,a.jsx)(n.td,{children:"varchar"})}),(0,a.jsx)(n.tr,{children:(0,a.jsx)(n.td,{children:"string"})}),(0,a.jsx)(n.tr,{children:(0,a.jsx)(n.td,{children:"boolean"})})]})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["For columns with mismatched formats (e.g., the file contains a string, but the user defines it as ",(0,a.jsx)(n.code,{children:"int"}),"; or other files have a different Schema than the first file), or missing columns (e.g., the file has 4 columns, but the user defines 5 columns), these columns will return ",(0,a.jsx)(n.code,{children:"null"}),"."]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"applicable-scenarios",children:"Applicable Scenarios"}),"\n",(0,a.jsx)(n.h3,{id:"query-analysis",children:"Query Analysis"}),"\n",(0,a.jsx)(n.p,{children:"TVF is very suitable for directly analyzing independent files on storage systems without having to import the data into Doris in advance."}),"\n",(0,a.jsx)(n.p,{children:"You can use any SQL statement for file analysis, such as:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"SELECT * FROM s3(\n    'uri' = 's3://bucket/path/to/tvf_test/test.parquet',\n    'format' = 'parquet',\n    's3.endpoint' = 'https://s3.us-east-1.amazonaws.com',\n    's3.region' = 'us-east-1',\n    's3.access_key' = 'ak',\n    's3.secret_key'='sk'\n)\nORDER BY p_partkey LIMIT 5;\n+-----------+------------------------------------------+----------------+----------+-------------------------+--------+-------------+---------------+---------------------+\n| p_partkey | p_name                                   | p_mfgr         | p_brand  | p_type                  | p_size | p_container | p_retailprice | p_comment           |\n+-----------+------------------------------------------+----------------+----------+-------------------------+--------+-------------+---------------+---------------------+\n|         1 | goldenrod lavender spring chocolate lace | Manufacturer#1 | Brand#13 | PROMO BURNISHED COPPER  |      7 | JUMBO PKG   |           901 | ly. slyly ironi     |\n|         2 | blush thistle blue yellow saddle         | Manufacturer#1 | Brand#13 | LARGE BRUSHED BRASS     |      1 | LG CASE     |           902 | lar accounts amo    |\n|         3 | spring green yellow purple cornsilk      | Manufacturer#4 | Brand#42 | STANDARD POLISHED BRASS |     21 | WRAP CASE   |           903 | egular deposits hag |\n|         4 | cornflower chocolate smoke green pink    | Manufacturer#3 | Brand#34 | SMALL PLATED BRASS      |     14 | MED DRUM    |           904 | p furiously r       |\n|         5 | forest brown coral puff cream            | Manufacturer#3 | Brand#32 | STANDARD POLISHED TIN   |     15 | SM PKG      |           905 |  wake carefully     |\n+-----------+------------------------------------------+----------------+----------+-------------------------+--------+-------------+---------------+---------------------+\n"})}),"\n",(0,a.jsxs)(n.p,{children:["TVF can appear in any position in SQL where a Table can appear, such as in the ",(0,a.jsx)(n.code,{children:"WITH"})," clause of a ",(0,a.jsx)(n.code,{children:"CTE"}),", in the ",(0,a.jsx)(n.code,{children:"FROM"})," clause, etc. This way, you can treat the file as a regular table for any analysis."]}),"\n",(0,a.jsxs)(n.p,{children:["You can also create a logical view for a TVF using the ",(0,a.jsx)(n.code,{children:"CREATE VIEW"})," statement. After that, you can access this TVF like other views, manage permissions, etc., and allow other users to access this View without having to repeatedly write connection information and other attributes."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"-- Create a view based on a TVF\nCREATE VIEW tvf_view AS \nSELECT * FROM s3(\n    'uri' = 's3://bucket/path/to/tvf_test/test.parquet',\n    'format' = 'parquet',\n    's3.endpoint' = 'https://s3.us-east-1.amazonaws.com',\n    's3.region' = 'us-east-1',\n    's3.access_key' = 'ak',\n    's3.secret_key'='sk'\n);\n\n-- Describe the view as usual\nDESC tvf_view;\n\n-- Query the view as usual\nSELECT * FROM tvf_view;\n\n-- Grant SELECT priv to other user on this view\nGRANT SELECT_PRIV ON db.tvf_view TO other_user;\n"})}),"\n",(0,a.jsx)(n.h3,{id:"data-import",children:"Data Import"}),"\n",(0,a.jsxs)(n.p,{children:["TVF can be used as a method for data import into Doris. With the ",(0,a.jsx)(n.code,{children:"INSERT INTO SELECT"})," syntax, we can easily import files into Doris."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"-- Create a Doris table\nCREATE TABLE IF NOT EXISTS test_table\n(\n    id int,\n    name varchar(50),\n    age int\n)\nDISTRIBUTED BY HASH(id) BUCKETS 4\nPROPERTIES(\"replication_num\" = \"1\");\n\n-- 2. Load data into table from TVF\nINSERT INTO test_table (id,name,age)\nSELECT cast(id as INT) as id, name, cast (age as INT) as age\nFROM s3(\n    'uri' = 's3://bucket/path/to/tvf_test/test.parquet',\n    'format' = 'parquet',\n    's3.endpoint' = 'https://s3.us-east-1.amazonaws.com',\n    's3.region' = 'us-east-1',\n    's3.access_key' = 'ak',\n    's3.secret_key'='sk'\n);\n"})}),"\n",(0,a.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["If the specified ",(0,a.jsx)(n.code,{children:"uri"})," does not match any files, or all matched files are empty, the TVF will return an empty result set. In this case, using ",(0,a.jsx)(n.code,{children:"DESC FUNCTION"})," to view the Schema of this TVF will yield a virtual column ",(0,a.jsx)(n.code,{children:"__dummy_col"}),", which is meaningless and only serves as a placeholder."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["If the specified file format is ",(0,a.jsx)(n.code,{children:"csv"}),", and the file read is not empty but the first line of the file is empty, an error ",(0,a.jsx)(n.code,{children:"The first line is empty, can not parse column numbers"})," will be prompted, as the Schema cannot be parsed from the first line of the file."]}),"\n"]}),"\n"]})]})}function h(e={}){let{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},250065:function(e,n,s){s.d(n,{Z:function(){return r},a:function(){return l}});var t=s(667294);let a={},i=t.createContext(a);function l(e){let n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:l(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);