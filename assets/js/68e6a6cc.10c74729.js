"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["234148"],{372138:function(e,a,s){s.r(a),s.d(a,{default:()=>b,frontMatter:()=>r,metadata:()=>t,assets:()=>c,toc:()=>o,contentTitle:()=>l});var t=JSON.parse('{"id":"lakehouse/best-practices/doris-aws-s3tables","title":"Integration with Glue + AWS S3 Tables","description":"AWS S3 Tables is a special type of S3 Bucket that provides read and write interfaces compatible with Apache Iceberg table format standards,","source":"@site/versioned_docs/version-2.1/lakehouse/best-practices/doris-aws-s3tables.md","sourceDirName":"lakehouse/best-practices","slug":"/lakehouse/best-practices/doris-aws-s3tables","permalink":"/docs/2.1/lakehouse/best-practices/doris-aws-s3tables","draft":false,"unlisted":false,"tags":[],"version":"2.1","lastUpdatedAt":1770477659000,"frontMatter":{"title":"Integration with Glue + AWS S3 Tables","language":"en","description":"AWS S3 Tables is a special type of S3 Bucket that provides read and write interfaces compatible with Apache Iceberg table format standards,"},"sidebar":"docs","previous":{"title":"Using Doris and LakeSoul","permalink":"/docs/2.1/lakehouse/best-practices/doris-lakesoul"},"next":{"title":"Integration with Aliyun DLF Rest Catalog","permalink":"/docs/2.1/lakehouse/best-practices/doris-dlf-paimon"}}'),n=s("785893"),i=s("250065");let r={title:"Integration with Glue + AWS S3 Tables",language:"en",description:"AWS S3 Tables is a special type of S3 Bucket that provides read and write interfaces compatible with Apache Iceberg table format standards,"},l=void 0,c={},o=[{value:"Usage Guide",id:"usage-guide",level:2},{value:"01 Create S3 Table Bucket",id:"01-create-s3-table-bucket",level:3},{value:"02 Create Iceberg Catalog",id:"02-create-iceberg-catalog",level:3},{value:"03 Access S3Tables",id:"03-access-s3tables",level:3},{value:"04 Create S3Tables Table and Write Data",id:"04-create-s3tables-table-and-write-data",level:3},{value:"05 Time Travel",id:"05-time-travel",level:3},{value:"06 Access S3 Tables Using EMR Spark",id:"06-access-s3-tables-using-emr-spark",level:3}];function d(e){let a={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.a)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(a.p,{children:[(0,n.jsx)(a.a,{href:"https://aws.amazon.com/s3/features/tables/",children:"AWS S3 Tables"})," is a special type of S3 Bucket that provides read and write interfaces compatible with Apache Iceberg table format standards, built on Amazon S3, offering the same durability, availability, scalability, and performance characteristics as S3 itself. Additionally, S3 Tables provides the following features:"]}),"\n",(0,n.jsxs)(a.ul,{children:["\n",(0,n.jsx)(a.li,{children:"Compared to Iceberg tables stored in regular S3 Buckets, S3 Tables can deliver up to 3x higher query performance and up to 10x higher transactions per second."}),"\n",(0,n.jsx)(a.li,{children:"Automated table management. S3 Tables automatically optimizes Iceberg table data, including small file compaction, snapshot management, and garbage file cleanup."}),"\n"]}),"\n",(0,n.jsx)(a.p,{children:"The release of S3 Tables further simplifies Lakehouse architecture and brings more possibilities for cloud-native lake-warehouse systems. This includes cold-hot separation, data archiving, data backup, and compute-storage separation architectures, all of which could evolve into entirely new architectures based on S3 Tables."}),"\n",(0,n.jsx)(a.p,{children:"Thanks to Amazon S3 Tables' high compatibility with the Iceberg API, Apache Doris can quickly integrate with S3 Tables. This article will demonstrate how to connect Apache Doris with S3 Tables and perform data analysis and processing."}),"\n",(0,n.jsx)(a.admonition,{type:"tip",children:(0,n.jsx)(a.p,{children:"This feature is supported since Doris 3.1"})}),"\n",(0,n.jsx)(a.h2,{id:"usage-guide",children:"Usage Guide"}),"\n",(0,n.jsx)(a.h3,{id:"01-create-s3-table-bucket",children:"01 Create S3 Table Bucket"}),"\n",(0,n.jsx)(a.p,{children:"S3 Table Bucket is the third type of Bucket launched by S3, on par with the previous General purpose bucket and Directory bucket."}),"\n",(0,n.jsx)(a.p,{children:(0,n.jsx)(a.img,{alt:"AWS S3 Table Bucket",src:s(929807).Z+"",width:"490",height:"600"})}),"\n",(0,n.jsx)(a.p,{children:"Here we create a Table Bucket named doris-s3-table-bucket. After creation, we will get a Table Bucket represented by an ARN."}),"\n",(0,n.jsx)(a.p,{children:(0,n.jsx)(a.img,{alt:"AWS S3 Table Bucket Create",src:s(569416).Z+"",width:"1280",height:"129"})}),"\n",(0,n.jsx)(a.h3,{id:"02-create-iceberg-catalog",children:"02 Create Iceberg Catalog"}),"\n",(0,n.jsxs)(a.ul,{children:["\n",(0,n.jsxs)(a.li,{children:["\n",(0,n.jsxs)(a.p,{children:["Create an Iceberg Catalog of type ",(0,n.jsx)(a.code,{children:"s3tables"})]}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-sql",children:"CREATE CATALOG iceberg_s3 PROPERTIES (\n    'type' = 'iceberg',\n    'iceberg.catalog.type' = 's3tables',\n    'warehouse' = 'arn:aws:s3tables:<region>:<acount_id>:bucket/<s3_table_bucket_name>',\n    's3.region' = '<region>',\n    's3.endpoint' = 's3.<region>.amazonaws.com',\n    's3.access_key' = '<ak>',\n    's3.secret_key' = '<sk>'\n);\n"})}),"\n"]}),"\n",(0,n.jsxs)(a.li,{children:["\n",(0,n.jsxs)(a.p,{children:["Connecting to ",(0,n.jsx)(a.code,{children:"s3 tables"})," using Glue Rest Catalog"]}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-sql",children:"CREATE CATALOG glue_s3 PROPERTIES (\n    'type' = 'iceberg',\n    'iceberg.catalog.type' = 'rest',\n    'iceberg.rest.uri' = 'https://glue.<region>.amazonaws.com/iceberg',\n    'warehouse' = '<acount_id>:s3tablescatalog/<s3_table_bucket_name>',\n    'iceberg.rest.sigv4-enabled' = 'true',\n    'iceberg.rest.signing-name' = 'glue',\n    'iceberg.rest.access-key-id' = '<ak>',\n    'iceberg.rest.secret-access-key' = '<sk>',\n    'iceberg.rest.signing-region' = '<region>'\n);\n"})}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(a.h3,{id:"03-access-s3tables",children:"03 Access S3Tables"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-sql",children:"Doris > SWITCH iceberg_s3;\n\nDoris > SHOW DATABASES;\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| my_namespace       |\n| mysql              |\n+--------------------+\n\nDoris > USE my_namespace;\n\nDoris > SHOW TABLES;\n+------------------------+\n| Tables_in_my_namespace |\n+------------------------+\n| my_table               |\n+------------------------+\n\nDoris > SELECT * FROM my_table;\n+------+------+-------+\n| id   | name | value |\n+------+------+-------+\n|    1 | ABC  |   100 |\n|    2 | XYZ  |   200 |\n+------+------+-------+\n"})}),"\n",(0,n.jsx)(a.h3,{id:"04-create-s3tables-table-and-write-data",children:"04 Create S3Tables Table and Write Data"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-sql",children:"Doris > CREATE TABLE partition_table (\n    ->   `ts` DATETIME COMMENT 'ts',\n    ->   `id` INT COMMENT 'col1',\n    ->   `pt1` STRING COMMENT 'pt1',\n    ->   `pt2` STRING COMMENT 'pt2'\n    -> )\n    -> PARTITION BY LIST (day(ts), pt1, pt2) ();\n\nDoris > INSERT INTO partition_table VALUES\n    -> (\"2024-01-01 08:00:00\", 1000, \"us-east\", \"PART1\"),\n    -> (\"2024-01-02 10:00:00\", 1002, \"us-sout\", \"PART2\");\nQuery OK, 2 rows affected\n{'status':'COMMITTED', 'txnId':'1736935786473'}\n\nDoris > SELECT * FROM partition_table;\n+----------------------------+------+---------+-------+\n| ts                         | id   | pt1     | pt2   |\n+----------------------------+------+---------+-------+\n| 2024-01-02 10:00:00.000000 | 1002 | us-sout | PART2 |\n| 2024-01-01 08:00:00.000000 | 1000 | us-east | PART1 |\n+----------------------------+------+---------+-------+\n"})}),"\n",(0,n.jsx)(a.h3,{id:"05-time-travel",children:"05 Time Travel"}),"\n",(0,n.jsxs)(a.p,{children:["We can insert another batch of data, then use the ",(0,n.jsx)(a.code,{children:"$snapshots"})," system table to view Iceberg Snapshots:"]}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-sql",children:'Doris > INSERT INTO partition_table VALUES\n    -> ("2024-01-03 08:00:00", 1000, "us-east", "PART1"),\n    -> ("2024-01-04 10:00:00", 1002, "us-sout", "PART2");\nQuery OK, 2 rows affected (9.76 sec)\n{\'status\':\'COMMITTED\', \'txnId\':\'1736935786474\'}\n'})}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{children:'Doris > SELECT * FROM partition_table$snapshots\\G\n*************************** 1. row ***************************\n committed_at: 2025-01-15 23:27:01\n  snapshot_id: 6834769222601914216\n    parent_id: -1\n    operation: append\nmanifest_list: s3://80afcb3f-6edf-46f2-7fhehwj6cengfwc7n6iz7ipzakd7quse1b--table-s3/metadata/snap-6834769222601914216-1-a6b2230d-fc0d-4c1d-8f20-94bb798f27b1.avro\n      summary: {"added-data-files":"2","added-records":"2","added-files-size":"5152","changed-partition-count":"2","total-records":"2","total-files-size":"5152","total-data-files":"2","total-delete-files":"0","total-position-deletes":"0","total-equality-deletes":"0","iceberg-version":"Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)"}\n*************************** 2. row ***************************\n committed_at: 2025-01-15 23:30:00\n  snapshot_id: 5670090782912867298\n    parent_id: 6834769222601914216\n    operation: append\nmanifest_list: s3://80afcb3f-6edf-46f2-7fhehwj6cengfwc7n6iz7ipzakd7quse1b--table-s3/metadata/snap-5670090782912867298-1-beeed339-be96-4710-858b-f39bb01cc3ff.avro\n      summary: {"added-data-files":"2","added-records":"2","added-files-size":"5152","changed-partition-count":"2","total-records":"4","total-files-size":"10304","total-data-files":"4","total-delete-files":"0","total-position-deletes":"0","total-equality-deletes":"0","iceberg-version":"Apache Iceberg 1.6.1 (commit 8e9d59d299be42b0bca9461457cd1e95dbaad086)"}\n'})}),"\n",(0,n.jsxs)(a.p,{children:["Use the ",(0,n.jsx)(a.code,{children:"VERSION AS OF"})," syntax to query different snapshots:"]}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-sql",children:"Doris > SELECT * FROM partition_table FOR VERSION AS OF 5670090782912867298;\n+----------------------------+------+---------+-------+\n| ts                         | id   | pt1     | pt2   |\n+----------------------------+------+---------+-------+\n| 2024-01-04 10:00:00.000000 | 1002 | us-sout | PART2 |\n| 2024-01-03 08:00:00.000000 | 1000 | us-east | PART1 |\n| 2024-01-01 08:00:00.000000 | 1000 | us-east | PART1 |\n| 2024-01-02 10:00:00.000000 | 1002 | us-sout | PART2 |\n+----------------------------+------+---------+-------+\n\nDoris > SELECT * FROM partition_table FOR VERSION AS OF 6834769222601914216;\n+----------------------------+------+---------+-------+\n| ts                         | id   | pt1     | pt2   |\n+----------------------------+------+---------+-------+\n| 2024-01-02 10:00:00.000000 | 1002 | us-sout | PART2 |\n| 2024-01-01 08:00:00.000000 | 1000 | us-east | PART1 |\n+----------------------------+------+---------+-------+\n"})}),"\n",(0,n.jsx)(a.h3,{id:"06-access-s3-tables-using-emr-spark",children:"06 Access S3 Tables Using EMR Spark"}),"\n",(0,n.jsx)(a.p,{children:"Data written using Doris can also be accessed using Spark:"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-shell",children:"spark-shell --jars /usr/share/aws/iceberg/lib//iceberg-spark-runtime-3.5_2.12-1.6.1-amzn-1.jar \\\n--packages software.amazon.s3tables:s3-tables-catalog-for-iceberg-runtime:0.1.3 \\\n--conf spark.sql.catalog.s3tablesbucket=org.apache.iceberg.spark.SparkCatalog \\\n--conf spark.sql.catalog.s3tablesbucket.catalog-impl=software.amazon.s3tables.iceberg.S3TablesCatalog \\\n--conf spark.sql.catalog.s3tablesbucket.warehouse=arn:aws:s3tables:us-east-1:169698000000:bucket/doris-s3-table-bucket \\\n--conf spark.sql.defaultCatalog=s3tablesbucket \\\n--conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\n"})}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-sql",children:'scala> spark.sql("SELECT * FROM s3tablesbucket.my_namespace.`partition_table` ").show()\n+-------------------+----+-------+-----+\n|                 ts|  id|    pt1|  pt2|\n+-------------------+----+-------+-----+\n|2024-01-02 10:00:00|1002|us-sout|PART2|\n|2024-01-01 08:00:00|1000|us-east|PART1|\n|2024-01-04 10:00:00|1002|us-sout|PART2|\n|2024-01-03 08:00:00|1000|us-east|PART1|\n+-------------------+----+-------+-----+\n'})})]})}function b(e={}){let{wrapper:a}={...(0,i.a)(),...e.components};return a?(0,n.jsx)(a,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},569416:function(e,a,s){s.d(a,{Z:function(){return t}});let t=s.p+"assets/images/s3-table-bucket-create-5981f616619e698458f9642f57a4af5d.png"},929807:function(e,a,s){s.d(a,{Z:function(){return t}});let t=s.p+"assets/images/s3-table-bucket-cd361f28553b89a7a8dddb6c244c0fb6.png"},250065:function(e,a,s){s.d(a,{Z:function(){return l},a:function(){return r}});var t=s(667294);let n={},i=t.createContext(n);function r(e){let a=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(a):{...a,...e}},[a,e])}function l(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),t.createElement(i.Provider,{value:a},e.children)}}}]);